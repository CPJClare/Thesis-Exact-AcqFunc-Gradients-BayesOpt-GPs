{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: Californian Housing Dataset\n",
        "\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f8624ab-e2aa-4fd3-9140-312ad0ac06d4"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyGPGO\n",
            "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.6)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Collecting Theano-PyMC\n",
            "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 15.3 MB/s \n",
            "\u001b[?25hCollecting pyMC3\n",
            "  Downloading pymc3-3.11.5-py3-none-any.whl (872 kB)\n",
            "\u001b[K     |████████████████████████████████| 872 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.1.0)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.1.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.12.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.5.1)\n",
            "Collecting deprecat\n",
            "  Downloading deprecat-2.1.1-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting semver>=2.13.0\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.8.0)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.2.2)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.0)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecat->pyMC3->pyGPGO) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n",
            "Building wheels for collected packages: pyGPGO, Theano-PyMC\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19879 sha256=a1e4a22059e138c942ce3b02708598628620c4d0d5247bd8f576e22b1db364be\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5d/0b/2160114e2f1b87791c51b66cf07f89831dbb6f49167950316f\n",
            "  Building wheel for Theano-PyMC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano-PyMC: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529963 sha256=7874d8ca8e701d478c836b1ae9bdc4c681901e87ff9066c5b77df7aebc5d436c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/af/8c/5dd7553522d74c52a7813806fc7ee1a9caa20a3f7c8fd850d5\n",
            "Successfully built pyGPGO Theano-PyMC\n",
            "Installing collected packages: Theano-PyMC, semver, deprecat, pyMC3, pyGPGO\n",
            "Successfully installed Theano-PyMC-1.1.2 deprecat-2.1.1 pyGPGO-0.5.1 pyMC3-3.11.5 semver-2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import norm\n",
        "from joblib import Parallel, delayed\n",
        "import itertools\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "df_train =  pd.read_csv('/content/sample_data/california_housing_train.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "1b52ec0b-7825-4f80-eb58-5f8527c7c085"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a776ee2-6d94-4a3d-a011-21db3a65bf50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a776ee2-6d94-4a3d-a011-21db3a65bf50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a776ee2-6d94-4a3d-a011-21db3a65bf50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a776ee2-6d94-4a3d-a011-21db3a65bf50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b095556a-3c1d-4701-c83d-a045d7f1c815"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 17000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "522d087a-e4b1-445b-81d3-37b9f843441a"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train.median_house_value.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('Median Californian House Price', weight = 'bold', family = 'Arial')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924365cb-3736-4c4c-feae-754a2362ae25"
      },
      "source": [
        "y = df_train.median_house_value.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66900.,  80100.,  85700., ..., 103600.,  85800.,  94600.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "be908aa0-9995-479c-f454-3c03af9b069c"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b0e9c9b-f0f0-4e28-8001-7e0cc252de45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b0e9c9b-f0f0-4e28-8001-7e0cc252de45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b0e9c9b-f0f0-4e28-8001-7e0cc252de45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b0e9c9b-f0f0-4e28-8001-7e0cc252de45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b668c6b2-8140-43da-b556-0199f74a1912"
      },
      "source": [
        "X = df_train.drop(['median_house_value'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  \n",
              "0      1015.0       472.0         1.4936  \n",
              "1      1129.0       463.0         1.8200  \n",
              "2       333.0       117.0         1.6509  \n",
              "3       515.0       226.0         3.1917  \n",
              "4       624.0       262.0         1.9250  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b048a38-d623-4758-821d-880bd8c471e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b048a38-d623-4758-821d-880bd8c471e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b048a38-d623-4758-821d-880bd8c471e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b048a38-d623-4758-821d-880bd8c471e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_test = 500 # test points\n",
        "\n",
        "util = 'ERM'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.1\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 30  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pmZYhVl9Hb"
      },
      "source": [
        "n_start_AcqFunc = max_iter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmJsNX29c_xA"
      },
      "source": [
        "### Surrogate derivatives: \n",
        "\n",
        "cov_func = squaredExponential()\n",
        "\n",
        "def kronDelta(X, Xstar):                     # Kronecker's Delta method\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\n",
        "\n",
        "def se(X, Xstar, sigmaf, l, sigman):         # S.E. kernel method\n",
        "    return sigmaf * np.exp(-0.5 * cdist(X, Xstar) ** 2 / l ** 2) + sigman * kronDelta(X, Xstar)\n",
        "\n",
        "def delta(X, Xstar):                         # Distance between training X and test Xstar vectors\n",
        "    return (X - Xstar)\n",
        "   \n",
        "def der_covmat(X, Xstar, sigmaf, l, sigman): # Covariance matrix derivative terms (i.e. exact, first-order)\n",
        "    nx = len(X)\n",
        "    ny = len(Xstar)\n",
        "    return np.round(np.array([(delta(np.atleast_2d(i), np.atleast_2d(j))[0] * se(np.atleast_2d(i), np.atleast_2d(j), sigmaf, l, sigman)[0]).sum() for (i, j) in itertools.product(X, Xstar)]).reshape(nx, ny), 8)\n",
        "\n",
        "class dGaussianProcess(GaussianProcess):    # Via inheritance, also optimises hyperparameters when opt = TRUE\n",
        "    \n",
        "    def AcqGrad(self, Xstar):               # Method returning exact, first-order derivatives of the GP's posterior mean and standard deviation\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = self.covfunc.K(self.X, Xstar).T\n",
        "        \n",
        "        dKstar = der_covmat(self.X, Xstar, self.covfunc.sigmaf, self.covfunc.l, self.covfunc.sigman).T\n",
        "        alpha_Kstar = np.dot(np.linalg.inv(self.K + (self.covfunc.sigman**2) * np.eye(len(self.X))), Kstar.T)\n",
        "        \n",
        "        dm = np.dot(dKstar, self.alpha)\n",
        "        ds = -2 * np.dot(dKstar, alpha_Kstar)\n",
        "        \n",
        "        return dm, ds           \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 1\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add exact acquisition function gradient as attribute:\n",
        "\n",
        "class Acquisition_grad(Acquisition):    \n",
        "    def __init__(self, mode, eps=eps, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'ERM': self.ERM\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "    \n",
        "    def ERM(self, y_global_orig, mean, std, ds, dm):\n",
        "        gamma = (mean - y_global_orig - self.eps) / (std + self.eps)\n",
        "        gamma_h = (mean - y_global_orig) / (std + self.eps)\n",
        "        dsdx = ds / (2 * (std + self.eps))\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\n",
        "        \n",
        "        f = (std + self.eps) * (gamma * norm.cdf(gamma) + norm.pdf(gamma))\n",
        "        df1 = f / (std + self.eps) * dsdx \n",
        "        df2 = (std + self.eps) * norm.cdf(gamma) * dmdx\n",
        "        df = (df1 + df2)[0]\n",
        "        df_arr = []\n",
        "\n",
        "        for j in range(0, dim):\n",
        "          df_arr.append(df)\n",
        "        return f, np.asarray(df_arr).transpose()\n",
        "        \n",
        "    def d_eval(self, y_global_orig, mean, std, ds, dm):\n",
        "    \n",
        "        return self.f(y_global_orig, mean, std, ds, dm, **self.params)\n",
        "        "
      ],
      "metadata": {
        "id": "ZIh5RYGkwBUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAK8N5bwfuJ7"
      },
      "source": [
        "## GPGO_multi: \n",
        "\n",
        "class GPGO_multi(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        " \n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(y_global_orig, new_mean, new_std, ds=ds, dm=dm)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(y_global_orig, new_mean, new_std, ds=ds, dm=dm)\n",
        "\n",
        "        return -f\n",
        "   \n",
        "    def _optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        \n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr        \n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_exact = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_exact = np.empty((n_start,))\n",
        "        opt_exact = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_exact = np.array([res.x for res in opt_exact])\n",
        "        f_best_exact = np.array([np.atleast_1d(res.fun)[0] for res in opt_exact])\n",
        "        f_best_min_exact = min(f_best_exact)\n",
        "\n",
        "        self.x_best_exact = x_best_exact\n",
        "        self.f_best_exact = f_best_exact\n",
        "        self.f_best_min_exact = f_best_min_exact\n",
        "        self.best_exact = x_best_exact[np.argmin(f_best_exact)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_exact)\n",
        "\n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_exact = str(inverse * self.f_best_min_exact)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_exact = BOLD + OKGREEN + max_acqfunc_exact + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc_exact, max_acqfunc))\n",
        "        \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self._optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S422jNLsdIMm"
      },
      "source": [
        "## dGPGO:\n",
        "\n",
        "class dGPGO(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        "\n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(y_global_orig, new_mean, new_std, ds=ds, dm=dm)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(y_global_orig, new_mean, new_std, ds=ds, dm=dm)\n",
        "\n",
        "        return -f\n",
        "\n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_approx = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_approx = np.empty((n_start,))\n",
        "        opt_approx = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_approx = np.array([res.x for res in opt_approx])\n",
        "        f_best_approx = np.array([np.atleast_1d(res.fun)[0] for res in opt_approx])\n",
        "        f_best_min_approx = min(f_best_approx)\n",
        "\n",
        "        self.x_best_approx = x_best_approx\n",
        "        self.f_best_approx = f_best_approx\n",
        "        self.f_best_min_approx = f_best_min_approx\n",
        "        self.best_approx = x_best_approx[np.argmin(f_best_approx)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_approx)\n",
        "    \n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_approx = str(inverse * self.f_best_min_approx)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_approx = BOLD + OKGREEN + max_acqfunc_approx + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc, max_acqfunc_approx))\n",
        "\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "580271f4-7133-4020-e13d-7890982fc045"
      },
      "source": [
        "start_approx = time.time()\n",
        "start_approx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663852405.4362442"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b38c19-df84-42f4-cce2-4742c20b3127"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_approx_1 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_1 = GPGO_multi(surrogate_approx_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "approx_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_1 = approx_1.getResult()[0]\n",
        "params_approx_1['max_depth'] = int(params_approx_1['max_depth'])\n",
        "params_approx_1['min_child_weight'] = int(params_approx_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_approx_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_approx_1 = xgb.train(params_approx_1, dX_approx_train1)\n",
        "pred_approx_1 = model_approx_1.predict(dX_approx_test1)\n",
        "\n",
        "rmse_approx_1 = np.sqrt(mean_squared_error(pred_approx_1, y_test1))\n",
        "rmse_approx_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 1.0028690365100252\t 0.6536753952667645\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7391862019705779\t 0.6536753952667645\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8806962872539386\t 0.6536753952667645\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.6536753952667645\t 0.6536753952667645\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 1.062518544792604\t 0.6536753952667645\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8659738506300403\t 0.6536753952667645\t 0.3516128267902776\t 0.3516128267902776\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 1.0589776023267656\t 0.6536753952667645\t 0.35059727959257997\t 0.35059727959257997\n",
            "3  \t [ 3.61274713  8.16007507 11.          0.84840025 19.          0.76215891]\t 0.6771887207267527\t 0.6536753952667645\t 0.36174031595002776\t 0.36174031595002776\n",
            "4  \t [ 9.28266952  0.44927819  7.          0.97265422 12.          0.93288355]\t 0.6820774846874944\t 0.6536753952667645\t 0.35159963941297434\t 0.35159963941297434\n",
            "5  \t [7.26893753 4.77012994 6.         0.80503254 3.         0.5748569 ]\t 0.8345963893957073\t 0.6536753952667645\t 0.3436763152055678\t 0.3436763152050742\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.9004243658767852\t 0.6536753952667645\t 0.3426188899357972\t 0.3426188899357972\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 1.0042308077866626\t 0.6536753952667645\t 0.34416129943123913\t 0.34416129943123913\n",
            "8  \t [1.97196346 6.91027342 6.         0.70962747 4.         0.32017066]\t 1.003362317360003\t 0.6536753952667645\t 0.3492162781188787\t 0.349216278106544\n",
            "9  \t [ 2.08878558  0.52993661 12.          0.75288969  1.          0.24822289]\t 1.0632523501795186\t 0.6536753952667645\t 0.3534058423488743\t 0.3534058423488743\n",
            "10 \t [ 9.11336104  7.53362458  9.          0.74107696 16.          0.6810286 ]\t 0.7469510576000753\t 0.6536753952667645\t 0.35892459196495347\t 0.35892459196495347\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 1.061946992849472\t 0.6536753952667645\t 0.35518766021780834\t 0.35518766021780834\n",
            "12 \t [ 1.88604523  9.48103721 11.          0.62052948 13.          0.76002949]\t 0.6847474575843426\t 0.6536753952667645\t 0.3598487495239716\t 0.3598487495239716\n",
            "13 \t [ 0.31984184  8.77960419  5.          0.79374224 16.          0.99761184]\t 0.7310969316491746\t 0.6536753952667645\t 0.35533597751375745\t 0.35533597751375745\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7499303794197336\t 0.6536753952667645\t 0.35210093294882056\t 0.35210093294882056\n",
            "15 \t [ 9.20512342  1.60831322 11.          0.87041344  2.          0.50117029]\t 0.8186293003915115\t 0.6536753952667645\t 0.34951421314760917\t 0.349514211121432\n",
            "16 \t [ 0.28990425  5.36117717 14.          0.57624837 11.          0.76620972]\t 0.684834878460344\t 0.6536753952667645\t 0.34838661346024014\t 0.34838613996913337\n",
            "17 \t [ 9.05451551  8.43196135 13.          0.88399349 12.          0.71276317]\t 0.7394602490781731\t 0.6536753952667645\t 0.34519201362060004\t 0.34519201362060004\n",
            "18 \t [7.53620606 9.21585827 9.         0.6102649  4.         0.74959467]\t 0.7555390919337681\t 0.6536753952667645\t 0.34307348370943425\t 0.34307348370943425\n",
            "19 \t [0.02000301 0.98539011 7.         0.81225498 5.         0.83272223]\t 0.7016321198241581\t 0.6536753952667645\t 0.3413610083223128\t 0.3413610083223128\n",
            "20 \t [ 5.83284604  4.19854596  7.          0.61565946 12.          0.69058075]\t 0.7667881430973947\t 0.6536753952667645\t 0.3390225182528413\t 0.3390224070767574\n",
            "21 \t [ 8.31884352  7.48611185 14.          0.79056923 18.          0.91287819]\t 0.6570802060505262\t 0.6536753952667645\t 0.33776720359298074\t 0.33776720355883333\n",
            "22 \t [ 4.65410509  7.57869444  5.          0.7635136  15.          0.8131422 ]\t 0.7396988098813949\t 0.6536753952667645\t 0.3351740325035751\t 0.3351740325035751\n",
            "23 \t [9.75910946 3.15553839 5.         0.81190775 7.         0.66076168]\t 0.8026335283678844\t 0.6536753952667645\t 0.3337688874207143\t 0.3337688874207143\n",
            "24 \t [ 7.04750175  3.42465254 14.          0.6398927  13.          0.58870141]\t 0.815252067284572\t 0.6536753952667645\t 0.33329316255025077\t 0.33329316255025077\n",
            "25 \t [3.92428694 0.68431362 6.         0.64283095 9.         0.2162494 ]\t 1.0619895012405975\t 0.6536753952667645\t 0.33302562771061595\t 0.33302562771061595\n",
            "26 \t [ 1.03968583  3.49943563 14.          0.82879876  3.          0.98366866]\t 0.6562345271802523\t 0.6536753952667645\t 0.3364409076318224\t 0.3364409076318224\n",
            "27 \t [ 2.52136808  8.51741902 14.          0.89185963  6.          0.23066693]\t 1.0608073786807473\t 0.6536753952667645\t 0.3342932376641854\t 0.3342932376641854\n",
            "28 \t [10.          9.16231333  5.          1.         19.51442525  0.1       ]\t 1.0251190755890853\t 0.6536753952667645\t 0.3374147401333587\t 0.3374149374266397\n",
            "29 \t [ 3.21551995  2.56534034 13.01839984  0.5        18.16652082  1.        ]\t 0.6693506776746849\t 0.6536753952667645\t 0.33980275958447836\t 0.33980137481690015\n",
            "30 \t [0.01760125 4.20168637 5.         0.62711786 8.         0.78825566]\t 0.7378644330521015\t 0.6536753952667645\t 0.33789876104434946\t 0.33789876104434946\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48973.66312746987"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864d6c06-b3f1-41ac-a948-3aaeceba29f8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_approx_2 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_2 = GPGO_multi(surrogate_approx_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "approx_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_2 = approx_2.getResult()[0]\n",
        "params_approx_2['max_depth'] = int(params_approx_2['max_depth'])\n",
        "params_approx_2['min_child_weight'] = int(params_approx_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_approx_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_approx_2 = xgb.train(params_approx_2, dX_approx_train2)\n",
        "pred_approx_2 = model_approx_2.predict(dX_approx_test2)\n",
        "\n",
        "rmse_approx_2 = np.sqrt(mean_squared_error(pred_approx_2, y_test2))\n",
        "rmse_approx_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.778909206070606\t 0.681387807728051\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.681387807728051\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.7040746477543849\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.7953147984784036\t 0.681387807728051\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.7954413972964868\t 0.681387807728051\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.2999859207899802\u001b[0m\t \u001b[1m\u001b[92m0.2999859207899802\u001b[0m\n",
            "2  \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\t 0.7341430302765248\t 0.6807577751383148\t 0.2954417961872129\t 0.2954417961872129\n",
            "3  \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]\t 0.7073935536898857\t 0.6807577751383148\t 0.29507728955743684\t 0.29507728955743684\n",
            "4  \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]\t 0.7899041327973497\t 0.6807577751383148\t 0.29349962645293376\t 0.29349962645293376\n",
            "5  \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]\t 0.7887181971022355\t 0.6807577751383148\t 0.29598062419337035\t 0.29598062419337035\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.2980285712812148\u001b[0m\t \u001b[1m\u001b[92m0.2980285712812148\u001b[0m\n",
            "7  \t [ 9.14946201  2.43697872  6.          0.997805   19.          0.45949208]\t 0.8064071783057642\t 0.67907472219801\t 0.29554885507956674\t 0.29554885507902934\n",
            "8  \t [3.03571116 4.83939078 5.         0.66625528 1.         0.23130028]\t 0.872344629033322\t 0.67907472219801\t 0.2978167282205312\t 0.2978167282205312\n",
            "9  \t [ 4.57706999  8.33565192 11.          0.6188546   7.          0.54017925]\t 0.7035850285613279\t 0.67907472219801\t 0.30207174603558656\t 0.30207174603558656\n",
            "10 \t [2.51973603 9.74135258 5.         0.69633293 8.         0.1952065 ]\t 0.8718341605674269\t 0.67907472219801\t 0.3005936762352891\t 0.3005936762352891\n",
            "11 \t [ 8.6330652   9.62113163 11.          0.50355876 13.          0.80231095]\t 0.6810729676933972\t 0.67907472219801\t 0.3038872288585747\t 0.3038872288585747\n",
            "12 \t [ 9.73810496  3.32466832  6.          0.67226447 13.          0.93959986]\t 0.70791287382674\t 0.67907472219801\t 0.3019766277343136\t 0.3019766229134107\n",
            "13 \t [ 7.86086296  9.53235807  5.          0.78700181 16.          0.22516618]\t 0.8728710854388536\t 0.67907472219801\t 0.30086116688144077\t 0.30086116688144077\n",
            "14 \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]\t 0.7143733066956096\t 0.67907472219801\t 0.30368634565310626\t 0.30368634565310626\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 8.6950785   0.99410218 13.          0.66782851 17.          0.9323419 ]\u001b[0m\t \u001b[1m\u001b[92m0.6668275525286983\u001b[0m\t \u001b[1m\u001b[92m0.6668275525286983\u001b[0m\t \u001b[1m\u001b[92m0.3027312892629761\u001b[0m\t \u001b[1m\u001b[92m0.3027312892629761\u001b[0m\n",
            "16 \t [9.70003354 0.07825472 7.         0.79315177 1.         0.1995403 ]\t 0.8658541266182345\t 0.6668275525286983\t 0.30106572713803803\t 0.30106572713803803\n",
            "17 \t [ 9.61885664  9.78589131 14.          0.8903706   1.          0.14094172]\t 0.86262646699532\t 0.6668275525286983\t 0.30326534325396287\t 0.30326534325396287\n",
            "18 \t [ 5.64670451  8.85432647 14.          0.95807607 10.          0.35707694]\t 0.7882609808277333\t 0.6668275525286983\t 0.3052987783271646\t 0.3052987783271646\n",
            "19 \t [ 0.34964202  6.10551304 14.          0.81887518  8.          0.79373024]\t 0.6685630386219239\t 0.6668275525286983\t 0.3056482417205434\t 0.3056482417205434\n",
            "20 \t [0.62273619 1.29124124 6.         0.81123451 8.         0.42451055]\t 0.8085428854730617\t 0.6668275525286983\t 0.30417868682267674\t 0.30417868682267674\n",
            "21 \t [8.31655833 8.60825609 5.         0.85952394 8.         0.28298607]\t 0.830413546965097\t 0.6668275525286983\t 0.304935024605648\t 0.304935024605648\n",
            "22 \t [ 0.51057799  7.98632671  8.          0.8773209  13.          0.97148281]\t 0.6760991691526478\t 0.6668275525286983\t 0.3059907392175278\t 0.3059907392175278\n",
            "23 \t [ 1.14769908  9.46854425 10.          0.58022432 19.          0.87672068]\t 0.6763818131586096\t 0.6668275525286983\t 0.3047214416738018\t 0.3047214416738018\n",
            "24 \t [ 5.48814708  1.96120195 13.          0.89659682  1.          0.34125713]\t 0.7953122343367733\t 0.6668275525286983\t 0.303547361545541\t 0.303547361545541\n",
            "25 \t [ 2.55390985  1.0433692  14.          0.50090092 18.          0.75542228]\t 0.6809836782112952\t 0.6668275525286983\t 0.30403162518713295\t 0.30403162518713295\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[ 8.30471915  3.26072064 14.          0.69508376  6.          0.94564556]\u001b[0m\t \u001b[1m\u001b[92m0.6666799570614775\u001b[0m\t \u001b[1m\u001b[92m0.6666799570614775\u001b[0m\t \u001b[1m\u001b[92m0.30300856017913946\u001b[0m\t \u001b[1m\u001b[92m0.3030085583153926\u001b[0m\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.6817048020092698\t 0.6666799570614775\t 0.30188474365578205\t 0.30188474365578205\n",
            "28 \t [ 4.11831219  1.06523616 12.          0.63008078 16.          0.53873389]\t 0.7006937452963055\t 0.6666799570614775\t 0.30099465528194985\t 0.30099465528194985\n",
            "29 \t [ 0.28751737  5.24348341 14.00232563  1.         19.42167533  0.58631405]\t 0.69510963580187\t 0.6666799570614775\t 0.3002850097193901\t 0.3002837876869887\n",
            "30 \t [4.59810674 1.74332022 5.         0.67256858 5.         0.56916425]\t 0.7697652406753995\t 0.6666799570614775\t 0.29963365675573894\t 0.2996328200351383\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49983.336198553036"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550a7f16-da2c-48e9-a0ba-8c32c1199eb3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_approx_3 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_3 = GPGO_multi(surrogate_approx_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "approx_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_3 = approx_3.getResult()[0]\n",
        "params_approx_3['max_depth'] = int(params_approx_3['max_depth'])\n",
        "params_approx_3['min_child_weight'] = int(params_approx_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_approx_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_approx_3 = xgb.train(params_approx_3, dX_approx_train3)\n",
        "pred_approx_3 = model_approx_3.predict(dX_approx_test3)\n",
        "\n",
        "rmse_approx_3 = np.sqrt(mean_squared_error(pred_approx_3, y_test3))\n",
        "rmse_approx_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.0213644638508028\t 0.7688389438662246\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.022822678309975\t 0.7688389438662246\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.7688389438662246\t 0.7688389438662246\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0239688135226253\t 0.7688389438662246\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8703298117399682\t 0.7688389438662246\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8050626816251143\t 0.7688389438662246\t 0.3778996429816352\t 0.3778996429816352\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 2.46535469  7.06056184  5.          0.53518488 13.          0.98930148]\u001b[0m\t \u001b[1m\u001b[92m0.7347345488605661\u001b[0m\t \u001b[1m\u001b[92m0.7347345488605661\u001b[0m\t \u001b[1m\u001b[92m0.3690512942835627\u001b[0m\t \u001b[1m\u001b[92m0.3690512942835627\u001b[0m\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0239673069901083\t 0.7347345488605661\t 0.35918770092919283\t 0.35918770092919283\n",
            "4  \t [ 6.69378835  1.1746468   5.          0.75549171 16.          0.73450657]\t 0.7722220514333056\t 0.7347345488605661\t 0.36571609405121075\t 0.36571609405121075\n",
            "5  \t [ 0.24010242  9.80847714 13.          0.63702721  3.          0.56729929]\t 0.7723921954821745\t 0.7347345488605661\t 0.359767598977794\t 0.359767598977794\n",
            "6  \t [9.87422438 6.71772444 5.         0.63287091 5.         0.98483042]\t 0.7384798879960105\t 0.7347345488605661\t 0.35494290969637377\t 0.35494290969637377\n",
            "7  \t [6.87752707 0.15955299 8.         0.55138154 9.         0.67263073]\t 0.7372222724588662\t 0.7347345488605661\t 0.34988828382968723\t 0.34988828382968723\n",
            "8  \t [2.6278521  1.48922274 6.         0.63082487 1.         0.15934029]\t 1.0282950487417917\t 0.7347345488605661\t 0.3455840955559042\t 0.34558409308904164\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[ 8.89682762  0.79017134 14.          0.58366818  8.          0.97456627]\u001b[0m\t \u001b[1m\u001b[92m0.6882258735708705\u001b[0m\t \u001b[1m\u001b[92m0.6882258735708705\u001b[0m\t \u001b[1m\u001b[92m0.35097988138864306\u001b[0m\t \u001b[1m\u001b[92m0.35097988138853964\u001b[0m\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 8.44289655  0.57103551 12.          0.84075455 17.          0.88566746]\u001b[0m\t \u001b[1m\u001b[92m0.6798132840292306\u001b[0m\t \u001b[1m\u001b[92m0.6798132840292306\u001b[0m\t \u001b[1m\u001b[92m0.3460815224725709\u001b[0m\t \u001b[1m\u001b[92m0.3460815224725709\u001b[0m\n",
            "11 \t [ 1.21954001  0.36323278  6.          0.64916715 17.          0.72126664]\t 0.7591259448829037\t 0.6798132840292306\t 0.3416008173495884\t 0.3416008173495884\n",
            "12 \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\t 0.6998375974069359\t 0.6798132840292306\t 0.33930842195503064\t 0.33930842195503064\n",
            "13 \t [ 6.75452287  5.54111128  5.          0.67317876 10.          0.11983715]\t 1.0305807790275678\t 0.6798132840292306\t 0.33607007432347674\t 0.3360700627198929\n",
            "14 \t [0.86375274 7.69964496 8.         0.67182269 1.         0.12474838]\t 1.0238038898846435\t 0.6798132840292306\t 0.3406750614813873\t 0.3406750614813873\n",
            "15 \t [ 8.58495733  5.09928748 13.          0.89538108  1.          0.67774369]\t 0.7408787247915003\t 0.6798132840292306\t 0.34457394879729536\t 0.34457394879729536\n",
            "16 \t [ 9.86273212  5.79963604 13.          0.69696961 16.          0.70097151]\t 0.7296642769414492\t 0.6798132840292306\t 0.3422903522680869\t 0.3422903522680869\n",
            "17 \t [ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\t 0.7059876882234674\t 0.6798132840292306\t 0.34002726923277393\t 0.34002726923277393\n",
            "18 \t [1.14934749 1.30310631 7.         0.60930428 6.         0.86412796]\t 0.7189871901849552\t 0.6798132840292306\t 0.3375926423195234\t 0.33759253559520613\n",
            "19 \t [ 2.58261481  1.43735307 13.          0.73828328 19.          0.96017932]\t 0.6819322162402592\t 0.6798132840292306\t 0.33554555230129285\t 0.33554555230129285\n",
            "20 \t [ 1.06084272  8.60821489 11.          0.60672694  9.          0.40602348]\t 0.8723133504012892\t 0.6798132840292306\t 0.33314170856491243\t 0.3331416771166655\n",
            "21 \t [ 9.83060339  5.43479292  5.          0.93965116 19.          0.81693736]\t 0.7430400763458248\t 0.6798132840292306\t 0.33374884860526055\t 0.33374884860526055\n",
            "22 \t [ 0.7793921   8.87321184 14.          0.62565306 14.          0.27955137]\t 0.9804360243561806\t 0.6798132840292306\t 0.3323910928418862\t 0.3323910928418862\n",
            "23 \t [ 1.20882434  1.32647361 14.          0.83121093  4.          0.9002973 ]\t 0.6847850750473601\t 0.6798132840292306\t 0.3347506584438639\t 0.334750655536318\n",
            "24 \t [ 0.04997226  0.57243486  5.          0.9748128  12.          0.24835402]\t 1.0287999951759097\t 0.6798132840292306\t 0.33274817036021964\t 0.33274817036021964\n",
            "25 \t [8.10694301 4.17712073 5.         0.80634144 1.         0.66433498]\t 0.7742548953777686\t 0.6798132840292306\t 0.3357263383371643\t 0.3357263383371643\n",
            "26 \t [ 5.07665331  4.6343883  14.          0.62511663 16.          0.73650486]\t 0.7300649872465008\t 0.6798132840292306\t 0.3348662179856673\t 0.3348662093386542\n",
            "27 \t [ 8.21944232  0.76315735 14.          0.70782001  3.          0.58640207]\t 0.771954843353409\t 0.6798132840292306\t 0.33354845206627776\t 0.33354845206627776\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 7.83094211 10.         13.08629882  1.         14.93651458  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6527100510281995\u001b[0m\t \u001b[1m\u001b[92m0.6527100510281995\u001b[0m\t \u001b[1m\u001b[92m0.33277862766449423\u001b[0m\t \u001b[1m\u001b[92m0.33277761476502077\u001b[0m\n",
            "29 \t [9.04708311 3.23802416 9.         0.69632437 5.         0.31952145]\t 0.9809540174678567\t 0.6527100510281995\t 0.3308179959155776\t 0.3308179959155776\n",
            "30 \t [ 0.50646974  6.72570721  7.          0.51798099 18.          0.75487674]\t 0.7188022076639518\t 0.6527100510281995\t 0.3327553079864872\t 0.3327553079864872\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48925.8432544791"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871ccf10-0b96-4718-ddd4-1039a357ae01"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_approx_4 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_4 = GPGO_multi(surrogate_approx_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "approx_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_4 = approx_4.getResult()[0]\n",
        "params_approx_4['max_depth'] = int(params_approx_4['max_depth'])\n",
        "params_approx_4['min_child_weight'] = int(params_approx_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_approx_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_approx_4 = xgb.train(params_approx_4, dX_approx_train4)\n",
        "pred_approx_4 = model_approx_4.predict(dX_approx_test4)\n",
        "\n",
        "rmse_approx_4 = np.sqrt(mean_squared_error(pred_approx_4, y_test4))\n",
        "rmse_approx_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7356156069458683\t 0.6641721421409617\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7070759857649549\t 0.6641721421409617\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 0.9423811784101735\t 0.6641721421409617\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.6641721421409617\t 0.6641721421409617\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.8244425146132294\t 0.6641721421409617\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 0.9441431878307984\t 0.6641721421409617\t 0.3115838464839154\t 0.3115838464839154\n",
            "2  \t [5.94148132 0.3774518  8.         0.8050532  1.         0.46608024]\t 0.7805337335260593\t 0.6641721421409617\t 0.3233405275534221\t 0.3233405275534221\n",
            "3  \t [ 5.85683381  2.94167057 14.          0.88584905  6.          0.61705001]\t 0.7122631009157718\t 0.6641721421409617\t 0.3216602680986483\t 0.3216602680986483\n",
            "4  \t [ 5.92074392  7.05411368 14.          0.56897417 18.          0.54051446]\t 0.7168223003470561\t 0.6641721421409617\t 0.31721405917684925\t 0.31721405917684925\n",
            "5  \t [ 0.13337167  3.07677647 14.          0.92270334  2.          0.56046161]\t 0.7175621988652162\t 0.6641721421409617\t 0.31389630996109885\t 0.313896309959191\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 0.9390440646887555\t 0.6641721421409617\t 0.3112436866762498\t 0.3112436866762498\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.7531044966742895\t 0.6641721421409617\t 0.31752883201933585\t 0.31752883201933585\n",
            "8  \t [ 0.32236964  2.41893129 14.          0.88540422 15.          0.72064562]\t 0.6990250321451492\t 0.6641721421409617\t 0.3161404025079665\t 0.3161404025079665\n",
            "9  \t [ 3.4576838   6.55355466  6.          0.72569372 18.          0.65149337]\t 0.7402639669497775\t 0.6641721421409617\t 0.31343087808024184\t 0.3134308779229008\n",
            "10 \t [ 9.3450382   8.82768787 11.          0.76868692  7.          0.8502727 ]\t 0.6886255429382424\t 0.6641721421409617\t 0.3121722639967386\t 0.3121722639967386\n",
            "11 \t [ 9.65147322  0.33792642 12.          0.92327424 17.          0.84355403]\t 0.681769217592037\t 0.6641721421409617\t 0.3098164387786871\t 0.3098164387786871\n",
            "12 \t [ 6.42812835  2.68771086 14.          0.56754055 12.          0.58164316]\t 0.7181852598091563\t 0.6641721421409617\t 0.30758841654535546\t 0.30758841654535546\n",
            "13 \t [0.69118951 0.05924245 6.         0.53870729 9.         0.9249957 ]\t 0.7094683558071616\t 0.6641721421409617\t 0.30638889627782034\t 0.30638889627782034\n",
            "14 \t [ 0.51187296  7.77314276 11.          0.63389119 15.          0.16589245]\t 0.9414371483413593\t 0.6641721421409617\t 0.3051385275613293\t 0.3051385275613293\n",
            "15 \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]\t 0.7682434061303821\t 0.6641721421409617\t 0.3092460771648293\t 0.3092460771648293\n",
            "16 \t [0.18736012 2.87894429 5.         0.99715153 3.         0.38605574]\t 0.8039158782445464\t 0.6641721421409617\t 0.3091086473206287\t 0.3091086473206287\n",
            "17 \t [ 3.32457373  8.75010191 14.          0.50853534  3.          0.96522732]\t 0.678104436556892\t 0.6641721421409617\t 0.3096712542334642\t 0.3096712542334642\n",
            "18 \t [6.18461978 1.56321293 5.         0.63345598 8.         0.11755092]\t 0.9382571320102834\t 0.6641721421409617\t 0.30799979473357425\t 0.30799979473357425\n",
            "19 \t [ 7.38805311  3.2889511   9.          0.96164384 12.          0.26669832]\t 0.8179704798095913\t 0.6641721421409617\t 0.3111768450235067\t 0.31117684487443126\n",
            "20 \t [ 1.78217576  9.78210974  5.          0.8003284  12.          0.83416548]\t 0.7532223657335955\t 0.6641721421409617\t 0.31182263223668255\t 0.31182263223668255\n",
            "21 \t [3.83586625 6.82676995 9.         0.53079541 5.         0.93774826]\t 0.6805235814013784\t 0.6641721421409617\t 0.31137732568275955\t 0.31137732467251555\n",
            "22 \t [ 7.74424383  9.98522818 11.          0.6893711  12.          0.28902454]\t 0.8228315565622646\t 0.6641721421409617\t 0.3099381380042685\t 0.3099381380042685\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 0.9412996363676764\t 0.6641721421409617\t 0.3106360744988411\t 0.3106360744988411\n",
            "24 \t [ 0.2037679   4.62327556 14.          0.9601471  10.          0.37032611]\t 0.821234070339543\t 0.6641721421409617\t 0.3131850762811978\t 0.3131850762811978\n",
            "25 \t [ 3.90664061  3.70607006  6.          0.71802602 14.          0.27231472]\t 0.8244487840414205\t 0.6641721421409617\t 0.31369410169901923\t 0.31369410169901923\n",
            "26 \t [ 8.9794725   0.03075938 11.          0.54769472  8.          0.98530081]\t 0.6739524026009786\t 0.6641721421409617\t 0.31420711755767144\t 0.31420706419869543\n",
            "27 \t [ 9.5097348   7.3660116   9.          0.93170762 19.          0.34791577]\t 0.8162562136213343\t 0.6641721421409617\t 0.31284922050750563\t 0.31284922050750563\n",
            "28 \t [8.25703758 3.81820079 8.         0.97745356 4.         0.84458611]\t 0.6978864542140426\t 0.6641721421409617\t 0.31326033913568024\t 0.31326033913568024\n",
            "29 \t [ 9.24438087  3.05350094 13.          0.80832366  2.          0.67593834]\t 0.7107438132911144\t 0.6641721421409617\t 0.31226140439212535\t 0.31226140439212535\n",
            "30 \t [ 5.25331619  0.         15.          0.5         1.          0.72210055]\t 0.7283588546142312\t 0.6641721421409617\t 0.31144821324847644\t 0.31144860664244556\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50692.52474167973"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65237913-31cd-471a-845a-b8eeb5646f27"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_approx_5 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_5 = GPGO_multi(surrogate_approx_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "approx_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_5 = approx_5.getResult()[0]\n",
        "params_approx_5['max_depth'] = int(params_approx_5['max_depth'])\n",
        "params_approx_5['min_child_weight'] = int(params_approx_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_approx_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_approx_5 = xgb.train(params_approx_5, dX_approx_train5)\n",
        "pred_approx_5 = model_approx_5.predict(dX_approx_test5)\n",
        "\n",
        "rmse_approx_5 = np.sqrt(mean_squared_error(pred_approx_5, y_test5))\n",
        "rmse_approx_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7403320965261992\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7493104333264211\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9342492295788805\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.939514214921639\t 0.7403320965261992\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.921290745787579\t 0.7403320965261992\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9436861715841889\t 0.7403320965261992\t 0.3397445061565474\t 0.3397445061565474\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9276450520884063\t 0.7403320965261992\t 0.3461373605897039\t 0.3461373605897039\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.3496576525198903\u001b[0m\t \u001b[1m\u001b[92m0.3496576525198903\u001b[0m\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.9276698902289097\t 0.7398148307506893\t 0.3458463388801236\t 0.3458463388801236\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.3463935244998457\u001b[0m\t \u001b[1m\u001b[92m0.3463935244998457\u001b[0m\n",
            "6  \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]\t 0.92565009216999\t 0.6989575443158274\t 0.3402425730734147\t 0.3402425730734123\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8160533272968584\t 0.6989575443158274\t 0.3429840253265198\t 0.34298402531628047\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m0.3415658317086086\u001b[0m\t \u001b[1m\u001b[92m0.3415658317086086\u001b[0m\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9277423136052668\t 0.6747588495441635\t 0.33655158207910785\t 0.33655158207910785\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.6796390241442563\t 0.6747588495441635\t 0.33905913877774346\t 0.33905913877774346\n",
            "11 \t [ 9.88162042  4.98501997  7.          0.71514689 11.          0.88825005]\t 0.6938260252917123\t 0.6747588495441635\t 0.3349597429775778\t 0.3349597429775778\n",
            "12 \t [8.44893619 0.35900307 6.         0.94734172 4.         0.72898681]\t 0.7387384974169141\t 0.6747588495441635\t 0.3316235379944725\t 0.3316235379944725\n",
            "13 \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]\t 0.7130088179210804\t 0.6747588495441635\t 0.32956684146471465\t 0.32956681651285785\n",
            "14 \t [ 9.58736014  2.45468429 12.          0.89338522 12.          0.76778503]\t 0.6833142835714986\t 0.6747588495441635\t 0.3272235355061632\t 0.32722352088416556\n",
            "15 \t [ 0.69381482  7.09764326  5.          0.79260103 13.          0.36148114]\t 0.9417860014577227\t 0.6747588495441635\t 0.3245780250798061\t 0.3245780250798061\n",
            "16 \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]\t 0.8392510578678525\t 0.6747588495441635\t 0.3273248428185534\t 0.3273248428185534\n",
            "17 \t [ 6.56637184  9.40150707  8.          0.97457564 11.          0.85712178]\t 0.6937780374760996\t 0.6747588495441635\t 0.32768512983599896\t 0.327684986934923\n",
            "18 \t [ 9.73541293  8.42044427 14.          0.53390677 16.          0.10576782]\t 0.9298944113695408\t 0.6747588495441635\t 0.32554404008495635\t 0.32554404008495635\n",
            "19 \t [ 0.71765067  7.44756902  5.          0.5        18.04292527  0.53826294]\t 0.816055273716841\t 0.6747588495441635\t 0.3276498511304058\t 0.3276489914002943\n",
            "20 \t [ 1.1246472   2.50523123 12.          0.73015278  7.          0.68499751]\t 0.697876102895983\t 0.6747588495441635\t 0.32844922082189626\t 0.32844922082189626\n",
            "21 \t [ 2.198289    3.67796949 10.          0.90046315 19.          0.21147767]\t 0.9281741766720613\t 0.6747588495441635\t 0.32573498678688384\t 0.32573498678688384\n",
            "22 \t [ 2.91337967  2.05536802 14.79688112  0.57196977 15.52209559  0.82078337]\t 0.6896985524939883\t 0.6747588495441635\t 0.3275606487968487\t 0.32755914370154005\n",
            "23 \t [ 9.60183769  3.43959486 14.          0.61022694  4.          0.76574329]\t 0.6946171572826957\t 0.6747588495441635\t 0.3257698683070193\t 0.325768884197501\n",
            "24 \t [5.80891976 6.22815082 5.         0.60791835 2.         0.19304152]\t 0.9476839298613445\t 0.6747588495441635\t 0.32415769479024326\t 0.3241573004249312\n",
            "25 \t [3.87440681 3.94556232 6.99648268 0.5        9.67350388 0.1       ]\t 0.9402177594584247\t 0.6747588495441635\t 0.3261651538396257\t 0.32616399398755946\n",
            "26 \t [ 7.84592019  0.         15.          0.5         9.37305487  0.26906981]\t 0.9323036187681891\t 0.6747588495441635\t 0.3279134001569839\t 0.3279127558630157\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 7.72255135 10.         13.25307714  0.85967227  1.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6544084709197107\u001b[0m\t \u001b[1m\u001b[92m0.6544084709197107\u001b[0m\t \u001b[1m\u001b[92m0.3294256027333984\u001b[0m\t \u001b[1m\u001b[92m0.3294244629833257\u001b[0m\n",
            "28 \t [ 6.60924517  5.47852198 12.          0.79248846 15.          0.38107311]\t 0.7807144361787735\t 0.6544084709197107\t 0.32817174188085596\t 0.3281717418808559\n",
            "29 \t [10.          2.26373485 15.          0.5        17.96070437  1.        ]\t 0.6618325765268445\t 0.6544084709197107\t 0.32703065219976807\t 0.3270308119134279\n",
            "30 \t [ 0.51069664  0.         12.69154378  1.          1.          0.1       ]\t 1.0039955240585257\t 0.6544084709197107\t 0.3253517757842164\t 0.32535167335399345\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52632.576806451565"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb21c0b4-5c68-4dfc-ae8d-63cb2cae0afb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_approx_6 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_6 = GPGO_multi(surrogate_approx_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "approx_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_6 = approx_6.getResult()[0]\n",
        "params_approx_6['max_depth'] = int(params_approx_6['max_depth'])\n",
        "params_approx_6['min_child_weight'] = int(params_approx_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_approx_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_approx_6 = xgb.train(params_approx_6, dX_approx_train6)\n",
        "pred_approx_6 = model_approx_6.predict(dX_approx_test6)\n",
        "\n",
        "rmse_approx_6 = np.sqrt(mean_squared_error(pred_approx_6, y_test6))\n",
        "rmse_approx_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8597082353696148\t 0.7312157182363477\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.8283267033366734\t 0.7312157182363477\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.7312157182363477\t 0.7312157182363477\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.835804847353631\t 0.7312157182363477\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0201879064028692\t 0.7312157182363477\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.019213535386702\t 0.7312157182363477\t 0.3429488605744742\t 0.3429488605744742\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.0290226001513474\t 0.7312157182363477\t 0.35435374476507975\t 0.35435374476507975\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0228902128409325\t 0.7312157182363477\t 0.36291012843192827\t 0.36291012843192827\n",
            "4  \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]\t 1.0595990180003476\t 0.7312157182363477\t 0.36885818085751304\t 0.36885818085676025\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m0.37522468008045745\u001b[0m\t \u001b[1m\u001b[92m0.37522468008045745\u001b[0m\n",
            "6  \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]\t 0.9234519385526558\t 0.6939533330723558\t 0.3665769128188622\t 0.3665769128184551\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.0610911324495744\t 0.6939533330723558\t 0.36674340768967156\t 0.36674340768966335\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]\u001b[0m\t \u001b[1m\u001b[92m0.6895189879978737\u001b[0m\t \u001b[1m\u001b[92m0.6895189879978737\u001b[0m\t \u001b[1m\u001b[92m0.37178656072796185\u001b[0m\t \u001b[1m\u001b[92m0.37178656072796185\u001b[0m\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0250396556181756\t 0.6895189879978737\t 0.36532982238856954\t 0.36532982238856954\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\u001b[0m\t \u001b[1m\u001b[92m0.6832941408312798\u001b[0m\t \u001b[1m\u001b[92m0.6832941408312798\u001b[0m\t \u001b[1m\u001b[92m0.3686152333004688\u001b[0m\t \u001b[1m\u001b[92m0.3686152333004688\u001b[0m\n",
            "11 \t [ 9.49126464  2.25575335  7.          0.89398566 13.          0.76947203]\t 0.7493845671941612\t 0.6832941408312798\t 0.36294205107221794\t 0.36294204677106073\n",
            "12 \t [ 1.03080361  6.70895845  7.          0.73336025 19.          0.31104879]\t 1.016921838187168\t 0.6832941408312798\t 0.359335962865231\t 0.359335962865231\n",
            "13 \t [0.         0.20555687 5.         0.5        1.         0.1       ]\t 1.0641944470930125\t 0.6832941408312798\t 0.3621722638076191\t 0.36217226531707314\n",
            "14 \t [9.89801174 9.77563967 9.         0.68555662 3.         0.83921118]\t 0.73813303625317\t 0.6832941408312798\t 0.36591688405049155\t 0.36591684212491915\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 0.50127522  1.94924928 11.          0.89270197 19.          0.91286914]\u001b[0m\t \u001b[1m\u001b[92m0.6768798166626013\u001b[0m\t \u001b[1m\u001b[92m0.6768798166626013\u001b[0m\t \u001b[1m\u001b[92m0.3625078806141919\u001b[0m\t \u001b[1m\u001b[92m0.3625078806141919\u001b[0m\n",
            "16 \t [6.55109905 2.29203942 6.         0.7269974  8.         0.87997636]\t 0.7181103319607761\t 0.6768798166626013\t 0.35845128843086294\t 0.35845128843086294\n",
            "17 \t [ 3.50815226  9.13058689  5.          0.80778314 15.          0.92212261]\t 0.7403743980122233\t 0.6768798166626013\t 0.35540015565271765\t 0.35540015565271565\n",
            "18 \t [0.75190021 2.99821111 7.         0.73112778 8.         0.11979456]\t 1.060673835734707\t 0.6768798166626013\t 0.35284941389746605\t 0.35284941389746605\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.0599380721478096\t 0.6768798166626013\t 0.35623641231607583\t 0.35623641231607583\n",
            "\u001b[1m\u001b[92m20\u001b[0m\t \u001b[1m\u001b[92m[10.          7.6157078   9.90808555  0.5         9.00003154  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6708845773195072\u001b[0m\t \u001b[1m\u001b[92m0.6708845773195072\u001b[0m\t \u001b[1m\u001b[92m0.35921795672426776\u001b[0m\t \u001b[1m\u001b[92m0.35921687751200637\u001b[0m\n",
            "21 \t [4.70222718 7.76335614 9.         0.92367012 9.         0.28724782]\t 1.0152545517792837\t 0.6708845773195072\t 0.35604693144811916\t 0.3560469314433019\n",
            "22 \t [ 9.56780844  0.64608047 12.          0.83676299  2.          0.96098008]\t 0.6833221374902283\t 0.6708845773195072\t 0.35805405083874764\t 0.35805405083874764\n",
            "23 \t [0.09752792 7.56070281 9.         0.95937939 3.         0.71279346]\t 0.7751689886400943\t 0.6708845773195072\t 0.35522009239706526\t 0.3552199459593115\n",
            "24 \t [ 9.55684885  4.02134483 11.          0.82079508  6.          0.83404351]\t 0.7299947122757273\t 0.6708845773195072\t 0.3537167369519371\t 0.3537167369519371\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.6893334668436607\t 0.6708845773195072\t 0.3517468190467277\t 0.3517468190467277\n",
            "26 \t [ 9.35726625  4.08028129 14.42376931  0.69647565 15.88336308  0.65907191]\t 0.7707420369831277\t 0.6708845773195072\t 0.34942667655194015\t 0.3494252163494889\n",
            "27 \t [ 0.          2.28895009  5.          1.         17.44490037  0.1       ]\t 1.0537596978138457\t 0.6708845773195072\t 0.34815236243121356\t 0.34815165499634465\n",
            "28 \t [5.13828315 0.         5.         1.         4.00377696 0.1       ]\t 1.0537163978465796\t 0.6708845773195072\t 0.35063507546785894\t 0.35063333679730696\n",
            "29 \t [ 1.0021313   4.9490761  14.          0.62016719  1.          0.18537333]\t 1.0636257139268357\t 0.6708845773195072\t 0.3529507835673223\t 0.35295063165737495\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.786373065109467\t 0.6708845773195072\t 0.35528393817438275\t 0.35528393817438275\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50060.38814849482"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92851908-0440-4dca-9d68-a43cdccba72c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_approx_7 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_7 = GPGO_multi(surrogate_approx_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "approx_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_7 = approx_7.getResult()[0]\n",
        "params_approx_7['max_depth'] = int(params_approx_7['max_depth'])\n",
        "params_approx_7['min_child_weight'] = int(params_approx_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_approx_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_approx_7 = xgb.train(params_approx_7, dX_approx_train7)\n",
        "pred_approx_7 = model_approx_7.predict(dX_approx_test7)\n",
        "\n",
        "rmse_approx_7 = np.sqrt(mean_squared_error(pred_approx_7, y_test7))\n",
        "rmse_approx_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.6599162825175136\t 0.6529031062312245\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.6529031062312245\t 0.6529031062312245\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.7849988476524127\t 0.6529031062312245\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7434573966703171\t 0.6529031062312245\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.6887936732176462\t 0.6529031062312245\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.8461730749178773\t 0.6529031062312245\t 0.28238594131635086\t 0.28238594131635086\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7280339284910606\t 0.6529031062312245\t 0.29230833350135155\t 0.29230833350135155\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.6571137209723783\t 0.6529031062312245\t 0.2920426828038876\t 0.2920426828038876\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7458231993222018\t 0.6529031062312245\t 0.288475661405999\t 0.288475661405999\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.7838758112536788\t 0.6529031062312245\t 0.2894968179396361\t 0.2894968179396361\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.6787899501779286\t 0.6529031062312245\t 0.29190243471954597\t 0.29190243471954597\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.8531322761504475\t 0.6529031062312245\t 0.29004729773479043\t 0.29004729773479043\n",
            "8  \t [ 1.95327375  0.09413692  7.          0.63967551 19.          0.52105045]\t 0.718715865573951\t 0.6529031062312245\t 0.2945675051414616\t 0.2945675051414616\n",
            "9  \t [5.70513125 8.30861013 6.         0.98680016 3.         0.16134411]\t 0.9984088714580504\t 0.6529031062312245\t 0.2939717784185071\t 0.2939717784185071\n",
            "10 \t [ 0.25030147  5.86047618  7.          0.62148035 15.          0.70956246]\t 0.7144935773647406\t 0.6529031062312245\t 0.3026196459448975\t 0.3026196459448975\n",
            "11 \t [ 6.35215     9.71205645 11.          0.67733044  6.          0.80174708]\t 0.6867359020307766\t 0.6529031062312245\t 0.3014797481335567\t 0.3014797427224536\n",
            "12 \t [9.93412004 7.01728008 6.         0.60790736 8.         0.46475011]\t 0.8183353504315909\t 0.6529031062312245\t 0.29983415882425574\t 0.29983415882425574\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.7792188999132433\t 0.6529031062312245\t 0.3014659924911099\t 0.3014659924911099\n",
            "14 \t [ 1.45077723  9.99574495  5.          0.58320457 19.          0.8020368 ]\t 0.7455249373416325\t 0.6529031062312245\t 0.3019957649237444\t 0.3019957649237444\n",
            "15 \t [ 0.30180848  0.36339665 10.          0.99951435 11.          0.54137142]\t 0.6900449537968393\t 0.6529031062312245\t 0.30175680408638517\t 0.30175680408638517\n",
            "16 \t [7.5058071  0.77198166 5.         0.94542975 7.         0.89710815]\t 0.7217956619874041\t 0.6529031062312245\t 0.3004887176703788\t 0.3004887176703788\n",
            "17 \t [ 0.08258912  2.04682383 12.          0.59206459 18.          0.58057909]\t 0.6960149194291863\t 0.6529031062312245\t 0.29990370960741175\t 0.29990370960741175\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.6910349298616485\t 0.6529031062312245\t 0.2989289722791582\t 0.29892897226854687\n",
            "19 \t [ 8.02008913  6.8951761  13.          0.63880909 19.          0.69330995]\t 0.6893407861836052\t 0.6529031062312245\t 0.29795597890264924\t 0.29795597890264924\n",
            "20 \t [ 9.02606866  9.9399456   5.          0.69325176 13.          0.80731892]\t 0.7457716132538541\t 0.6529031062312245\t 0.2970351821313311\t 0.2970351821313311\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7015179019308584\t 0.6529031062312245\t 0.29705458549970937\t 0.29705458549970937\n",
            "22 \t [ 2.21548548  9.34072297 10.          0.96109934 13.          0.7636836 ]\t 0.6798017103904265\t 0.6529031062312245\t 0.29641188108505817\t 0.29641188108505817\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[ 1.10150879  4.93737158 13.          0.87840594  8.          0.95224738]\u001b[0m\t \u001b[1m\u001b[92m0.6467893306949126\u001b[0m\t \u001b[1m\u001b[92m0.6467893306949126\u001b[0m\t \u001b[1m\u001b[92m0.29551086922456277\u001b[0m\t \u001b[1m\u001b[92m0.29551086922456277\u001b[0m\n",
            "24 \t [ 8.17909255  8.95640578 13.          0.94174624  1.          0.89014148]\t 0.6509486270988182\t 0.6467893306949126\t 0.2942542528670737\t 0.2942542299543774\n",
            "25 \t [ 0.          6.83171588 15.          1.         12.28323693  0.1       ]\t 1.0027505156759997\t 0.6467893306949126\t 0.2931294252697439\t 0.29312937749092693\n",
            "26 \t [ 5.03032449  1.46993678 12.          0.54826603 16.          0.88093043]\t 0.6584236565498969\t 0.6467893306949126\t 0.29731923726884624\t 0.29731923726884624\n",
            "27 \t [ 9.72265512  3.8270652  10.          0.71648686  6.          0.86209857]\t 0.6848726653905244\t 0.6467893306949126\t 0.29626036110382276\t 0.2962602293591251\n",
            "28 \t [ 5.50533402  5.98134311 11.          0.606747    9.          0.23402402]\t 0.993933313945832\t 0.6467893306949126\t 0.2955722491466663\t 0.2955722491466663\n",
            "29 \t [ 9.92745389  2.10791379  6.          0.91867901 19.          0.37494465]\t 0.8675172360459502\t 0.6467893306949126\t 0.2991320999868795\t 0.2991320999868795\n",
            "30 \t [1.66779279 0.54723135 6.         0.82307279 8.         0.95931183]\t 0.6973128000849222\t 0.6467893306949126\t 0.30061791871480287\t 0.30061791871480287\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49673.760083321315"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1312e332-551a-410f-e10f-56cc3917d2c3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_approx_8 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_8 = GPGO_multi(surrogate_approx_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "approx_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_8 = approx_8.getResult()[0]\n",
        "params_approx_8['max_depth'] = int(params_approx_8['max_depth'])\n",
        "params_approx_8['min_child_weight'] = int(params_approx_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_approx_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_approx_8 = xgb.train(params_approx_8, dX_approx_train8)\n",
        "pred_approx_8 = model_approx_8.predict(dX_approx_test8)\n",
        "\n",
        "rmse_approx_8 = np.sqrt(mean_squared_error(pred_approx_8, y_test8))\n",
        "rmse_approx_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.8097437093843076\t 0.6653168057229354\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.676783388491471\t 0.6653168057229354\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8290150461838799\t 0.6653168057229354\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.704280612172438\t 0.6653168057229354\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.6653168057229354\t 0.6653168057229354\t    \t    \n",
            "1  \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\t 0.6939807861210728\t 0.6653168057229354\t 0.29530598409939274\t 0.29530598409939274\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8292448989696929\t 0.6653168057229354\t 0.2923121719696599\t 0.2923121719696599\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7238654894117781\t 0.6653168057229354\t 0.29811811123180404\t 0.29811811123180404\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8298868503374536\t 0.6653168057229354\t 0.2969669775234298\t 0.2969669775234298\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7298305735353544\t 0.6653168057229354\t 0.30094796238754046\t 0.30094796238754046\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.6713374162855336\t 0.6653168057229354\t 0.29998355795660303\t 0.29998355795660303\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8412489648220683\t 0.6653168057229354\t 0.2972038616621777\t 0.2972038616621777\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8281572228887775\t 0.6653168057229354\t 0.3005918394082364\t 0.3005918394082364\n",
            "9  \t [ 0.45485069  5.92046568 13.          0.54575641 15.          0.3753516 ]\t 0.8133506998200086\t 0.6653168057229354\t 0.3029878039354719\t 0.3029878035142273\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.6700820921354065\t 0.6653168057229354\t 0.3045732553571228\t 0.3045732553479406\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8403741678101049\t 0.6653168057229354\t 0.302232843369809\t 0.302232843369809\n",
            "12 \t [3.47378168 0.90493309 7.         0.70332668 6.         0.717685  ]\t 0.7108804508392579\t 0.6653168057229354\t 0.3044020940742175\t 0.3044020940742175\n",
            "13 \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]\t 0.9373386140641772\t 0.6653168057229354\t 0.30321796558308517\t 0.30321796558308517\n",
            "14 \t [1.36072521 8.96337054 5.         0.74382165 2.         0.12580076]\t 0.9379435984221122\t 0.6653168057229354\t 0.3075741779230177\t 0.3075741779230177\n",
            "15 \t [ 3.32794564  9.35873285 13.          0.95404271 12.          0.46503428]\t 0.8057168013419183\t 0.6653168057229354\t 0.3114353097566187\t 0.31143527494479334\n",
            "16 \t [ 6.35979139  1.00897047 10.          0.55338934  9.          0.8992107 ]\t 0.6742016407056493\t 0.6653168057229354\t 0.3119429398780463\t 0.31194258874732356\n",
            "17 \t [0.26711089 1.47965823 5.         0.94483199 1.         0.67844469]\t 0.7386069861707144\t 0.6653168057229354\t 0.3100316208646036\t 0.31003162085226976\n",
            "18 \t [ 8.81884199  0.29557486 11.          0.94612367  2.          0.80082225]\t 0.6729826219675135\t 0.6653168057229354\t 0.30934960922213955\t 0.30934960922213955\n",
            "19 \t [ 4.10272358  0.68972827 14.          0.96902802  1.          0.19814279]\t 0.9303071311772037\t 0.6653168057229354\t 0.30768555981084295\t 0.30768555981084295\n",
            "20 \t [ 1.37842187  7.92618907 14.          0.53493538  2.          0.9994541 ]\t 0.6778496323948628\t 0.6653168057229354\t 0.31058832358309996\t 0.31058832358309996\n",
            "21 \t [ 2.33741522  1.6087129  12.51633022  0.67402188 20.          0.1       ]\t 0.9303294555928596\t 0.6653168057229354\t 0.3090819606529612\t 0.309081971909157\n",
            "22 \t [ 0.76637948  1.6718521   5.          0.89180884 15.          0.76035097]\t 0.7285188069721016\t 0.6653168057229354\t 0.31169774587528287\t 0.3116977458752753\n",
            "23 \t [9.0548994  9.22699073 6.         0.81952407 4.         0.89275019]\t 0.7048213880431081\t 0.6653168057229354\t 0.3109431238447433\t 0.3109431238447433\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]\u001b[0m\t \u001b[1m\u001b[92m0.6652912380850803\u001b[0m\t \u001b[1m\u001b[92m0.6652912380850803\u001b[0m\t \u001b[1m\u001b[92m0.3099294904832722\u001b[0m\t \u001b[1m\u001b[92m0.30992939155109034\u001b[0m\n",
            "25 \t [ 9.9367659   8.11161883 14.          0.64229002 15.          0.71963352]\t 0.6946799358952597\t 0.6652912380850803\t 0.30850115825613744\t 0.30850115825613744\n",
            "26 \t [10.          6.2936694   5.          1.         11.32943149  0.1       ]\t 0.9653061246881615\t 0.6652912380850803\t 0.3075072933779228\t 0.30750721210412396\n",
            "27 \t [ 5.77641842  4.40719497 14.          0.58387887 10.          0.77626915]\t 0.6804450182630599\t 0.6652912380850803\t 0.31031349468010483\t 0.31031349468010483\n",
            "28 \t [ 1.06330602  9.84698732  5.          0.70744161 15.          0.6986094 ]\t 0.7398934603464837\t 0.6652912380850803\t 0.3091731857328608\t 0.3091731857328608\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.699572467500549\t 0.6652912380850803\t 0.3087583250770913\t 0.3087583250770913\n",
            "30 \t [ 6.56126126  1.25177273  5.          0.60554055 11.          0.89113205]\t 0.7253897845864579\t 0.6652912380850803\t 0.3078881733746952\t 0.30788800314474835\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52609.47902158823"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39ffedb-9842-4e45-9e72-9a55938b37ed"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_approx_9 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_9 = GPGO_multi(surrogate_approx_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "approx_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_9 = approx_9.getResult()[0]\n",
        "params_approx_9['max_depth'] = int(params_approx_9['max_depth'])\n",
        "params_approx_9['min_child_weight'] = int(params_approx_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_approx_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_approx_9 = xgb.train(params_approx_9, dX_approx_train9)\n",
        "pred_approx_9 = model_approx_9.predict(dX_approx_test9)\n",
        "\n",
        "rmse_approx_9 = np.sqrt(mean_squared_error(pred_approx_9, y_test9))\n",
        "rmse_approx_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 0.8449026536729003\t 0.6448358819228919\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 0.8430936233516066\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.6448358819228919\t 0.6448358819228919\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.7455250925664565\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.6542440322310401\t 0.6448358819228919\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.0516333409565926\t 0.6448358819228919\t 0.29983497120862285\t 0.29983497120862285\n",
            "2  \t [9.23885705 0.0495141  9.         0.5847098  7.         0.79832927]\t 0.6774051522557019\t 0.6448358819228919\t 0.3228827814144945\t 0.3228827814144945\n",
            "3  \t [ 3.67545472  4.78145311 14.          0.63123486 17.          0.4863889 ]\t 0.7930932442681178\t 0.6448358819228919\t 0.3159006125887972\t 0.3159006125887972\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.7396199848029671\t 0.6448358819228919\t 0.3159628745833061\t 0.3159628745833061\n",
            "5  \t [ 1.86381009  9.16177979  5.          0.9344438  17.          0.81379931]\t 0.7377720407232845\t 0.6448358819228919\t 0.313709717356761\t 0.31370971735676095\n",
            "6  \t [ 2.35563756  1.41309797  5.          0.61127581 14.          0.85229383]\t 0.7381603779527465\t 0.6448358819228919\t 0.31182577312452525\t 0.31182577312452525\n",
            "7  \t [ 0.65024006  0.20015298 14.          0.90298726 13.          0.95798937]\t 0.6479585144859159\t 0.6448358819228919\t 0.3102892818820712\t 0.3102892818820712\n",
            "8  \t [ 9.89935012  1.80411649  9.          0.642097   16.          0.9768379 ]\t 0.6624923928604278\t 0.6448358819228919\t 0.30630798772359025\t 0.30630798772061973\n",
            "9  \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]\t 0.788150408197674\t 0.6448358819228919\t 0.3032829991627532\t 0.3032829991627532\n",
            "10 \t [ 8.9317907   9.240006   13.          0.55531212  4.          0.42887515]\t 0.8067241228581707\t 0.6448358819228919\t 0.3040924717894431\t 0.304092471789443\n",
            "11 \t [2.63920029 2.84662126 8.         0.81372528 9.         0.70958016]\t 0.7107155274108488\t 0.6448358819228919\t 0.30530758749566733\t 0.30530758749566733\n",
            "12 \t [1.13081555 8.89608809 5.         0.68242063 1.         0.25767085]\t 0.8508904111239197\t 0.6448358819228919\t 0.30399241739176874\t 0.3039924173917687\n",
            "13 \t [ 8.01493798  7.33950965 10.          0.50609192 18.          0.9957267 ]\t 0.6703192470045024\t 0.6448358819228919\t 0.3061922439546144\t 0.3061922439546144\n",
            "14 \t [ 8.08392893  1.91862949 14.          0.6384648  17.          0.1890016 ]\t 1.0461857744698733\t 0.6448358819228919\t 0.304167832291185\t 0.3041678249286556\n",
            "15 \t [9.88943457 8.53804591 8.         0.65243257 7.         0.28069664]\t 0.8352977818443392\t 0.6448358819228919\t 0.311154160780131\t 0.311154160780131\n",
            "16 \t [ 3.66353781  7.3371628  13.          0.91928424 11.          0.42437688]\t 0.78680708804053\t 0.6448358819228919\t 0.3122952922843894\t 0.31229528777926346\n",
            "17 \t [ 1.01403007  4.17086177  6.          0.95687904 19.          0.93022379]\t 0.6958192358474726\t 0.6448358819228919\t 0.312371415660397\t 0.31237140742937863\n",
            "18 \t [ 9.00084206  1.85673124 10.          0.98011614  2.          0.25530052]\t 0.83279328574821\t 0.6448358819228919\t 0.3108749813871983\t 0.3108749813871983\n",
            "19 \t [2.39281114 8.24027537 6.         0.62412974 6.         0.7547697 ]\t 0.7107399222825\t 0.6448358819228919\t 0.31183416171741746\t 0.31183416171741746\n",
            "20 \t [ 5.06569568  9.95512019 10.          0.79200421  8.          0.9497448 ]\t 0.6524837713585139\t 0.6448358819228919\t 0.3107068699515938\t 0.3107068699515938\n",
            "21 \t [ 4.2953213   0.27911896 10.          0.9783586  19.          0.46300401]\t 0.7860315206098012\t 0.6448358819228919\t 0.3088486861901497\t 0.30884868617062683\n",
            "22 \t [5.69641029 8.40739134 9.         0.78375397 1.         0.13665985]\t 1.0469513005500544\t 0.6448358819228919\t 0.30903203790045003\t 0.30903203790045003\n",
            "23 \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]\t 0.8491103282876022\t 0.6448358819228919\t 0.3137273941961043\t 0.3137273941961043\n",
            "24 \t [1.76701563 1.7346788  7.         0.94361827 2.         0.93288306]\t 0.6754110020522134\t 0.6448358819228919\t 0.31465517893033196\t 0.31465517893033196\n",
            "25 \t [ 9.01552706  3.25572905  5.          0.56123527 16.          0.5672937 ]\t 0.797912270059593\t 0.6448358819228919\t 0.31320500979360155\t 0.3132050095287529\n",
            "26 \t [4.86659604 3.67943735 9.         0.97224139 1.         0.90536162]\t 0.6576745506297413\t 0.6448358819228919\t 0.3133768837636369\t 0.3133768826257385\n",
            "27 \t [ 0.45983101  9.28402862 13.          0.52786561  6.          0.42783681]\t 0.8036069849990609\t 0.6448358819228919\t 0.3118610629900297\t 0.3118610629900297\n",
            "28 \t [7.20425099 1.56266186 5.         0.88211354 9.         0.78887069]\t 0.7368960706458181\t 0.6448358819228919\t 0.31213838795145443\t 0.31213838795145443\n",
            "29 \t [3.08321869 0.87587118 5.         0.75683721 6.         0.32966687]\t 0.8525276760004173\t 0.6448358819228919\t 0.3116035123048183\t 0.3116035123048183\n",
            "30 \t [ 6.14078962  2.31372054 11.          0.9240952  13.          0.361681  ]\t 0.8314074749252223\t 0.6448358819228919\t 0.3124792019604592\t 0.3124792019604592\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48075.00995818073"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1150271-9b84-4aa0-a754-237e741dcdbd"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_approx_10 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_10 = GPGO_multi(surrogate_approx_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "approx_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_10 = approx_10.getResult()[0]\n",
        "params_approx_10['max_depth'] = int(params_approx_10['max_depth'])\n",
        "params_approx_10['min_child_weight'] = int(params_approx_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_approx_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_approx_10 = xgb.train(params_approx_10, dX_approx_train10)\n",
        "pred_approx_10 = model_approx_10.predict(dX_approx_test10)\n",
        "\n",
        "rmse_approx_10 = np.sqrt(mean_squared_error(pred_approx_10, y_test10))\n",
        "rmse_approx_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 0.8785010703819621\t 0.6669292375133978\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.6669292375133978\t 0.6669292375133978\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7012460140601039\t 0.6669292375133978\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7005965853529538\t 0.6669292375133978\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 0.880412005930048\t 0.6669292375133978\t    \t    \n",
            "1  \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\t 0.6770142260932797\t 0.6669292375133978\t 0.3076911021312796\t 0.3076911021312796\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.7417959722875219\t 0.6669292375133978\t 0.30174974776897906\t 0.30174974776897906\n",
            "3  \t [1.0517383  0.29626986 6.         0.71496305 2.         0.21703638]\t 0.8792946548244501\t 0.6669292375133978\t 0.30092577760604944\t 0.30092577760604944\n",
            "4  \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\t 0.7006385046040607\t 0.6669292375133978\t 0.30760086874051396\t 0.30760086874051396\n",
            "5  \t [ 2.36407072  4.99081503 14.          0.6287111   1.          0.46714602]\t 0.7578758817373941\t 0.6669292375133978\t 0.3046080437237625\t 0.30460804372376243\n",
            "6  \t [ 9.8195229   7.4353827   6.          0.61370759 10.          0.85798549]\t 0.7015549121482302\t 0.6669292375133978\t 0.30438287130407826\t 0.30438287130407826\n",
            "7  \t [8.82521763 9.96779345 8.         0.82356907 1.         0.3598298 ]\t 0.8142907394883079\t 0.6669292375133978\t 0.30223739971739505\t 0.3022373997173792\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7069523757910561\t 0.6669292375133978\t 0.30418646429240503\t 0.30418646429240503\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\u001b[0m\t \u001b[1m\u001b[92m0.661096368919013\u001b[0m\t \u001b[1m\u001b[92m0.661096368919013\u001b[0m\t \u001b[1m\u001b[92m0.30253996852546494\u001b[0m\t \u001b[1m\u001b[92m0.30253996852546494\u001b[0m\n",
            "10 \t [ 9.32751793  9.16094516  5.          0.70577301 16.          0.29580142]\t 0.8234668645210068\t 0.661096368919013\t 0.2999349509370068\t 0.2999349505525206\n",
            "11 \t [5.00762913 1.53619492 9.         0.56892944 8.         0.96567366]\t 0.662454600529182\t 0.661096368919013\t 0.3019245522048662\t 0.30192455218126046\n",
            "12 \t [ 2.40528406  7.71427622 14.          0.55203588 14.          0.3470708 ]\t 0.8154596077767258\t 0.661096368919013\t 0.2997103842444435\t 0.2997103842444435\n",
            "13 \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]\t 0.823119322181516\t 0.661096368919013\t 0.3012761659150957\t 0.3012761659150957\n",
            "14 \t [ 0.2734411   0.20947276 13.          0.89386904  7.          0.27558279]\t 0.8166474442456968\t 0.661096368919013\t 0.3028463531088843\t 0.3028463531088843\n",
            "15 \t [ 9.86913094  2.54287696 14.          0.86051843  2.          0.74044264]\t 0.6976866250322032\t 0.661096368919013\t 0.30409747969349404\t 0.30409747969349404\n",
            "16 \t [ 3.32064678  9.82322091 10.          0.61729748  2.          0.52189899]\t 0.7141379767240427\t 0.661096368919013\t 0.3028613657640817\t 0.30286135383103885\n",
            "17 \t [ 4.63020556  1.51436379 11.          0.68034517  2.          0.42766971]\t 0.7486371706886035\t 0.661096368919013\t 0.302030356733612\t 0.302030345523618\n",
            "18 \t [ 3.35903512  5.65946459  5.          0.99895528 10.          0.94028903]\t 0.7198633628577074\t 0.661096368919013\t 0.3018780732447876\t 0.3018780732447876\n",
            "19 \t [ 7.82641344  8.43235645 13.          0.61872216  7.          0.69024191]\t 0.6971262650078873\t 0.661096368919013\t 0.30125409279327564\t 0.301254092523207\n",
            "20 \t [0.02696897 2.95683802 6.         0.66811128 8.         0.42238237]\t 0.7521884028688212\t 0.661096368919013\t 0.30032474776934126\t 0.30032426979131216\n",
            "21 \t [ 4.83476746  0.         14.47637417  0.5         9.50099038  0.68020794]\t 0.6986600858966655\t 0.661096368919013\t 0.30031550913898575\t 0.3003154386484532\n",
            "22 \t [ 6.19948038  6.36838188  8.          0.76805564 19.          0.53627741]\t 0.711941213153515\t 0.661096368919013\t 0.29951404384776437\t 0.29951404384765623\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[ 6.89824313  6.43931113 11.          0.60707962 11.          0.89509759]\u001b[0m\t \u001b[1m\u001b[92m0.6539666670983036\u001b[0m\t \u001b[1m\u001b[92m0.6539666670983036\u001b[0m\t \u001b[1m\u001b[92m0.2989546264732688\u001b[0m\t \u001b[1m\u001b[92m0.2989546264732688\u001b[0m\n",
            "24 \t [ 4.11986688  9.81320751 11.          0.98131964 17.          0.2975892 ]\t 0.81020927033387\t 0.6539666670983036\t 0.297679151747625\t 0.29767915174761433\n",
            "25 \t [10.          4.99834805 15.          1.         14.2836694   0.1       ]\t 1.0570663513022178\t 0.6539666670983036\t 0.29859646715266897\t 0.29859637763717667\n",
            "26 \t [ 9.76455747  9.71578983 14.          0.66293675 18.          0.1137209 ]\t 0.881723986870453\t 0.6539666670983036\t 0.3035057995651431\t 0.3035057995651431\n",
            "27 \t [0.73638155 5.44724197 9.         0.90159859 3.         0.84981348]\t 0.6619468807381774\t 0.6539666670983036\t 0.3051814423388704\t 0.3051814423388704\n",
            "28 \t [ 0.          7.60398639 12.92847211  1.         20.          0.1       ]\t 1.056999794347736\t 0.6539666670983036\t 0.30398072158391926\t 0.30398083071554904\n",
            "29 \t [ 6.16349263  8.99102846 14.          0.6618501   2.          0.7403865 ]\t 0.7025994843252346\t 0.6539666670983036\t 0.3082086843295108\t 0.3082086843295108\n",
            "30 \t [ 1.15143775  1.44003305  5.          0.55411367 14.          0.81935679]\t 0.7257754398445894\t 0.6539666670983036\t 0.3074241399891715\t 0.3074241399891715\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51146.96955017311"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbbbfa8-45bf-4a21-d5df-02b73759e7b5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_approx_11 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_11 = GPGO_multi(surrogate_approx_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "approx_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_11 = approx_11.getResult()[0]\n",
        "params_approx_11['max_depth'] = int(params_approx_11['max_depth'])\n",
        "params_approx_11['min_child_weight'] = int(params_approx_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_approx_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_approx_11 = xgb.train(params_approx_11, dX_approx_train11)\n",
        "pred_approx_11 = model_approx_11.predict(dX_approx_test11)\n",
        "\n",
        "rmse_approx_11 = np.sqrt(mean_squared_error(pred_approx_11, y_test11))\n",
        "rmse_approx_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.7904007286371394\t 0.6894069737354023\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.727634308123781\t 0.6894069737354023\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.6894069737354023\t 0.6894069737354023\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7071657410132528\t 0.6894069737354023\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7012825433030343\t 0.6894069737354023\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.711031226877882\t 0.6894069737354023\t 0.2885980345291438\t 0.2885980345291438\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.2877808915237221\u001b[0m\t \u001b[1m\u001b[92m0.2877808915237221\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7648729702018928\t 0.6577294425265764\t 0.284293322185048\t 0.284293322185048\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 0.9235319432135773\t 0.6577294425265764\t 0.2869820646132957\t 0.2869820646132957\n",
            "5  \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]\t 0.7883201967902798\t 0.6577294425265764\t 0.2971371601629244\t 0.2971371601629244\n",
            "6  \t [ 3.67323902  7.86608025  9.          0.6017103  12.          0.8976084 ]\t 0.6646588413956347\t 0.6577294425265764\t 0.298918226731636\t 0.2989182267292521\n",
            "7  \t [ 8.8168337   8.37959662 14.          0.86429866 15.          0.72516241]\t 0.6892145672079726\t 0.6577294425265764\t 0.29600846867923913\t 0.29600846867923913\n",
            "8  \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]\t 0.8743477887688297\t 0.6577294425265764\t 0.2944187644237174\t 0.2944187644237174\n",
            "9  \t [ 4.65266155  1.51144578 13.          0.9981878   8.          0.76538736]\t 0.6852941374864567\t 0.6577294425265764\t 0.2988572871512654\t 0.2988572871512654\n",
            "10 \t [ 9.96434657  9.7457538   7.          0.51716335 13.          0.80468719]\t 0.7098807101273504\t 0.6577294425265764\t 0.29720171193058115\t 0.29720171193058115\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.8864529961319944\t 0.6577294425265764\t 0.2962037583556379\t 0.2962037583556379\n",
            "12 \t [ 8.75969772  9.81259093 13.          0.73915202  9.          0.12048735]\t 0.9231023673501877\t 0.6577294425265764\t 0.30011599793431737\t 0.30011599793431737\n",
            "13 \t [ 3.07772231  9.36080815 12.          0.63816578 18.          0.13286747]\t 0.9234149203761113\t 0.6577294425265764\t 0.3046176669995411\t 0.3046176669995411\n",
            "14 \t [ 8.71522337  2.64896453  8.          0.8880663  13.          0.19932467]\t 0.9228060288203824\t 0.6577294425265764\t 0.3084407744452076\t 0.30844073904674135\n",
            "15 \t [0.61700864 1.88368662 5.         0.7080512  1.         0.20173876]\t 0.9297173774466645\t 0.6577294425265764\t 0.3118682933159554\t 0.3118682933159554\n",
            "16 \t [ 4.54549823  8.84141407 12.          0.50940273  3.          0.75742975]\t 0.7068100593711837\t 0.6577294425265764\t 0.31508287011433517\t 0.31508287011433517\n",
            "17 \t [4.68258101 8.96288202 5.         0.97630328 6.         0.39227084]\t 0.8031528445623343\t 0.6577294425265764\t 0.3135856144590761\t 0.3135856144590761\n",
            "18 \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]\t 0.698358780864823\t 0.6577294425265764\t 0.3139539515057154\t 0.3139539515057154\n",
            "19 \t [ 8.3684965   4.27856165  5.          0.69634244 18.1077127   1.        ]\t 0.7143993788447425\t 0.6577294425265764\t 0.3124472009149815\t 0.3124474591379392\n",
            "\u001b[1m\u001b[92m20\u001b[0m\t \u001b[1m\u001b[92m[10.          7.02451722 11.63306687  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6386949133518321\u001b[0m\t \u001b[1m\u001b[92m0.6386949133518321\u001b[0m\t \u001b[1m\u001b[92m0.31135226267188276\u001b[0m\t \u001b[1m\u001b[92m0.31135231233886346\u001b[0m\n",
            "21 \t [ 4.20382838  8.11840794 14.          0.97060995 11.          0.52636944]\t 0.7250537141107671\t 0.6386949133518321\t 0.30933787985121897\t 0.30933787985121897\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7286740032592812\t 0.6386949133518321\t 0.30858967299544815\t 0.30858967299544815\n",
            "23 \t [ 9.97716226  3.28825714 13.          0.55185778 13.          0.23012169]\t 0.9247048172921157\t 0.6386949133518321\t 0.3079456150667225\t 0.3079456150667225\n",
            "24 \t [9.06829377 8.93961606 6.         0.58229519 2.         0.64167434]\t 0.7207061667898202\t 0.6386949133518321\t 0.3103288493370487\t 0.3103288493370487\n",
            "25 \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]\t 0.9247656684808231\t 0.6386949133518321\t 0.3095271763628526\t 0.3095271763628526\n",
            "26 \t [1.36500216 0.         5.         0.5        6.63683211 1.        ]\t 0.7205170559318953\t 0.6386949133518321\t 0.3116879726259977\t 0.3116896619110335\n",
            "27 \t [ 0.          4.68690021  5.99439558  0.68488768 11.67542907  0.50799326]\t 0.7645046331605979\t 0.6386949133518321\t 0.31093703981229487\t 0.31093569223839235\n",
            "28 \t [0.17914108 0.38366975 9.84039055 0.68959197 7.08891683 0.89257373]\t 0.6600160394305483\t 0.6386949133518321\t 0.31075159169125893\t 0.31075180116665746\n",
            "29 \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]\t 0.6600116767225708\t 0.6386949133518321\t 0.3094218515651463\t 0.3094218515651463\n",
            "30 \t [4.8041921  4.06620309 5.         0.94317975 9.         0.20395595]\t 0.93061105311828\t 0.6386949133518321\t 0.3081634267015754\t 0.3081634267015754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50156.32060074565"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d589f852-2e4a-4009-dfb8-4ca611b09474"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_approx_12 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_12 = GPGO_multi(surrogate_approx_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "approx_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_12 = approx_12.getResult()[0]\n",
        "params_approx_12['max_depth'] = int(params_approx_12['max_depth'])\n",
        "params_approx_12['min_child_weight'] = int(params_approx_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_approx_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_approx_12 = xgb.train(params_approx_12, dX_approx_train12)\n",
        "pred_approx_12 = model_approx_12.predict(dX_approx_test12)\n",
        "\n",
        "rmse_approx_12 = np.sqrt(mean_squared_error(pred_approx_12, y_test12))\n",
        "rmse_approx_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.9314271055202143\t 0.7056203424268611\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.7910532936167305\t 0.7056203424268611\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.7196830962696428\t 0.7056203424268611\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7056203424268611\t 0.7056203424268611\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.8082458628311272\t 0.7056203424268611\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.74699493326549\t 0.7056203424268611\t 0.3172746473679078\t 0.3172746473679078\n",
            "2  \t [ 7.57473716  9.63637997 12.          0.83444517 10.          0.18761713]\t 0.9247498596892157\t 0.7056203424268611\t 0.3141455540294768\t 0.3141455540294768\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 9.04517621  0.80881017 13.          0.96890904  5.          0.75400021]\u001b[0m\t \u001b[1m\u001b[92m0.6897808103544698\u001b[0m\t \u001b[1m\u001b[92m0.6897808103544698\u001b[0m\t \u001b[1m\u001b[92m0.3216328226487935\u001b[0m\t \u001b[1m\u001b[92m0.3216328226487935\u001b[0m\n",
            "4  \t [ 2.73241117  0.55778587 14.          0.70282167 15.          0.8966204 ]\t 0.6967406870158588\t 0.6897808103544698\t 0.31620001735515724\t 0.31620001735515724\n",
            "5  \t [ 6.66970674  0.03985694  6.          0.76922453 11.          0.18327615]\t 0.9302409127927834\t 0.6897808103544698\t 0.3121823950417558\t 0.3121823950417558\n",
            "6  \t [ 1.23389285  0.85357459 13.          0.93854198  3.          0.52598214]\t 0.7221002132069921\t 0.6897808103544698\t 0.31856653093512055\t 0.31856653093512055\n",
            "7  \t [ 0.57203639  5.0857779   9.          0.68290949 10.          0.94408458]\t 0.7012842559435354\t 0.6897808103544698\t 0.31591612992890716\t 0.31591612992890716\n",
            "8  \t [ 9.11635581  9.60013795  5.          0.57034236 14.          0.41758327]\t 0.8017323350323444\t 0.6897808103544698\t 0.31306353974511414\t 0.3130635397361659\n",
            "9  \t [9.77568711 0.70796585 6.         0.73327465 3.         0.82051057]\t 0.7213506404912987\t 0.6897808103544698\t 0.3135903887326894\t 0.3135903887326894\n",
            "10 \t [ 0.14475494  9.8292754  12.          0.60331385  2.          0.9622215 ]\t 0.7073584311311387\t 0.6897808103544698\t 0.31181749762353655\t 0.31181749762353655\n",
            "11 \t [ 3.24107348  8.27034509 14.          0.92485614 16.          0.53812048]\t 0.7151360298031719\t 0.6897808103544698\t 0.30993075307890844\t 0.30993075307890844\n",
            "12 \t [ 7.55307662  2.76896497 12.          0.93049335 17.          0.33736097]\t 0.7889723938717788\t 0.6897808103544698\t 0.3084488212901142\t 0.3084488212901142\n",
            "13 \t [ 0.04787228  7.48596331  8.          0.52068382 16.          0.7086396 ]\t 0.7110240148871393\t 0.6897808103544698\t 0.3088233213600003\t 0.308823320036215\n",
            "14 \t [4.27099049 1.84437193 8.         0.60505752 3.         0.28835442]\t 0.7946180236578642\t 0.6897808103544698\t 0.30747927942413805\t 0.3074792659258086\n",
            "15 \t [ 5.00288594  8.63257736  7.          0.63451109 10.          0.4931163 ]\t 0.779054992813269\t 0.6897808103544698\t 0.30798805905658655\t 0.30798801717757796\n",
            "16 \t [ 0.77892218  8.99624404 13.          0.66723238  9.          0.47803353]\t 0.7775062665234967\t 0.6897808103544698\t 0.30812915588121914\t 0.30812912613890414\n",
            "17 \t [ 8.92040797  9.99421763 13.          0.88657464 18.          0.32294618]\t 0.7893524262985254\t 0.6897808103544698\t 0.3082271623585622\t 0.3082271623585622\n",
            "18 \t [0.22904635 0.         5.         1.         1.         1.        ]\t 0.7206578292363397\t 0.6897808103544698\t 0.3085338435949521\t 0.30853383305948595\n",
            "19 \t [0.64518061 0.         5.         0.5        9.95208378 0.1       ]\t 0.9369718830296223\t 0.6897808103544698\t 0.30764913001076677\t 0.30764927165101424\n",
            "20 \t [ 9.98175567  0.8705802   6.          0.55210219 18.          0.50471737]\t 0.7496479603542527\t 0.6897808103544698\t 0.31068680103286095\t 0.31068680103286095\n",
            "21 \t [ 6.26649824  4.98006493 14.          0.7181208   9.          0.25218732]\t 0.7937968861807033\t 0.6897808103544698\t 0.31022982876225796\t 0.3102297967625514\n",
            "22 \t [ 9.7033379   2.67148283  8.46196228  1.         13.39746882  0.57267886]\t 0.7580274435394726\t 0.6897808103544698\t 0.31048025036412896\t 0.31048025447285327\n",
            "23 \t [9.99675486 4.75786893 6.         0.97752073 8.         0.29304564]\t 0.7994526461935878\t 0.6897808103544698\t 0.3101848517089998\t 0.31018434123157584\n",
            "24 \t [ 1.47973338  1.45058818 11.          0.74181509 19.          0.60410465]\t 0.7209141390650076\t 0.6897808103544698\t 0.3105020478664935\t 0.3105019129949485\n",
            "25 \t [ 3.96205991  9.89622107  8.          0.50097572 19.          0.66768637]\t 0.7123539047313558\t 0.6897808103544698\t 0.30974071535869424\t 0.30974071535869424\n",
            "26 \t [8.97886962 5.1990592  8.         0.6115526  3.         0.92989751]\t 0.7062171777812216\t 0.6897808103544698\t 0.30914400455783214\t 0.30914400455783214\n",
            "27 \t [0.         0.18504574 9.80779861 0.84597658 8.37970343 0.19941488]\t 0.9247997228652837\t 0.6897808103544698\t 0.30808231992111174\t 0.3080823795943189\n",
            "28 \t [ 9.13327668  0.92433654 12.          0.91412474 10.          0.85058075]\t 0.6905450567206979\t 0.6897808103544698\t 0.31037219050880854\t 0.31037219050880854\n",
            "29 \t [ 3.8544074   5.22723842 10.          0.76354194  1.          0.13710805]\t 0.927143786270312\t 0.6897808103544698\t 0.3093732377266837\t 0.3093732377266837\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[10.          6.68068328  8.20444873  0.85551381 17.05151847  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.669942278916295\u001b[0m\t \u001b[1m\u001b[92m0.669942278916295\u001b[0m\t \u001b[1m\u001b[92m0.31112531617404793\u001b[0m\t \u001b[1m\u001b[92m0.3111247037725076\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52965.47556879547"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22778dd6-6143-46e3-d77c-9820ff2165ba"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_approx_13 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_13 = GPGO_multi(surrogate_approx_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "approx_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_13 = approx_13.getResult()[0]\n",
        "params_approx_13['max_depth'] = int(params_approx_13['max_depth'])\n",
        "params_approx_13['min_child_weight'] = int(params_approx_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_approx_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_approx_13 = xgb.train(params_approx_13, dX_approx_train13)\n",
        "pred_approx_13 = model_approx_13.predict(dX_approx_test13)\n",
        "\n",
        "rmse_approx_13 = np.sqrt(mean_squared_error(pred_approx_13, y_test13))\n",
        "rmse_approx_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.6628876451121497\t 0.6628876451121497\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1013657958154304\t 0.6628876451121497\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.92150734169971\t 0.6628876451121497\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.71924819784624\t 0.6628876451121497\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1014421616742969\t 0.6628876451121497\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7207240599672383\t 0.6628876451121497\t 0.3670299499203164\t 0.3670299499203164\n",
            "2  \t [6.93463528 1.25795731 8.         0.92695971 3.         0.9534311 ]\t 0.6734860180774931\t 0.6628876451121497\t 0.35501098834879774\t 0.35501098833341127\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7679544515659981\t 0.6628876451121497\t 0.3440022402793623\t 0.3440022402793623\n",
            "4  \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]\t 0.6797825903178236\t 0.6628876451121497\t 0.33953702485752457\t 0.33953702485752457\n",
            "5  \t [ 8.98888343  8.3187307  12.          0.8674744   2.          0.79321204]\t 0.6701335803019719\t 0.6628876451121497\t 0.3326374927661458\t 0.3326374927661458\n",
            "6  \t [ 1.86840748  0.75206083 14.          0.81141351 17.          0.47108772]\t 0.8190622083881806\t 0.6628876451121497\t 0.326695359200595\t 0.32669535919867104\n",
            "7  \t [ 6.50677714  2.64641451 14.          0.50110879 19.          0.46175841]\t 0.8250792636501453\t 0.6628876451121497\t 0.3267016500840003\t 0.3267016500840003\n",
            "8  \t [ 0.53852623  1.13078322 12.          0.85062386  1.          0.22708294]\t 1.1062273028353988\t 0.6628876451121497\t 0.32690708096705956\t 0.32690708096705956\n",
            "9  \t [9.82022331 2.48941517 7.         0.64964742 8.         0.44060186]\t 0.8227498001206589\t 0.6628876451121497\t 0.33708419657618677\t 0.33708419643377385\n",
            "10 \t [ 0.95213595  8.68324297 14.          0.57163216  8.          0.28130834]\t 0.9272758866528952\t 0.6628876451121497\t 0.33646462573237107\t 0.33646462573237107\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7370906275446215\t 0.6628876451121497\t 0.33879842213868827\t 0.33879842213868827\n",
            "12 \t [ 9.94337897  0.36950862  8.          0.73485109 19.          0.44537046]\t 0.8212415354789184\t 0.6628876451121497\t 0.3361760503082956\t 0.3361760503082956\n",
            "13 \t [ 0.65991354  4.66843968 10.          0.71271776  9.          0.9826504 ]\t 0.6689179423925529\t 0.6628876451121497\t 0.33567948120605656\t 0.3356794744201349\n",
            "14 \t [0.59196411 2.70489003 6.         0.53471064 2.         0.87047587]\t 0.71441968725325\t 0.6628876451121497\t 0.3322305827475091\t 0.3322305827475091\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.6686440552339279\t 0.6628876451121497\t 0.329914003136668\t 0.3299140031363726\n",
            "16 \t [8.21699236 8.94190125 6.         0.51556316 8.         0.7742198 ]\t 0.714863442644246\t 0.6628876451121497\t 0.32704568108143744\t 0.32704568108143744\n",
            "17 \t [7.55403251 6.23917493 5.         0.63649547 1.         0.75229567]\t 0.73633358340512\t 0.6628876451121497\t 0.3251746312005478\t 0.32517463119992884\n",
            "18 \t [ 2.91019341  6.38178397 14.          0.79652507  1.          0.10091662]\t 1.108112277749133\t 0.6628876451121497\t 0.32380936579164443\t 0.32380936571469854\n",
            "19 \t [ 8.70212257  9.22072414 13.          0.93050035 17.          0.7479803 ]\t 0.7016619838210264\t 0.6628876451121497\t 0.3298372560492399\t 0.3298372560492399\n",
            "20 \t [ 9.0456957   9.26794703  7.          0.55038469 16.          0.67260205]\t 0.7268029093905258\t 0.6628876451121497\t 0.32790922436240644\t 0.32790922436240644\n",
            "21 \t [ 8.79523185  3.72755126 14.          0.50499174  7.          0.18146663]\t 1.1073736151841609\t 0.6628876451121497\t 0.3264757084670013\t 0.3264757084670013\n",
            "22 \t [4.81500161 3.57381354 5.         0.94983462 6.         0.39427909]\t 0.8381958469988422\t 0.6628876451121497\t 0.3316524539708812\t 0.3316524539708812\n",
            "23 \t [ 2.05622909  9.08047387  8.          0.8397078  17.          0.73365999]\t 0.7124011319640049\t 0.6628876451121497\t 0.33175432143150774\t 0.33175432143150774\n",
            "24 \t [ 0.537802    3.33621713  8.          0.77943172 18.          0.5870313 ]\t 0.7295026676611162\t 0.6628876451121497\t 0.3301741480819133\t 0.3301741480804369\n",
            "25 \t [ 4.58851998  9.96722725 10.          0.86802391  9.          0.49712674]\t 0.8197897150933404\t 0.6628876451121497\t 0.3289018585574555\t 0.3289018585574555\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.672888499874982\t 0.6628876451121497\t 0.3288402701363348\t 0.3288402701363348\n",
            "27 \t [ 9.62074658  3.4145225   5.          0.72518542 14.          0.23325058]\t 1.0988532186443218\t 0.6628876451121497\t 0.32702708127540536\t 0.32702708127540536\n",
            "28 \t [ 5.21978638 10.          5.          0.5         4.13569498  1.        ]\t 0.723327127395539\t 0.6628876451121497\t 0.3310735887649902\t 0.3310732598789865\n",
            "29 \t [ 1.1665804   8.5178555  13.          0.63744653 19.          0.35989497]\t 0.9216009805623578\t 0.6628876451121497\t 0.3298664966182526\t 0.32986589396315524\n",
            "30 \t [0.43091775 0.3532639  5.         0.76123896 7.         0.49074528]\t 0.8387970949832267\t 0.6628876451121497\t 0.3310396214769479\t 0.3310396214769479\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49640.64566227302"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5568c0-523d-4bee-cff3-3364ebb8b8fe"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_approx_14 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_14 = GPGO_multi(surrogate_approx_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "approx_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_14 = approx_14.getResult()[0]\n",
        "params_approx_14['max_depth'] = int(params_approx_14['max_depth'])\n",
        "params_approx_14['min_child_weight'] = int(params_approx_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_approx_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_approx_14 = xgb.train(params_approx_14, dX_approx_train14)\n",
        "pred_approx_14 = model_approx_14.predict(dX_approx_test14)\n",
        "\n",
        "rmse_approx_14 = np.sqrt(mean_squared_error(pred_approx_14, y_test14))\n",
        "rmse_approx_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.8139066743222003\t 0.6747866005380063\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.6747866005380063\t 0.6747866005380063\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.977412427074478\t 0.6747866005380063\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.6774024187451972\t 0.6747866005380063\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 1.0197967308919336\t 0.6747866005380063\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 1.0126649561802825\t 0.6747866005380063\t 0.3371920067474154\t 0.3371920067474154\n",
            "2  \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]\t 0.9571856949825378\t 0.6747866005380063\t 0.34921565403432436\t 0.34921565403432436\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7245455903141328\t 0.6747866005380063\t 0.3540637697851143\t 0.3540637697851143\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 1.0111604668907606\t 0.6747866005380063\t 0.3466047642295713\t 0.3466047642295713\n",
            "5  \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]\t 0.9600990595782894\t 0.6747866005380063\t 0.3533633843706546\t 0.3533633843706546\n",
            "6  \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]\t 1.0131910395518218\t 0.6747866005380063\t 0.3564426623652536\t 0.3564426623652536\n",
            "7  \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]\t 0.7242608483603965\t 0.6747866005380063\t 0.3610457138170768\t 0.3610457138170749\n",
            "8  \t [ 0.63353879  9.61017877  8.          0.96421247 18.          0.39200727]\t 0.8087127953472528\t 0.6747866005380063\t 0.3555957833140526\t 0.3555957833140526\n",
            "9  \t [ 6.82711248  9.86843937 13.          0.52138031 17.          0.20003272]\t 1.0114628267773051\t 0.6747866005380063\t 0.353169215166696\t 0.353169215166696\n",
            "10 \t [ 8.90983817  2.82321414  7.          0.66164117 11.          0.64519606]\t 0.697395180788185\t 0.6747866005380063\t 0.35700089455234707\t 0.35700089455234707\n",
            "11 \t [ 9.30217735  6.23147787  8.          0.97503033 15.          0.52511943]\t 0.7234253694323725\t 0.6747866005380063\t 0.35229692076294067\t 0.35229692076294067\n",
            "12 \t [ 1.50285169  4.17593259 14.          0.69234646  6.          0.74044842]\t 0.677587403128438\t 0.6747866005380063\t 0.34865759408490254\t 0.34865759408490254\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.25039867  4.81148287 14.          0.83239345 15.          0.88911818]\u001b[0m\t \u001b[1m\u001b[92m0.6657241930879318\u001b[0m\t \u001b[1m\u001b[92m0.6657241930879318\u001b[0m\t \u001b[1m\u001b[92m0.3445428555263876\u001b[0m\t \u001b[1m\u001b[92m0.3445428555263876\u001b[0m\n",
            "14 \t [4.48522578 6.54261798 5.         0.79314226 1.         0.29945677]\t 0.9752292115331169\t 0.6657241930879318\t 0.3406367242758819\t 0.3406367242758819\n",
            "15 \t [ 1.13909448  9.99750981 12.          0.83097832  8.          0.96211319]\t 0.6681753308209242\t 0.6657241930879318\t 0.3433556923739936\t 0.3433556923739936\n",
            "16 \t [ 5.21920054  9.35580917 14.          0.81835368  4.          0.54800317]\t 0.7211586025861135\t 0.6657241930879318\t 0.3399247784287532\t 0.33992477812630845\n",
            "17 \t [ 4.83871117  1.89317253 13.          0.87688851 13.          0.10679344]\t 1.0126577425360461\t 0.6657241930879318\t 0.337624608756137\t 0.337624608756137\n",
            "18 \t [ 9.40706915  0.91600736 13.          0.648599    7.          0.62885715]\t 0.6782712913254569\t 0.6657241930879318\t 0.3409216831657883\t 0.3409216831657883\n",
            "19 \t [2.50634417 7.18764527 7.         0.74380288 7.         0.36061143]\t 0.9625602671963932\t 0.6657241930879318\t 0.33816811255713125\t 0.33816811255713125\n",
            "20 \t [2.03544962 0.82234782 9.         0.75192666 8.         0.57674562]\t 0.7214652120719057\t 0.6657241930879318\t 0.3402013105751152\t 0.3402013105751152\n",
            "21 \t [ 1.52900897  2.49551652 10.          0.74070159  3.          0.79386687]\t 0.6772839651254358\t 0.6657241930879318\t 0.33826197803278796\t 0.33826197803278796\n",
            "22 \t [7.76121524 5.62360915 8.0825544  0.7368122  7.53905344 0.1       ]\t 1.01217285665158\t 0.6657241930879318\t 0.3358987327291543\t 0.33589870863767113\n",
            "23 \t [10.          0.         11.99999383  1.          1.          0.1       ]\t 1.010041143772337\t 0.6657241930879318\t 0.3386568720142774\t 0.33865684859030465\n",
            "24 \t [ 6.55062625  9.63146322  5.          0.68406751 18.          0.23627226]\t 1.020688722409838\t 0.6657241930879318\t 0.3411616751774009\t 0.3411616751774009\n",
            "25 \t [ 6.71198965  0.7988094   6.          0.93755772 17.          0.83354732]\t 0.7109212151666767\t 0.6657241930879318\t 0.3436500169448487\t 0.3436500169448487\n",
            "26 \t [ 6.58726115  5.15136775 14.          0.85920414  6.          0.77914131]\t 0.6741930074515965\t 0.6657241930879318\t 0.34181862075237374\t 0.3418184852300632\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[10.          0.         12.16636253  0.5        11.98505656  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6604070144213999\u001b[0m\t \u001b[1m\u001b[92m0.6604070144213999\u001b[0m\t \u001b[1m\u001b[92m0.33971145459202245\u001b[0m\t \u001b[1m\u001b[92m0.3397111186869837\u001b[0m\n",
            "28 \t [ 9.70174036  9.71799099 14.          0.84593857  8.          0.66512595]\t 0.672972068481645\t 0.6604070144213999\t 0.3375906464126925\t 0.3375906463975067\n",
            "\u001b[1m\u001b[92m29\u001b[0m\t \u001b[1m\u001b[92m[ 5.03668381 10.         10.          1.          1.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.654410311419214\u001b[0m\t \u001b[1m\u001b[92m0.654410311419214\u001b[0m\t \u001b[1m\u001b[92m0.33570529680544064\u001b[0m\t \u001b[1m\u001b[92m0.3357054132154455\u001b[0m\n",
            "30 \t [ 1.26617981  4.03386415  8.          0.85223134 19.          0.86958504]\t 0.6828604856051443\t 0.654410311419214\t 0.3337486123597108\t 0.3337486123597108\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52075.93811130026"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac1d140-7ba9-46f7-9180-dc5fee8c2bee"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_approx_15 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_15 = GPGO_multi(surrogate_approx_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "approx_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_15 = approx_15.getResult()[0]\n",
        "params_approx_15['max_depth'] = int(params_approx_15['max_depth'])\n",
        "params_approx_15['min_child_weight'] = int(params_approx_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_approx_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_approx_15 = xgb.train(params_approx_15, dX_approx_train15)\n",
        "pred_approx_15 = model_approx_15.predict(dX_approx_test15)\n",
        "\n",
        "rmse_approx_15 = np.sqrt(mean_squared_error(pred_approx_15, y_test15))\n",
        "rmse_approx_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.6568473525973234\t 0.6568473525973234\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 0.9115777462403312\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 0.9091447847268881\t 0.6568473525973234\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.702826724376194\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 0.9107852583947551\t 0.6568473525973234\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.663179402460053\t 0.6568473525973234\t 0.3295785752099735\t 0.3295785752099735\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.8585273074032198\t 0.6568473525973234\t 0.3196632894606259\t 0.3196632894606259\n",
            "3  \t [ 1.91126037  0.99517267  5.          0.54111286 13.          0.82351196]\t 0.7380302996053825\t 0.6568473525973234\t 0.32302514853507647\t 0.32302514853507647\n",
            "4  \t [ 9.65016643  9.36315476  6.          0.59817648 12.          0.93115055]\t 0.703799488681527\t 0.6568473525973234\t 0.3195906765459467\t 0.3195906765459467\n",
            "5  \t [ 7.92634325  7.5869497  10.          0.81214373  5.          0.71583728]\t 0.6720659222110311\t 0.6568473525973234\t 0.31551375091852046\t 0.31551375091852046\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.8514677232156771\t 0.6568473525973234\t 0.3110990969214054\t 0.3110990969214054\n",
            "7  \t [ 1.16848639  8.05538533  5.          0.78038294 17.          0.39890654]\t 0.8255978584765504\t 0.6568473525973234\t 0.31380555436892177\t 0.31380555436892177\n",
            "8  \t [ 2.92030295  6.55213539  7.          0.85743112 11.          0.10721562]\t 0.9101677934684653\t 0.6568473525973234\t 0.31513174745793937\t 0.31513174745793937\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.7097411329660293\t 0.6568473525973234\t 0.3190779967530785\t 0.3190779967530785\n",
            "10 \t [ 7.63220266  0.71776488 13.          0.94235703 19.          0.50312607]\t 0.6591343622016139\t 0.6568473525973234\t 0.3166466745395976\t 0.3166466745395976\n",
            "11 \t [7.86329715 0.45193827 6.         0.68312899 1.         0.69810196]\t 0.7252936528187457\t 0.6568473525973234\t 0.31335355024028533\t 0.31335355024028533\n",
            "12 \t [ 9.84885491  3.44589736 14.          0.68420761  1.          0.79220009]\t 0.6603837378394706\t 0.6568473525973234\t 0.3119075662254854\t 0.3119075662254854\n",
            "13 \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\t 0.6855937848974291\t 0.6568473525973234\t 0.30926761410495784\t 0.30926761410495784\n",
            "14 \t [ 7.74771021  6.65318771  6.          0.83647538 17.          0.81072392]\t 0.7061824016851268\t 0.6568473525973234\t 0.3073903089807594\t 0.3073903089807594\n",
            "15 \t [ 6.65116837  8.16324548 14.          0.95750787  1.          0.74925927]\t 0.6659910272710082\t 0.6568473525973234\t 0.3060932459232285\t 0.3060932459232285\n",
            "16 \t [ 1.01000548  1.96777104 12.          0.51504561  8.          0.68970296]\t 0.6828545569961324\t 0.6568473525973234\t 0.3042005676938715\t 0.3042005676938715\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 4.37932047  6.20385796 12.          0.97766072  9.          0.88967325]\u001b[0m\t \u001b[1m\u001b[92m0.6404286658351375\u001b[0m\t \u001b[1m\u001b[92m0.6404286658351375\u001b[0m\t \u001b[1m\u001b[92m0.3027629219073913\u001b[0m\t \u001b[1m\u001b[92m0.3027629219073913\u001b[0m\n",
            "18 \t [ 1.86027286  4.35430307 13.          0.53536444 15.          0.92334731]\t 0.6602836056414704\t 0.6404286658351375\t 0.30077553258767004\t 0.30077553258767004\n",
            "19 \t [7.35570048 8.26460229 5.         0.55162663 8.         0.77748758]\t 0.7365875110336327\t 0.6404286658351375\t 0.2992481727753593\t 0.2992481727753593\n",
            "20 \t [6.71458767 6.21192942 5.         0.70021974 1.         0.14733325]\t 0.9149321430036975\t 0.6404286658351375\t 0.29902541564679236\t 0.29902541544981287\n",
            "21 \t [ 6.73498132  2.48341216  8.          0.97238597 17.          0.57678061]\t 0.6802134749813487\t 0.6404286658351375\t 0.30194155340372275\t 0.301940909240379\n",
            "22 \t [ 5.91978734  0.48720314 11.6413944   1.          3.05115061  0.1       ]\t 0.8978734733309024\t 0.6404286658351375\t 0.3008920932955954\t 0.3008921383268371\n",
            "23 \t [ 0.06156614  1.14076192 14.          0.54534808 18.          0.46239971]\t 0.7928419063140086\t 0.6404286658351375\t 0.3031418466537931\t 0.303141846429569\n",
            "24 \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]\t 0.756031776613528\t 0.6404286658351375\t 0.3036214419255469\t 0.30362134921996264\n",
            "25 \t [3.03172944 5.76276781 8.         0.84811645 4.         0.37564447]\t 0.7935285221615977\t 0.6404286658351375\t 0.30355245570666145\t 0.3035522764951824\n",
            "26 \t [0.21101476 5.34019706 5.         0.5        1.         1.        ]\t 0.7268493078144952\t 0.6404286658351375\t 0.30399545001558365\t 0.3039954451304554\n",
            "27 \t [ 5.05579023  0.09405836  8.          0.93704589 10.          0.9570134 ]\t 0.659126679409869\t 0.6404286658351375\t 0.3035531636288092\t 0.3035531636288092\n",
            "28 \t [ 0.17423277  9.28464895 11.          0.86455659  1.          0.87456687]\t 0.6518721676322569\t 0.6404286658351375\t 0.302366925995755\t 0.302366051941625\n",
            "29 \t [ 9.86958766  9.71945286 10.          0.93465271  9.          0.31222907]\t 0.8514784778735729\t 0.6404286658351375\t 0.30117230890602714\t 0.30117230145198204\n",
            "30 \t [ 9.40435768  7.598465   10.          0.97457018 15.          0.31309738]\t 0.847985472604506\t 0.6404286658351375\t 0.3023751822659294\t 0.3023751822659294\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50042.62774515855"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caea00a3-64d8-4375-a5a6-3eacc11e1840"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_approx_16 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_16 = GPGO_multi(surrogate_approx_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "approx_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_16 = approx_16.getResult()[0]\n",
        "params_approx_16['max_depth'] = int(params_approx_16['max_depth'])\n",
        "params_approx_16['min_child_weight'] = int(params_approx_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_approx_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_approx_16 = xgb.train(params_approx_16, dX_approx_train16)\n",
        "pred_approx_16 = model_approx_16.predict(dX_approx_test16)\n",
        "\n",
        "rmse_approx_16 = np.sqrt(mean_squared_error(pred_approx_16, y_test16))\n",
        "rmse_approx_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 0.9529819347295859\t 0.8883829281923242\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 0.9481041389252269\t 0.8883829281923242\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.8883829281923242\t 0.8883829281923242\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 0.9564077542414676\t 0.8883829281923242\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 0.9552184743546004\t 0.8883829281923242\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.3752148540161885\u001b[0m\t \u001b[1m\u001b[92m0.3752148540161885\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 0.8747438848890932\t 0.6878693399983744\t 0.36038168604389414\t 0.36038168604389414\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.8608053593354814\t 0.6878693399983744\t 0.35878680567321586\t 0.35878680567321586\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 0.9494553422981233\t 0.6878693399983744\t 0.35689418506729026\t 0.35689418506729026\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.8646755374886521\t 0.6878693399983744\t 0.35938768089084805\t 0.35938768089084805\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.7307340308882677\t 0.6878693399983744\t 0.3579770704184243\t 0.3579770704184243\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 0.9623426051674955\t 0.6878693399983744\t 0.35245714276704776\t 0.35245714276704776\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.7620148611738933\t 0.6878693399983744\t 0.3551762277085254\t 0.3551762277085254\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.3515127885791405\u001b[0m\t \u001b[1m\u001b[92m0.3515127885791405\u001b[0m\n",
            "10 \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]\t 0.7199718018091047\t 0.6730441336589406\t 0.3462387217991105\t 0.3462387205461694\n",
            "11 \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]\t 0.9735436243628346\t 0.6730441336589406\t 0.3426252382292785\t 0.3426252382292785\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.7141008345477899\t 0.6730441336589406\t 0.34565947766122995\t 0.34565947766122995\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.34238294160097854\u001b[0m\t \u001b[1m\u001b[92m0.34238294160097854\u001b[0m\n",
            "14 \t [0.50474552 1.15372476 8.         0.52058641 1.         0.43046119]\t 0.8762709839016471\t 0.6551680070961308\t 0.3383958215838508\t 0.3383958215836076\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 0.8854668121365705\t 0.6551680070961308\t 0.33899379982643807\t 0.33899379982643807\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.7778153254020743\t 0.6551680070961308\t 0.3397208358104838\t 0.3397208358104838\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 0.9718611347031094\t 0.6551680070961308\t 0.33837793405481487\t 0.33837793405481487\n",
            "18 \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]\t 0.8703303423168164\t 0.6551680070961308\t 0.34076620419526327\t 0.34076620419526327\n",
            "19 \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]\t 0.8664298555004347\t 0.6551680070961308\t 0.3410567100153507\t 0.3410567100153507\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.8073058384557079\t 0.6551680070961308\t 0.34125015177726076\t 0.34125015177726076\n",
            "21 \t [ 3.28864291  8.88700951  7.          0.70665299 16.          0.26783249]\t 0.9496880408110411\t 0.6551680070961308\t 0.3405041646041177\t 0.3405041646041177\n",
            "22 \t [ 6.72271828  8.33075498 14.          0.78841734 10.          0.48431777]\t 0.863099611959315\t 0.6551680070961308\t 0.3420527086273573\t 0.34205188993386915\n",
            "23 \t [0.58596137 5.71336149 9.         0.70354751 9.         0.28160967]\t 0.9498200925027509\t 0.6551680070961308\t 0.34214326261777706\t 0.34214326261777706\n",
            "24 \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]\t 0.7113005276137964\t 0.6551680070961308\t 0.34352283463368866\t 0.34352283463368866\n",
            "25 \t [ 9.01141716  1.23452325  9.          0.70620993 16.          0.46074297]\t 0.8622295969277951\t 0.6551680070961308\t 0.3416385094224812\t 0.3416385094224812\n",
            "26 \t [ 5.38505352  0.27838384  8.          0.64624975 19.          0.94943729]\t 0.6741571003845405\t 0.6551680070961308\t 0.34171684944498754\t 0.3417168477888163\n",
            "27 \t [ 0.2375092   5.20448002  7.          0.887766   16.          0.16167958]\t 0.971082975245141\t 0.6551680070961308\t 0.33961297614128366\t 0.33961297614127606\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 3.60668261  3.61026877 14.          0.9898327  13.          0.9620422 ]\u001b[0m\t \u001b[1m\u001b[92m0.652084379738873\u001b[0m\t \u001b[1m\u001b[92m0.652084379738873\u001b[0m\t \u001b[1m\u001b[92m0.34120678900606505\u001b[0m\t \u001b[1m\u001b[92m0.34120678900606505\u001b[0m\n",
            "29 \t [ 8.24772358 10.          9.41100195  1.         14.23205144  0.1       ]\t 0.9338180492850718\t 0.652084379738873\t 0.3390338743809084\t 0.3390323220241759\n",
            "30 \t [ 6.47170115  0.         10.40540242  1.         11.87811661  0.33867412]\t 0.8281189940750873\t 0.652084379738873\t 0.3400644082097386\t 0.3400627267542941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49556.08949355573"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bf3843-141d-4594-880f-699a76af76d1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_approx_17 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_17 = GPGO_multi(surrogate_approx_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "approx_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_17 = approx_17.getResult()[0]\n",
        "params_approx_17['max_depth'] = int(params_approx_17['max_depth'])\n",
        "params_approx_17['min_child_weight'] = int(params_approx_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_approx_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_approx_17 = xgb.train(params_approx_17, dX_approx_train17)\n",
        "pred_approx_17 = model_approx_17.predict(dX_approx_test17)\n",
        "\n",
        "rmse_approx_17 = np.sqrt(mean_squared_error(pred_approx_17, y_test17))\n",
        "rmse_approx_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.7141038418197827\t 0.7141038418197827\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.8024876355160464\t 0.7141038418197827\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.7659849712152795\t 0.7141038418197827\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9684453836634761\t 0.7141038418197827\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.8556892362199922\t 0.7141038418197827\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.86898292288902\t 0.7141038418197827\t 0.3270025542460203\t 0.3270025542460203\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.778300364354035\t 0.7141038418197827\t 0.33036248288508874\t 0.33036248288508874\n",
            "3  \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\t 0.726434848802118\t 0.7141038418197827\t 0.32759830801541495\t 0.32759830801541495\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9672674042711217\t 0.7141038418197827\t 0.32311604618747775\t 0.32311604618747775\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.826366430225874\t 0.7141038418197827\t 0.3306791318502007\t 0.3306791318502007\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.8659399691320455\t 0.7141038418197827\t 0.3318141689458407\t 0.3318141689458407\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.7563633439329396\t 0.7141038418197827\t 0.331958861787517\t 0.331958861787517\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.861798864893942\t 0.7141038418197827\t 0.3295468862871227\t 0.3295468862871227\n",
            "9  \t [ 1.2716555   3.78378689  5.          0.57556817 17.          0.18163876]\t 0.9716163961274858\t 0.7141038418197827\t 0.3306657358607556\t 0.3306657358607556\n",
            "10 \t [1.38490793 6.87002541 5.         0.73931504 9.         0.41767138]\t 0.829976302946727\t 0.7141038418197827\t 0.3350550348654543\t 0.3350550348654543\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.8069651446453449\t 0.7141038418197827\t 0.33479364401306244\t 0.33479364401306244\n",
            "12 \t [ 9.99251025  3.68443024 14.          0.88286102  6.          0.35061034]\t 0.8574563680670202\t 0.7141038418197827\t 0.33400432891053083\t 0.3340043167334271\n",
            "13 \t [ 5.50988068  4.52551329 10.          0.62342816  9.          0.60901352]\t 0.7623016588267515\t 0.7141038418197827\t 0.3344844890413835\t 0.33448439544058495\n",
            "14 \t [5.79855217 7.64610678 9.         0.54644758 3.         0.68341681]\t 0.7349404110255493\t 0.7141038418197827\t 0.33286995601691205\t 0.33286995601691205\n",
            "15 \t [ 9.19532326  8.42928342 11.          0.5289521  11.          0.74996998]\t 0.7306673350944987\t 0.7141038418197827\t 0.33090057712005616\t 0.33090057712005616\n",
            "16 \t [6.14842106 3.92031042 5.         0.80436272 5.         0.42842685]\t 0.8298337600349435\t 0.7141038418197827\t 0.32966376298425937\t 0.32966376298425937\n",
            "17 \t [ 1.93531857  1.03643759  8.          0.58366211 11.          0.77260063]\t 0.7377317601285239\t 0.7141038418197827\t 0.32913797061377964\t 0.32913782949271625\n",
            "18 \t [ 1.83368891  8.1756677   8.          0.96471075 17.          0.14868642]\t 0.9653693800994253\t 0.7141038418197827\t 0.32763540251228757\t 0.32763482773207725\n",
            "19 \t [ 1.32113565  9.62738611 14.          0.55066636 15.          0.36069244]\t 0.8636922015613553\t 0.7141038418197827\t 0.3303431131970162\t 0.33034307829519827\n",
            "20 \t [ 6.88175573  0.68997438  9.          0.55006192 19.          0.74555899]\t 0.7341056462061506\t 0.7141038418197827\t 0.33094784077618683\t 0.33094784077618683\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[ 7.32262595  0.987487   14.          0.78324612 14.          0.76403633]\u001b[0m\t \u001b[1m\u001b[92m0.7129217809179572\u001b[0m\t \u001b[1m\u001b[92m0.7129217809179572\u001b[0m\t \u001b[1m\u001b[92m0.32950903863747055\u001b[0m\t \u001b[1m\u001b[92m0.3295089126410372\u001b[0m\n",
            "22 \t [10.          1.82621073  5.          1.          8.73768631  1.        ]\t 0.7206315826213403\t 0.7129217809179572\t 0.32788906658868155\t 0.3278893063296583\n",
            "23 \t [ 7.07271536  8.13007518  5.          0.98530219 19.          0.92839144]\t 0.7288961616067631\t 0.7129217809179572\t 0.32694665981857207\t 0.32694665981857207\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[0.85666329 5.92364698 9.         0.69191689 5.         0.98975497]\u001b[0m\t \u001b[1m\u001b[92m0.6651465396376819\u001b[0m\t \u001b[1m\u001b[92m0.6651465396376819\u001b[0m\t \u001b[1m\u001b[92m0.325274901434568\u001b[0m\t \u001b[1m\u001b[92m0.32527476266684496\u001b[0m\n",
            "\u001b[1m\u001b[92m25\u001b[0m\t \u001b[1m\u001b[92m[ 6.24000319  9.26686468  8.57311807  1.         14.28732968  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6616406212425372\u001b[0m\t \u001b[1m\u001b[92m0.6616406212425372\u001b[0m\t \u001b[1m\u001b[92m0.3233929967711583\u001b[0m\t \u001b[1m\u001b[92m0.32339203076326106\u001b[0m\n",
            "26 \t [ 3.61406382  9.87735751 10.          0.70199599  8.          0.85082246]\t 0.721371984674188\t 0.6616406212425372\t 0.3215892997233259\t 0.32158917940583537\n",
            "27 \t [ 5.62137526  0.50742571 12.          0.60891749  1.          0.89299215]\t 0.6736748141470514\t 0.6616406212425372\t 0.32096653011318793\t 0.32096653011318793\n",
            "28 \t [0.26094573 1.69395726 7.84340019 0.5        2.15165034 1.        ]\t 0.6904978088487874\t 0.6616406212425372\t 0.3190631162762447\t 0.3190613738616827\n",
            "29 \t [ 0.30609514  2.49894713 14.          0.69397027 18.          0.71750058]\t 0.7193266691045255\t 0.6616406212425372\t 0.3178299455838909\t 0.3178297967299877\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[ 0.          2.82204782 15.          1.         12.00290427  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6451871207933318\u001b[0m\t \u001b[1m\u001b[92m0.6451871207933318\u001b[0m\t \u001b[1m\u001b[92m0.31696437287761847\u001b[0m\t \u001b[1m\u001b[92m0.3169651694970763\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47888.08332240055"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6645cc-05c4-44d1-b33c-49d09899b75a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_approx_18 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_18 = GPGO_multi(surrogate_approx_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "approx_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_18 = approx_18.getResult()[0]\n",
        "params_approx_18['max_depth'] = int(params_approx_18['max_depth'])\n",
        "params_approx_18['min_child_weight'] = int(params_approx_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_approx_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_approx_18 = xgb.train(params_approx_18, dX_approx_train18)\n",
        "pred_approx_18 = model_approx_18.predict(dX_approx_test18)\n",
        "\n",
        "rmse_approx_18 = np.sqrt(mean_squared_error(pred_approx_18, y_test18))\n",
        "rmse_approx_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.8853778201562241\t 0.6968179065224296\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.6968179065224296\t 0.6968179065224296\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.8778125354456613\t 0.6968179065224296\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.7421252990295766\t 0.6968179065224296\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.7041732589144625\t 0.6968179065224296\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.7694285284315747\t 0.6968179065224296\t 0.3126534529085481\t 0.3126534529085481\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.65697799905797\u001b[0m\t \u001b[1m\u001b[92m0.65697799905797\u001b[0m\t \u001b[1m\u001b[92m0.31171136119100235\u001b[0m\t \u001b[1m\u001b[92m0.31171136119100235\u001b[0m\n",
            "3  \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]\t 0.740342057576812\t 0.65697799905797\t 0.30511788530348133\t 0.30511788530348133\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.893321248053374\t 0.65697799905797\t 0.30391454062987144\t 0.30391454062987144\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.697182883066114\t 0.65697799905797\t 0.3106284653330969\t 0.3106284653330969\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 0.934413982456124\t 0.65697799905797\t 0.30712885788688327\t 0.30712885788688327\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 0.9339136409907385\t 0.65697799905797\t 0.3140253373753111\t 0.3140253373753111\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.7385292363411576\t 0.65697799905797\t 0.3189903201191462\t 0.3189903201191462\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.7318688282028918\t 0.65697799905797\t 0.3171829250085082\t 0.3171829250085082\n",
            "10 \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]\t 0.6917610853596872\t 0.65697799905797\t 0.31544905054947897\t 0.31544905054947897\n",
            "11 \t [ 0.2637722   4.11659493  5.          0.61604637 11.          0.22374653]\t 0.934862140121076\t 0.65697799905797\t 0.3129722519438204\t 0.3129722519438204\n",
            "12 \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]\t 0.7530157713797134\t 0.65697799905797\t 0.3165847827754016\t 0.3165847827754016\n",
            "13 \t [ 1.3916722   9.15131624  5.          0.92812295 18.          0.82773453]\t 0.7365431886620325\t 0.65697799905797\t 0.31609908643573603\t 0.31609908643573603\n",
            "14 \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]\t 0.7718546540038929\t 0.65697799905797\t 0.3149036100946041\t 0.3149036100946041\n",
            "15 \t [3.36125149 0.38066674 7.         0.83604387 7.         0.55591318]\t 0.7419578447057461\t 0.65697799905797\t 0.3145400573016607\t 0.3145400573016607\n",
            "16 \t [ 9.04557073  7.9579056  13.          0.79457459 11.          0.37545445]\t 0.7687992481703463\t 0.65697799905797\t 0.3136391909944521\t 0.3136391909944521\n",
            "17 \t [ 2.34351425  1.27586471  9.          0.74485285 16.          0.89346344]\t 0.6655993851049598\t 0.65697799905797\t 0.31331250874565814\t 0.31331250874565814\n",
            "18 \t [10.         10.         14.          0.74237179  3.11601351  0.1       ]\t 0.9282919172477871\t 0.65697799905797\t 0.31129982200782014\t 0.31129996529812093\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 0.932289957585124\t 0.65697799905797\t 0.3142697383445933\t 0.3142697383445933\n",
            "20 \t [ 3.70191103 10.          5.          0.5         7.56231263  1.        ]\t 0.7233712707918818\t 0.65697799905797\t 0.316710779070753\t 0.31671181668155624\n",
            "21 \t [1.6832815  7.79896856 8.         0.88290952 1.         0.43603362]\t 0.7769167187231257\t 0.65697799905797\t 0.31563477999469075\t 0.31563477999469075\n",
            "22 \t [ 2.28468954  1.6391614  12.45645935  0.93879975  2.4324693   0.17742387]\t 0.924393098381341\t 0.65697799905797\t 0.3154173818664292\t 0.31541615187198674\n",
            "23 \t [ 5.51855676  4.72863061  7.          0.84848043 18.          0.90915156]\t 0.6816662268252194\t 0.65697799905797\t 0.3175534954130287\t 0.3175529386240035\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 2.61567385  0.01777662 13.          0.8245822  14.          0.91600971]\u001b[0m\t \u001b[1m\u001b[92m0.6484014268359763\u001b[0m\t \u001b[1m\u001b[92m0.6484014268359763\u001b[0m\t \u001b[1m\u001b[92m0.3161794888481345\u001b[0m\t \u001b[1m\u001b[92m0.3161794888481345\u001b[0m\n",
            "25 \t [ 8.31410468  0.         15.          0.79035617 10.71751409  0.1       ]\t 0.9271030828824758\t 0.6484014268359763\t 0.314234059201393\t 0.3142347429108974\n",
            "26 \t [ 0.          4.60577199 15.          0.5        13.17962661  0.1       ]\t 0.9269669904382637\t 0.6484014268359763\t 0.3162462877803069\t 0.31624624991022443\n",
            "27 \t [ 5.23584891  5.16791884 13.85153429  0.5         8.52296275  0.67425057]\t 0.7081597421102026\t 0.6484014268359763\t 0.31811436582412267\t 0.31811468290437533\n",
            "28 \t [0.66035854 2.38007533 8.         0.81153492 1.         0.70953566]\t 0.7010965274956258\t 0.6484014268359763\t 0.31719067253012356\t 0.31719067253012356\n",
            "29 \t [9.89337178 3.81875947 5.         0.59649267 7.         0.86884145]\t 0.739125810481835\t 0.6484014268359763\t 0.3161198216499313\t 0.3161198216499313\n",
            "30 \t [ 7.6132918   7.55235501  9.          0.85017682 14.          0.49704899]\t 0.7691270051155563\t 0.6484014268359763\t 0.31539301395748065\t 0.31539289882401533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48371.830907973024"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f003a73-fb0f-4876-d4df-96f7a2b65786"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_approx_19 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_19 = GPGO_multi(surrogate_approx_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "approx_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_19 = approx_19.getResult()[0]\n",
        "params_approx_19['max_depth'] = int(params_approx_19['max_depth'])\n",
        "params_approx_19['min_child_weight'] = int(params_approx_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_approx_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_approx_19 = xgb.train(params_approx_19, dX_approx_train19)\n",
        "pred_approx_19 = model_approx_19.predict(dX_approx_test19)\n",
        "\n",
        "rmse_approx_19 = np.sqrt(mean_squared_error(pred_approx_19, y_test19))\n",
        "rmse_approx_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.7381578397530673\t 0.7295721630591281\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.7470234185181706\t 0.7295721630591281\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.018052265694813\t 0.7295721630591281\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.7455570460653044\t 0.7295721630591281\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.7295721630591281\t 0.7295721630591281\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.31920645780629253\u001b[0m\t \u001b[1m\u001b[92m0.31920645780629253\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.7019341665321482\t 0.6773838424850286\t 0.3115797201652415\t 0.3115797201652415\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.0199606306890758\t 0.6773838424850286\t 0.30727117328789294\t 0.30727117328789294\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.7327508164518542\t 0.6773838424850286\t 0.3214189336371386\t 0.3214189336371386\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.8626234515673594\t 0.6773838424850286\t 0.3183176431253634\t 0.3183176431253634\n",
            "6  \t [ 8.42570155  4.07975309 12.          0.91619537  8.          0.61684591]\t 0.7059767781587389\t 0.6773838424850286\t 0.3209930457205859\t 0.3209930456587387\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.7065170119936448\t 0.6773838424850286\t 0.31761736678139474\t 0.31761736678139474\n",
            "8  \t [ 3.63408057  9.2502169   7.          0.59622027 10.          0.62731569]\t 0.7317581740148223\t 0.6773838424850286\t 0.3147927227916585\t 0.3147927227916585\n",
            "9  \t [ 1.79783097  1.91934618  5.          0.77893204 13.          0.47835366]\t 0.7857306346205829\t 0.6773838424850286\t 0.31309327826105887\t 0.31309327826105887\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 4.45643696  6.43761151 10.          0.59521711 15.          0.91320177]\u001b[0m\t \u001b[1m\u001b[92m0.6773536163008785\u001b[0m\t \u001b[1m\u001b[92m0.6773536163008785\u001b[0m\t \u001b[1m\u001b[92m0.3131195662588827\u001b[0m\t \u001b[1m\u001b[92m0.3131195578541349\u001b[0m\n",
            "11 \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]\t 0.7333445147195274\t 0.6773536163008785\t 0.3104443777149082\t 0.3104443777149082\n",
            "\u001b[1m\u001b[92m12\u001b[0m\t \u001b[1m\u001b[92m[ 9.23915017 10.          9.34561051  0.5         8.83821357  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6709245448993438\u001b[0m\t \u001b[1m\u001b[92m0.6709245448993438\u001b[0m\t \u001b[1m\u001b[92m0.3093570418254338\u001b[0m\t \u001b[1m\u001b[92m0.30935704120347524\u001b[0m\n",
            "13 \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]\t 1.0149681655113947\t 0.6709245448993438\t 0.30706103763292925\t 0.30706103365029513\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.7335321473751593\t 0.6709245448993438\t 0.31330011254637913\t 0.31330011254637913\n",
            "15 \t [ 3.29312611  0.9704927   6.          0.68391426 19.          0.43020049]\t 0.767048132195449\t 0.6709245448993438\t 0.31224667298033165\t 0.31224667255637806\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.7391934581482711\t 0.6709245448993438\t 0.3119377045095111\t 0.3119377022040868\n",
            "17 \t [9.42305669 0.3423134  7.         0.77066127 8.         0.63693457]\t 0.7280806792663158\t 0.6709245448993438\t 0.31114733179344456\t 0.31114733179344456\n",
            "18 \t [ 4.53712581  0.82823489 12.          0.77278662  7.          0.49955948]\t 0.7418182765032342\t 0.6709245448993438\t 0.31023702877683396\t 0.3102364707730275\n",
            "19 \t [ 1.10650842  9.77537077 14.          0.83431584  1.          0.5884296 ]\t 0.7222348544284499\t 0.6709245448993438\t 0.3096292352527396\t 0.3096292352527396\n",
            "20 \t [ 9.47745808  9.50911305 13.          0.70555451  1.          0.87222907]\t 0.6776716071409558\t 0.6709245448993438\t 0.3087633176111565\t 0.3087633176111565\n",
            "21 \t [0.63927877 0.36518569 5.         0.86590497 1.         0.99444527]\t 0.729970665502028\t 0.6709245448993438\t 0.30731896066135944\t 0.30731896066135944\n",
            "22 \t [ 8.32444303 10.         15.          0.5        10.49244237  0.1       ]\t 1.0184883372527078\t 0.6709245448993438\t 0.30671534362916447\t 0.3067153419266518\n",
            "23 \t [9.69395621 3.02000208 9.         0.64387395 1.         0.9318623 ]\t 0.6816619990654174\t 0.6709245448993438\t 0.3109735501099725\t 0.3109728462950847\n",
            "24 \t [ 2.76287935  0.832992   10.          0.52421602  1.          0.77581255]\t 0.6811258108165148\t 0.6709245448993438\t 0.3096641214300379\t 0.3096641214300379\n",
            "\u001b[1m\u001b[92m25\u001b[0m\t \u001b[1m\u001b[92m[ 0.          3.67332341  9.56127074  0.5        16.56559295  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6696062832683504\u001b[0m\t \u001b[1m\u001b[92m0.6696062832683504\u001b[0m\t \u001b[1m\u001b[92m0.30843350618420384\u001b[0m\t \u001b[1m\u001b[92m0.30843377378692405\u001b[0m\n",
            "26 \t [ 9.2876216   9.23467155  9.          0.78119986 18.          0.66822771]\t 0.7093766156846689\t 0.6696062832683504\t 0.30714671623430484\t 0.30714671623430484\n",
            "27 \t [ 0.          0.28276228 12.5986234   0.5        10.68773086  0.1       ]\t 1.0176630723330928\t 0.6696062832683504\t 0.3063971747538269\t 0.3063976439755396\n",
            "28 \t [ 5.12579843  0.51137195 14.          0.55412141 13.          0.64495739]\t 0.7109871057528058\t 0.6696062832683504\t 0.30999444546600186\t 0.30999444546600186\n",
            "29 \t [ 8.73793669  2.43663345 11.          0.74070373 19.          0.18745114]\t 1.016658260578657\t 0.6696062832683504\t 0.3092290310556974\t 0.3092290310556974\n",
            "30 \t [5.36262055 6.28890061 5.         0.79048249 6.27144859 0.29066962]\t 0.8674190256427666\t 0.6696062832683504\t 0.31248640264252003\t 0.3124864662246833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52021.65327692546"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6eee817-10a1-4874-ced7-69bebe283d93"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_approx_20 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_20 = GPGO_multi(surrogate_approx_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "approx_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_20 = approx_20.getResult()[0]\n",
        "params_approx_20['max_depth'] = int(params_approx_20['max_depth'])\n",
        "params_approx_20['min_child_weight'] = int(params_approx_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_approx_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_approx_20 = xgb.train(params_approx_20, dX_approx_train20)\n",
        "pred_approx_20 = model_approx_20.predict(dX_approx_test20)\n",
        "\n",
        "rmse_approx_20 = np.sqrt(mean_squared_error(pred_approx_20, y_test20))\n",
        "rmse_approx_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.6597299542050263\t 0.6597299542050263\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.6983733363249625\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0633118913318171\t 0.6597299542050263\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.8790653027854468\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.8778581695963045\t 0.6597299542050263\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.8825953654337161\t 0.6597299542050263\t 0.3383723349263821\t 0.3383723349263821\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0635732061044851\t 0.6597299542050263\t 0.3403957614639891\t 0.3403957614639891\n",
            "3  \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]\t 0.7502219040814293\t 0.6597299542050263\t 0.35360385401873795\t 0.3536038540187377\n",
            "4  \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]\t 0.7367139517682284\t 0.6597299542050263\t 0.34728004809963386\t 0.34728004809963386\n",
            "5  \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]\t 0.8006234291185196\t 0.6597299542050263\t 0.3417617221065268\t 0.3417617221065268\n",
            "6  \t [ 9.80686472  1.37296982 14.          0.9100959  10.          0.1681724 ]\t 1.058727127460609\t 0.6597299542050263\t 0.33959187158504567\t 0.33959187158504567\n",
            "7  \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]\t 0.703165388931625\t 0.6597299542050263\t 0.3480934841548431\t 0.3480934841548431\n",
            "8  \t [ 2.63649501  9.62311075  7.          0.5192485  13.          0.19746315]\t 1.0640909980360433\t 0.6597299542050263\t 0.342821197321253\t 0.34282119365125024\n",
            "9  \t [ 9.18502444  7.06345806 13.          0.62385346 16.          0.94993271]\t 0.6703678866341707\t 0.6597299542050263\t 0.3497830071237432\t 0.3497830071237432\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.8036859734991779\t 0.6597299542050263\t 0.3446830937726973\t 0.3446830937726973\n",
            "11 \t [ 1.427592    3.43787632  6.          0.91643951 11.          0.75231375]\t 0.7101353944025834\t 0.6597299542050263\t 0.34301108920989415\t 0.343011087911276\n",
            "12 \t [ 6.87684298  0.81341201 12.          0.63438989 19.          0.35708107]\t 0.8844718896334441\t 0.6597299542050263\t 0.3395870366833972\t 0.3395870301296865\n",
            "13 \t [ 3.51322154  8.79998304 14.          0.91142182  1.          0.35103611]\t 0.8922088424958478\t 0.6597299542050263\t 0.34048892153503735\t 0.34048892153503735\n",
            "\u001b[1m\u001b[92m14\u001b[0m\t \u001b[1m\u001b[92m[ 4.58148989  3.72438203 13.          0.84299454  8.          0.92612108]\u001b[0m\t \u001b[1m\u001b[92m0.6573252901701634\u001b[0m\t \u001b[1m\u001b[92m0.6573252901701634\u001b[0m\t \u001b[1m\u001b[92m0.341264660580991\u001b[0m\t \u001b[1m\u001b[92m0.34126455838138703\u001b[0m\n",
            "15 \t [ 9.90619221  7.05528672  5.          0.91932487 18.          0.63366006]\t 0.7328927505356351\t 0.6573252901701634\t 0.337663519540588\t 0.337663519540588\n",
            "16 \t [ 6.77914888  1.1999303   5.68893053  0.95683686 11.51752589  0.1       ]\t 1.0635316822156633\t 0.6573252901701634\t 0.33545212023597587\t 0.3354515325350281\n",
            "17 \t [ 8.3723055   9.68266939 11.          0.50145124  1.          0.82596229]\t 0.7117644991570005\t 0.6573252901701634\t 0.3402087479436612\t 0.3402087479436612\n",
            "18 \t [ 0.7766431   8.0732046   5.          0.88801393 19.          0.19994543]\t 1.063694650982524\t 0.6573252901701634\t 0.3378549625962939\t 0.3378549625962939\n",
            "19 \t [8.67223652 9.66010575 6.         0.63457768 6.         0.86415257]\t 0.7147083784607429\t 0.6573252901701634\t 0.34207089549049396\t 0.3420707929019466\n",
            "20 \t [ 0.48052083  7.11896241 11.          0.81692586 10.          0.28962119]\t 0.8805558125442058\t 0.6573252901701634\t 0.3398887578288718\t 0.3398886436441724\n",
            "21 \t [ 2.16891361  0.40236972  6.          0.57865056 19.          0.33900997]\t 0.8933558323113931\t 0.6573252901701634\t 0.3404251023646885\t 0.3404251023646885\n",
            "22 \t [7.09521948 1.98932663 6.         0.65989265 2.         0.73023722]\t 0.7154584586376316\t 0.6573252901701634\t 0.3409831278961493\t 0.3409831278961493\n",
            "23 \t [ 3.30640788  0.          8.82596209  1.         14.09216631  1.        ]\t 0.6581401739975309\t 0.6573252901701634\t 0.3390879167762436\t 0.33908758302205655\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.6902699854328027\t 0.6573252901701634\t 0.3367204249201614\t 0.3367204249201614\n",
            "25 \t [0.         9.36979536 6.48177647 0.5        7.57242261 1.        ]\t 0.700413168946177\t 0.6573252901701634\t 0.33472802371044863\t 0.3347279932753633\n",
            "26 \t [ 0.84368952  1.32307267 14.          0.66534106  5.          0.6002203 ]\t 0.7551323766336555\t 0.6573252901701634\t 0.3330325239069313\t 0.33303198366654757\n",
            "27 \t [ 3.5307179   8.63523862 15.          1.         13.49694196  0.1       ]\t 1.0094721297797533\t 0.6573252901701634\t 0.33205508594470706\t 0.33205508318968846\n",
            "28 \t [ 6.45441241  7.55076564 15.          1.         19.90626365  0.1       ]\t 1.0092239867660122\t 0.6573252901701634\t 0.33448946551760195\t 0.33448896192595146\n",
            "29 \t [ 2.05797056  3.5679443  14.          0.67286552 19.          0.3168445 ]\t 0.8832112854050795\t 0.6573252901701634\t 0.3367566512141197\t 0.3367565396388261\n",
            "30 \t [ 5.69118312  0.31278663 13.88390219  0.5         1.          1.        ]\t 0.6734357928934096\t 0.6573252901701634\t 0.33722513610109045\t 0.33722389853506096\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49435.43377717865"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8f8984-b6b4-4577-dcc8-ea7d3f889b57"
      },
      "source": [
        "end_approx = time.time()\n",
        "end_approx\n",
        "\n",
        "time_approx = end_approx - start_approx\n",
        "time_approx\n",
        "\n",
        "start_exact = time.time()\n",
        "start_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663854485.1654675"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8ef36e-b1f1-4f74-cc36-001a39618eb0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_exact_1 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_1 = dGPGO(surrogate_exact_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_1 = exact_1.getResult()[0]\n",
        "params_exact_1['max_depth'] = int(params_exact_1['max_depth'])\n",
        "params_exact_1['min_child_weight'] = int(params_exact_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_exact_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_exact_1 = xgb.train(params_exact_1, dX_exact_train1)\n",
        "pred_exact_1 = model_exact_1.predict(dX_exact_test1)\n",
        "\n",
        "rmse_exact_1 = np.sqrt(mean_squared_error(pred_exact_1, y_test1))\n",
        "rmse_exact_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 1.0028690365100252\t 0.6536753952667645\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7391862019705779\t 0.6536753952667645\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8806962872539386\t 0.6536753952667645\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.6536753952667645\t 0.6536753952667645\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 1.062518544792604\t 0.6536753952667645\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8659738506300403\t 0.6536753952667645\t 0.3516128267902776\t 0.3516128267902776\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 1.0589776023267656\t 0.6536753952667645\t 0.35059727959257997\t 0.35059727959257997\n",
            "3  \t [ 3.61274713  8.16007507 11.          0.84840025 19.          0.76215891]\t 0.6771887207267527\t 0.6536753952667645\t 0.36174031595002776\t 0.36174031595002776\n",
            "4  \t [ 9.28266952  0.44927819  7.          0.97265422 12.          0.93288355]\t 0.6820774846874944\t 0.6536753952667645\t 0.35159963941297434\t 0.35159963941297434\n",
            "5  \t [0.         0.         5.         0.5        3.69183045 0.1       ]\t 1.0640504359985177\t 0.6536753952667645\t 0.3436763152055678\t 0.3436763152050742\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.9004243658767852\t 0.6536753952667645\t 0.35259139090589275\t 0.35259139090589275\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 1.0042308077866626\t 0.6536753952667645\t 0.35319784489833767\t 0.35319784489833767\n",
            "8  \t [8.51945771 8.4424986  8.         0.90741371 1.         0.49942468]\t 0.8757522803338091\t 0.6536753952667645\t 0.3573933038213049\t 0.3573933038213049\n",
            "9  \t [ 2.08878558  0.52993661 12.          0.75288969  1.          0.24822289]\t 1.0632523501795186\t 0.6536753952667645\t 0.356782205600558\t 0.356782205600558\n",
            "10 \t [ 9.11336104  7.53362458  9.          0.74107696 16.          0.6810286 ]\t 0.7469510576000753\t 0.6536753952667645\t 0.36201297546775474\t 0.36201297546775474\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 1.061946992849472\t 0.6536753952667645\t 0.35810114526820347\t 0.35810114526820347\n",
            "12 \t [6.76356635 2.31703141 5.         0.84148498 5.         0.43949556]\t 0.8998699639297213\t 0.6536753952667645\t 0.36254566833007085\t 0.36254566833007085\n",
            "13 \t [ 0.31984184  8.77960419  5.          0.79374224 16.          0.99761184]\t 0.7310969316491746\t 0.6536753952667645\t 0.36233780635919705\t 0.36233780635919705\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7499303794197336\t 0.6536753952667645\t 0.3587769995150093\t 0.3587769995150093\n",
            "15 \t [ 9.20512342  1.60831322 11.          0.87041344  2.          0.50117029]\t 0.8186293003915115\t 0.6536753952667645\t 0.35589176276477613\t 0.35589176276477613\n",
            "\u001b[1m\u001b[92m16\u001b[0m\t \u001b[1m\u001b[92m[ 6.70762007  7.34936999 15.          1.          8.61394352  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6467899788844533\u001b[0m\t \u001b[1m\u001b[92m0.6467899788844533\u001b[0m\t \u001b[1m\u001b[92m0.3544642352885375\u001b[0m\t \u001b[1m\u001b[92m0.3544642348146781\u001b[0m\n",
            "17 \t [1.68476972 5.2908721  8.         0.92839616 1.         0.96471758]\t 0.670961172017669\t 0.6467899788844533\t 0.3504909333516761\t 0.3504909333516761\n",
            "18 \t [ 1.73244272  9.39481924 14.          0.69771339 11.          0.59112044]\t 0.8167281986762898\t 0.6467899788844533\t 0.347155602526375\t 0.347155602526375\n",
            "19 \t [10. 10. 15.  1. 20.  1.]\t 0.6504936383293095\t 0.6467899788844533\t 0.34624919286466793\t 0.34624919168770485\n",
            "20 \t [0.         6.83764348 5.         0.5        6.20528825 0.1       ]\t 1.064396151529363\t 0.6467899788844533\t 0.34308837669240777\t 0.34308830130969525\n",
            "21 \t [ 9.4425029   7.91959048 12.          0.56014827 12.          0.69595669]\t 0.7511032808618066\t 0.6467899788844533\t 0.34670992491113617\t 0.34670992491113617\n",
            "22 \t [5.85156673 7.89906642 5.         0.85677229 5.         0.41366189]\t 0.8998998428518361\t 0.6467899788844533\t 0.34501872846181303\t 0.34501872846181303\n",
            "23 \t [ 0.13012668  6.42252804 13.          0.9980631   6.          0.4031198 ]\t 0.8682080246709607\t 0.6467899788844533\t 0.34554604596776745\t 0.34554604596776745\n",
            "24 \t [ 7.04750175  3.42465254 14.          0.6398927  13.          0.58870141]\t 0.815252067284572\t 0.6467899788844533\t 0.3455629487714612\t 0.3455629487714612\n",
            "25 \t [3.92428694 0.68431362 6.         0.64283095 9.         0.2162494 ]\t 1.0619895012405975\t 0.6467899788844533\t 0.3448947164170338\t 0.3448947164170338\n",
            "26 \t [ 1.03968583  3.49943563 14.          0.82879876  3.          0.98366866]\t 0.6562345271802523\t 0.6467899788844533\t 0.3478082347365723\t 0.3478082347365723\n",
            "27 \t [ 9.80506138  4.80078528 13.          0.71095318 17.          0.3227225 ]\t 1.0006677560529766\t 0.6467899788844533\t 0.34536812420186824\t 0.34536812420186824\n",
            "28 \t [ 0.15246909  0.64891005  5.          0.82057511 17.          0.55392553]\t 0.8471082658020649\t 0.6467899788844533\t 0.34716426643824344\t 0.34716426643824344\n",
            "29 \t [ 7.40845157  8.58336508  5.          0.8318041  19.          0.36434664]\t 1.0097984953249557\t 0.6467899788844533\t 0.34688856216621716\t 0.34688856216621716\n",
            "30 \t [ 3.57982931  9.40933622 11.          0.73034117  7.          0.92682434]\t 0.6617439770794065\t 0.6467899788844533\t 0.34867488280209813\t 0.34867488280209813\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47122.48782091602"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7eab42-9e06-4e34-bdd6-a5a2aa36d339"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_exact_2 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_2 = dGPGO(surrogate_exact_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_2 = exact_2.getResult()[0]\n",
        "params_exact_2['max_depth'] = int(params_exact_2['max_depth'])\n",
        "params_exact_2['min_child_weight'] = int(params_exact_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_exact_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_exact_2 = xgb.train(params_exact_2, dX_exact_train2)\n",
        "pred_exact_2 = model_exact_2.predict(dX_exact_test2)\n",
        "\n",
        "rmse_exact_2 = np.sqrt(mean_squared_error(pred_exact_2, y_test2))\n",
        "rmse_exact_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.778909206070606\t 0.681387807728051\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.681387807728051\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.7040746477543849\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.7953147984784036\t 0.681387807728051\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.7954413972964868\t 0.681387807728051\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.2999859207899802\u001b[0m\t \u001b[1m\u001b[92m0.2999859207899802\u001b[0m\n",
            "2  \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\t 0.7341430302765248\t 0.6807577751383148\t 0.2954417961872129\t 0.2954417961872129\n",
            "3  \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]\t 0.7073935536898857\t 0.6807577751383148\t 0.29507728955743684\t 0.29507728955743684\n",
            "4  \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]\t 0.7899041327973497\t 0.6807577751383148\t 0.29349962645293376\t 0.29349962645293376\n",
            "5  \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]\t 0.7887181971022355\t 0.6807577751383148\t 0.29598062419337035\t 0.29598062419337035\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.2980285712812148\u001b[0m\t \u001b[1m\u001b[92m0.2980285712812148\u001b[0m\n",
            "7  \t [0.         0.         5.42926341 0.5        1.         0.1       ]\t 0.8726019020039407\t 0.67907472219801\t 0.29554885507956674\t 0.29554885507902934\n",
            "8  \t [1.98662322 5.58086412 6.         0.94862422 3.         0.77339666]\t 0.7107162399424428\t 0.67907472219801\t 0.30028130744679477\t 0.30028130744679477\n",
            "9  \t [ 9.24652802  2.85452625  6.          0.82083864 14.          0.624768  ]\t 0.7397571279868462\t 0.67907472219801\t 0.29912455794959064\t 0.29912455794959064\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.27081994  8.72536784 13.          0.81607342  8.          0.82891087]\u001b[0m\t \u001b[1m\u001b[92m0.6684024492575475\u001b[0m\t \u001b[1m\u001b[92m0.6684024492575475\u001b[0m\t \u001b[1m\u001b[92m0.2988402238234423\u001b[0m\t \u001b[1m\u001b[92m0.2988402238234423\u001b[0m\n",
            "11 \t [ 8.6330652   9.62113163 11.          0.50355876 13.          0.80231095]\t 0.6810729676933972\t 0.6684024492575475\t 0.2967175057966178\t 0.2967175057966178\n",
            "12 \t [ 8.76507252  8.76898373 14.          0.51356786  6.          0.73624795]\t 0.6802600475884806\t 0.6684024492575475\t 0.29521648724460375\t 0.29521648724460375\n",
            "13 \t [ 7.86086296  9.53235807  5.          0.78700181 16.          0.22516618]\t 0.8728710854388536\t 0.6684024492575475\t 0.2938681121679371\t 0.2938681121679371\n",
            "14 \t [ 9.27473506  0.48916448  9.          0.9279608  19.          0.68123621]\t 0.6739448414977296\t 0.6684024492575475\t 0.29714893588033214\t 0.29714893588033214\n",
            "15 \t [6.7013581  8.78983047 8.         0.50210667 6.         0.10992865]\t 0.864505287294602\t 0.6684024492575475\t 0.2957278982572292\t 0.2957278982572292\n",
            "16 \t [9.70003354 0.07825472 7.         0.79315177 1.         0.1995403 ]\t 0.8658541266182345\t 0.6684024492575475\t 0.2984421021359243\t 0.2984421021359243\n",
            "17 \t [ 1.94467794  1.47584396  5.          0.91953126 11.          0.49707889]\t 0.8258856905247922\t 0.6684024492575475\t 0.30078545288432273\t 0.30078545288432273\n",
            "18 \t [ 5.64670451  8.85432647 14.          0.95807607 10.          0.35707694]\t 0.7882609808277333\t 0.6684024492575475\t 0.3022063049071293\t 0.3022063049071293\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[ 0.48637371  2.78458646 12.          0.70150197  2.          0.96585736]\u001b[0m\t \u001b[1m\u001b[92m0.668026783011353\u001b[0m\t \u001b[1m\u001b[92m0.668026783011353\u001b[0m\t \u001b[1m\u001b[92m0.30269484052768325\u001b[0m\t \u001b[1m\u001b[92m0.30269484052768325\u001b[0m\n",
            "20 \t [ 4.83121679  4.47130268 10.          0.728185   17.          0.20086862]\t 0.863733069206407\t 0.668026783011353\t 0.3013266931570449\t 0.3013266931570449\n",
            "21 \t [ 9.82029269  9.84985633  5.          0.72258871 11.          0.9421958 ]\t 0.7335433725717916\t 0.668026783011353\t 0.30316994875918\t 0.30316994875918\n",
            "22 \t [ 0.51057799  7.98632671  8.          0.8773209  13.          0.97148281]\t 0.6760991691526478\t 0.668026783011353\t 0.3027769139164181\t 0.3027769139164181\n",
            "23 \t [ 1.14769908  9.46854425 10.          0.58022432 19.          0.87672068]\t 0.6763818131586096\t 0.668026783011353\t 0.30161423040863533\t 0.30161423040863533\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 0.46676511  3.42223934 13.          0.71405562 11.          0.87561456]\u001b[0m\t \u001b[1m\u001b[92m0.6646623391819284\u001b[0m\t \u001b[1m\u001b[92m0.6646623391819284\u001b[0m\t \u001b[1m\u001b[92m0.30053547170038736\u001b[0m\t \u001b[1m\u001b[92m0.30053547170038736\u001b[0m\n",
            "25 \t [ 9.70148981  3.84860271 14.          0.8648022   1.          0.77351018]\t 0.6761632488275804\t 0.6646623391819284\t 0.2993899008870081\t 0.2993899008870081\n",
            "26 \t [ 0.02669598  1.64831584  5.          0.65312552 16.          0.42301503]\t 0.826317354920929\t 0.6646623391819284\t 0.2984468892185075\t 0.2984468892185075\n",
            "27 \t [ 0.83347683  9.2405824  11.          0.54910641  7.          0.39091807]\t 0.7920844160112999\t 0.6646623391819284\t 0.29950665418025696\t 0.29950665418025696\n",
            "28 \t [ 7.32261517  3.77223908 13.          0.66532455  8.          0.34613674]\t 0.7978087661541414\t 0.6646623391819284\t 0.30003566095161516\t 0.30003566095161516\n",
            "29 \t [ 0.9606398   3.99734176 14.          0.87801589 19.          0.63696571]\t 0.6694636250286194\t 0.6646623391819284\t 0.30012639570695243\t 0.30012639570695243\n",
            "30 \t [5.42020088 3.35712712 5.         0.5        6.62536706 0.1       ]\t 0.8724885207531285\t 0.6646623391819284\t 0.29920649274517414\t 0.2992060881221874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49438.684153303526"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b61bfed-0c9a-436b-9ad4-6388cc8cdc7b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_exact_3 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_3 = dGPGO(surrogate_exact_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_3 = exact_3.getResult()[0]\n",
        "params_exact_3['max_depth'] = int(params_exact_3['max_depth'])\n",
        "params_exact_3['min_child_weight'] = int(params_exact_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_exact_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_exact_3 = xgb.train(params_exact_3, dX_exact_train3)\n",
        "pred_exact_3 = model_exact_3.predict(dX_exact_test3)\n",
        "\n",
        "rmse_exact_3 = np.sqrt(mean_squared_error(pred_exact_3, y_test3))\n",
        "rmse_exact_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.0213644638508028\t 0.7688389438662246\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.022822678309975\t 0.7688389438662246\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.7688389438662246\t 0.7688389438662246\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0239688135226253\t 0.7688389438662246\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8703298117399682\t 0.7688389438662246\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8050626816251143\t 0.7688389438662246\t 0.3778996429816352\t 0.3778996429816352\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 2.46535469  7.06056184  5.          0.53518488 13.          0.98930148]\u001b[0m\t \u001b[1m\u001b[92m0.7347345488605661\u001b[0m\t \u001b[1m\u001b[92m0.7347345488605661\u001b[0m\t \u001b[1m\u001b[92m0.3690512942835627\u001b[0m\t \u001b[1m\u001b[92m0.3690512942835627\u001b[0m\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0239673069901083\t 0.7347345488605661\t 0.35918770092919283\t 0.35918770092919283\n",
            "4  \t [ 6.69378835  1.1746468   5.          0.75549171 16.          0.73450657]\t 0.7722220514333056\t 0.7347345488605661\t 0.36571609405121075\t 0.36571609405121075\n",
            "5  \t [ 0.24010242  9.80847714 13.          0.63702721  3.          0.56729929]\t 0.7723921954821745\t 0.7347345488605661\t 0.359767598977794\t 0.359767598977794\n",
            "6  \t [9.87422438 6.71772444 5.         0.63287091 5.         0.98483042]\t 0.7384798879960105\t 0.7347345488605661\t 0.35494290969637377\t 0.35494290969637377\n",
            "7  \t [6.87752707 0.15955299 8.         0.55138154 9.         0.67263073]\t 0.7372222724588662\t 0.7347345488605661\t 0.34988828382968723\t 0.34988828382968723\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         19.97016437  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6548396524742095\u001b[0m\t \u001b[1m\u001b[92m0.6548396524742095\u001b[0m\t \u001b[1m\u001b[92m0.3455840955559042\u001b[0m\t \u001b[1m\u001b[92m0.34558409308904164\u001b[0m\n",
            "9  \t [ 8.89682762  0.79017134 14.          0.58366818  8.          0.97456627]\t 0.6882258735708705\t 0.6548396524742095\t 0.339840298194224\t 0.339840298194224\n",
            "10 \t [ 8.44289655  0.57103551 12.          0.84075455 17.          0.88566746]\t 0.6798132840292306\t 0.6548396524742095\t 0.3355989289963111\t 0.3355989289963111\n",
            "11 \t [ 1.21954001  0.36323278  6.          0.64916715 17.          0.72126664]\t 0.7591259448829037\t 0.6548396524742095\t 0.3316952415806904\t 0.3316952415806904\n",
            "12 \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\t 0.6998375974069359\t 0.6548396524742095\t 0.32996613113751055\t 0.32996613113751055\n",
            "13 \t [6.20912945 0.39964995 6.         0.93464521 2.         0.86851666]\t 0.730951449819879\t 0.6548396524742095\t 0.3271976732585233\t 0.3271976732585233\n",
            "14 \t [1.50960194 4.23400924 5.         0.89031631 5.         0.36573726]\t 0.9903357121595885\t 0.6548396524742095\t 0.325322669569142\t 0.325322669569142\n",
            "15 \t [ 8.58495733  5.09928748 13.          0.89538108  1.          0.67774369]\t 0.7408787247915003\t 0.6548396524742095\t 0.32936303892837915\t 0.32936303892837915\n",
            "16 \t [ 9.86273212  5.79963604 13.          0.69696961 16.          0.70097151]\t 0.7296642769414492\t 0.6548396524742095\t 0.32775607886407687\t 0.32775607886407687\n",
            "17 \t [ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\t 0.7059876882234674\t 0.6548396524742095\t 0.32610381930139687\t 0.32610381930139687\n",
            "18 \t [9.83745664 3.68679807 9.         0.98607907 6.         0.93173856]\t 0.685538272783727\t 0.6548396524742095\t 0.3242150039782465\t 0.3242150039782465\n",
            "19 \t [ 2.58261481  1.43735307 13.          0.73828328 19.          0.96017932]\t 0.6819322162402592\t 0.6548396524742095\t 0.3221759770949034\t 0.3221759770949034\n",
            "20 \t [ 1.06084272  8.60821489 11.          0.60672694  9.          0.40602348]\t 0.8723133504012892\t 0.6548396524742095\t 0.32024409497691464\t 0.32024409497691464\n",
            "21 \t [ 9.83060339  5.43479292  5.          0.93965116 19.          0.81693736]\t 0.7430400763458248\t 0.6548396524742095\t 0.3214005090042336\t 0.3214005090042336\n",
            "22 \t [ 0.7793921   8.87321184 14.          0.62565306 14.          0.27955137]\t 0.9804360243561806\t 0.6548396524742095\t 0.3204760915900404\t 0.3204760915900404\n",
            "23 \t [ 0.89096443  0.          5.          0.5        10.70486842  0.1       ]\t 1.0275047954954335\t 0.6548396524742095\t 0.32336863634277635\t 0.3233686334288848\n",
            "24 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0276382267404158\t 0.6548396524742095\t 0.32685441503602225\t 0.32685441463162435\n",
            "25 \t [ 5.97844374  3.36129959  7.          0.91463604 12.          0.38394576]\t 0.8766228713943243\t 0.6548396524742095\t 0.3300689717339328\t 0.3300689717339328\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[ 8.94329651 10.         15.          1.         12.41385942  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6536482646986954\u001b[0m\t \u001b[1m\u001b[92m0.6536482646986954\u001b[0m\t \u001b[1m\u001b[92m0.33074290546664015\u001b[0m\t \u001b[1m\u001b[92m0.3307428905007617\u001b[0m\n",
            "27 \t [ 3.48494009  3.901268    7.11378496  1.         19.11378496  1.        ]\t 0.6872502862699843\t 0.6536482646986954\t 0.3287183358783864\t 0.32871833586564236\n",
            "28 \t [0.10407235 6.38352286 6.         0.56621173 1.         0.79521576]\t 0.7357893847800288\t 0.6536482646986954\t 0.3271504390238646\t 0.3271509590389933\n",
            "29 \t [0.33715852 0.41541443 9.         0.53276138 6.         0.26454539]\t 0.9783805417169177\t 0.6536482646986954\t 0.3261836907013923\t 0.3261836907013923\n",
            "30 \t [9.08126432 3.56543214 8.         0.91637613 1.         0.41674238]\t 0.8703845962289429\t 0.6536482646986954\t 0.32824778037233415\t 0.32824778037233415\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47949.10243627046"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKX_nfEaaAwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9a83f8-3b3e-41f3-f6a2-e6aa82686b07"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_exact_4 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_4 = dGPGO(surrogate_exact_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_4 = exact_4.getResult()[0]\n",
        "params_exact_4['max_depth'] = int(params_exact_4['max_depth'])\n",
        "params_exact_4['min_child_weight'] = int(params_exact_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_exact_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_exact_4 = xgb.train(params_exact_4, dX_exact_train4)\n",
        "pred_exact_4 = model_exact_4.predict(dX_exact_test4)\n",
        "\n",
        "rmse_exact_4 = np.sqrt(mean_squared_error(pred_exact_4, y_test4))\n",
        "rmse_exact_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7356156069458683\t 0.6641721421409617\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7070759857649549\t 0.6641721421409617\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 0.9423811784101735\t 0.6641721421409617\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.6641721421409617\t 0.6641721421409617\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.8244425146132294\t 0.6641721421409617\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 0.9441431878307984\t 0.6641721421409617\t 0.3115838464839154\t 0.3115838464839154\n",
            "2  \t [5.94148132 0.3774518  8.         0.8050532  1.         0.46608024]\t 0.7805337335260593\t 0.6641721421409617\t 0.3233405275534221\t 0.3233405275534221\n",
            "3  \t [ 5.85683381  2.94167057 14.          0.88584905  6.          0.61705001]\t 0.7122631009157718\t 0.6641721421409617\t 0.3216602680986483\t 0.3216602680986483\n",
            "4  \t [ 5.92074392  7.05411368 14.          0.56897417 18.          0.54051446]\t 0.7168223003470561\t 0.6641721421409617\t 0.31721405917684925\t 0.31721405917684925\n",
            "5  \t [0.         0.         5.         0.5        6.73198666 0.1       ]\t 0.9404794500681988\t 0.6641721421409617\t 0.31389630996109885\t 0.313896309959191\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 0.9390440646887555\t 0.6641721421409617\t 0.3205543559750189\t 0.3205543559750189\n",
            "7  \t [3.21596988 8.94366669 5.         0.67472534 1.         0.78039064]\t 0.7531044966742895\t 0.6641721421409617\t 0.3258408067685784\t 0.3258408067685784\n",
            "8  \t [ 0.32236964  2.41893129 14.          0.88540422 15.          0.72064562]\t 0.6990250321451492\t 0.6641721421409617\t 0.3238005859120998\t 0.3238005859120998\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[ 9.60850755 10.         11.70227466  1.         10.70227466  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6453275415844378\u001b[0m\t \u001b[1m\u001b[92m0.6453275415844378\u001b[0m\t \u001b[1m\u001b[92m0.32056806467330806\u001b[0m\t \u001b[1m\u001b[92m0.32056806451604264\u001b[0m\n",
            "10 \t [ 3.07807355  8.11709345  7.          0.6375573  19.          0.82418508]\t 0.7129287838369809\t 0.6453275415844378\t 0.31647729107104067\t 0.31647729107104067\n",
            "11 \t [ 9.65147322  0.33792642 12.          0.92327424 17.          0.84355403]\t 0.681769217592037\t 0.6453275415844378\t 0.3144417946454299\t 0.3144417946454299\n",
            "12 \t [ 8.48843563  0.37785156 11.          0.83297408  1.          0.855572  ]\t 0.6923205913979871\t 0.6453275415844378\t 0.3119575478897172\t 0.3119575478897172\n",
            "13 \t [ 3.43261604  8.66268038 14.          0.50531501  2.          0.27796316]\t 0.8344269219556752\t 0.6453275415844378\t 0.30996412763451975\t 0.30996412763451975\n",
            "14 \t [ 3.22282465  1.05364145  6.          0.75774626 12.          0.92739587]\t 0.7076032952079638\t 0.6453275415844378\t 0.3112856352232665\t 0.3112856352232665\n",
            "15 \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]\t 0.7682434061303821\t 0.6453275415844378\t 0.30982695865320575\t 0.30982695865320575\n",
            "16 \t [ 1.59376327  9.3637724   5.          0.56698742 13.          0.29635446]\t 0.8312840491127815\t 0.6453275415844378\t 0.30965690726616163\t 0.30965690726616163\n",
            "17 \t [0.  0.  5.  0.5 1.  0.1]\t 0.9408999252070572\t 0.6453275415844378\t 0.31073744349549925\t 0.31073710681684796\n",
            "18 \t [ 5.7913209   0.66562836 12.          0.88967575 12.          0.45276187]\t 0.7701049123721093\t 0.6453275415844378\t 0.3139661777700762\t 0.3139661777700762\n",
            "19 \t [6.04758549 0.99675153 5.         0.67521977 7.         0.8442095 ]\t 0.7543233654111011\t 0.6453275415844378\t 0.31367868780417446\t 0.31367868780417446\n",
            "\u001b[1m\u001b[92m20\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6437292534451688\u001b[0m\t \u001b[1m\u001b[92m0.6437292534451688\u001b[0m\t \u001b[1m\u001b[92m0.31315793193888697\u001b[0m\t \u001b[1m\u001b[92m0.31315793179954066\u001b[0m\n",
            "21 \t [3.83586625 6.82676995 9.         0.53079541 5.         0.93774826]\t 0.6805235814013784\t 0.6437292534451688\t 0.3110966944651835\t 0.3110966944651835\n",
            "22 \t [ 0.47074559  8.10477098 13.          0.56791553 14.          0.20602216]\t 0.9419371446444249\t 0.6437292534451688\t 0.3096702738564464\t 0.3096702738564464\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 0.9412996363676764\t 0.6437292534451688\t 0.3123683512186871\t 0.3123683512186871\n",
            "24 \t [ 9.80678487  3.95044929 10.          0.72584344 13.          0.44065799]\t 0.7744169895010555\t 0.6437292534451688\t 0.3148420845816192\t 0.3148420845816192\n",
            "25 \t [ 1.0597149   0.38351024 12.          0.75387748  5.          0.85079697]\t 0.6904594739904761\t 0.6437292534451688\t 0.31464073695923833\t 0.31464073695923833\n",
            "26 \t [ 0.52746177  0.91300727  5.70921531  0.5        17.70921531  0.1       ]\t 0.9400557578776609\t 0.6437292534451688\t 0.31340541920569465\t 0.3134051781500479\n",
            "27 \t [ 9.5097348   7.3660116   9.          0.93170762 19.          0.34791577]\t 0.8162562136213343\t 0.6437292534451688\t 0.31558377323498077\t 0.31558377323498077\n",
            "28 \t [8.0273803  9.87833752 7.         0.89111617 6.         0.4918673 ]\t 0.7835403275506838\t 0.6437292534451688\t 0.3159076534191346\t 0.3159076534191346\n",
            "29 \t [ 0.          0.93408053 11.12982099  0.5        11.12982099  0.1       ]\t 0.9438467410602944\t 0.6437292534451688\t 0.3158192906709121\t 0.31581983464987434\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[ 9.65854213  4.11912588 15.          1.          9.16593907  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6420894908216785\u001b[0m\t \u001b[1m\u001b[92m0.6420894908216785\u001b[0m\t \u001b[1m\u001b[92m0.3177510148524777\u001b[0m\t \u001b[1m\u001b[92m0.31774972108254895\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49143.54464745735"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c99a50-7024-4f74-ded2-ace1396aa4ac"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_exact_5 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_5 = dGPGO(surrogate_exact_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_5 = exact_5.getResult()[0]\n",
        "params_exact_5['max_depth'] = int(params_exact_5['max_depth'])\n",
        "params_exact_5['min_child_weight'] = int(params_exact_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_exact_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_exact_5 = xgb.train(params_exact_5, dX_exact_train5)\n",
        "pred_exact_5 = model_exact_5.predict(dX_exact_test5)\n",
        "\n",
        "rmse_exact_5 = np.sqrt(mean_squared_error(pred_exact_5, y_test5))\n",
        "rmse_exact_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7403320965261992\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7493104333264211\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9342492295788805\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.939514214921639\t 0.7403320965261992\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.921290745787579\t 0.7403320965261992\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9436861715841889\t 0.7403320965261992\t 0.3397445061565474\t 0.3397445061565474\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9276450520884063\t 0.7403320965261992\t 0.3461373605897039\t 0.3461373605897039\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.3496576525198903\u001b[0m\t \u001b[1m\u001b[92m0.3496576525198903\u001b[0m\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.9276698902289097\t 0.7398148307506893\t 0.3458463388801236\t 0.3458463388801236\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.3463935244998457\u001b[0m\t \u001b[1m\u001b[92m0.3463935244998457\u001b[0m\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10.          9.59464903 15.          1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6458620128690523\u001b[0m\t \u001b[1m\u001b[92m0.6458620128690523\u001b[0m\t \u001b[1m\u001b[92m0.3402425730734147\u001b[0m\t \u001b[1m\u001b[92m0.3402425730734123\u001b[0m\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8160533272968584\t 0.6458620128690523\t 0.3335810653153943\t 0.3335810653153943\n",
            "8  \t [ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\t 0.6747588495441635\t 0.6458620128690523\t 0.33291987689770697\t 0.33291987689770697\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9277423136052668\t 0.6458620128690523\t 0.32845686552102993\t 0.32845686552102993\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.6796390241442563\t 0.6458620128690523\t 0.3316060999768682\t 0.3316060999768682\n",
            "11 \t [ 9.88162042  4.98501997  7.          0.71514689 11.          0.88825005]\t 0.6938260252917123\t 0.6458620128690523\t 0.3279218983566237\t 0.3279218983566237\n",
            "12 \t [ 1.24947698  9.04398434 11.          0.51619206  1.          0.25149054]\t 0.938747258179798\t 0.6458620128690523\t 0.32496229716177055\t 0.32496229716177055\n",
            "13 \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]\t 0.7130088179210804\t 0.6458620128690523\t 0.3280838010095799\t 0.3280838010095799\n",
            "14 \t [8.65416386 1.0753157  5.         0.51446617 5.         0.26433033]\t 0.9436404003700456\t 0.6458620128690523\t 0.32581300441417477\t 0.32581300441417477\n",
            "15 \t [ 0.69381482  7.09764326  5.          0.79260103 13.          0.36148114]\t 0.9417860014577227\t 0.6458620128690523\t 0.32867314860866137\t 0.32867314860866137\n",
            "16 \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]\t 0.8392510578678525\t 0.6458620128690523\t 0.3311841550824529\t 0.3311841550824529\n",
            "17 \t [ 9.82957504  3.67845167 14.          0.66259018 12.          0.65947706]\t 0.6974835790346434\t 0.6458620128690523\t 0.3313578248594023\t 0.3313578248594023\n",
            "18 \t [ 0.33154545  2.45627958  8.          0.87454095 14.          0.94998466]\t 0.680697624911\t 0.6458620128690523\t 0.32912959855857776\t 0.32912959855857776\n",
            "19 \t [10.         10.          9.37903877  1.         16.37903877  1.        ]\t 0.6549325643063361\t 0.6458620128690523\t 0.326837855840361\t 0.3268378717564554\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7616619440927369\t 0.6458620128690523\t 0.32526539373529184\t 0.32526539373529184\n",
            "21 \t [ 1.45932766  1.48724096 14.          0.8053907  17.          0.73407168]\t 0.696669546047991\t 0.6458620128690523\t 0.3235709735248532\t 0.32357099581043525\n",
            "22 \t [1.22587583 6.62501016 8.97024148 0.5        5.97024148 0.1       ]\t 0.9300207135435375\t 0.6458620128690523\t 0.32193440666501927\t 0.32193529835813167\n",
            "23 \t [0.  0.  5.  0.5 1.  0.1]\t 0.9489319500726727\t 0.6458620128690523\t 0.3238859263906405\t 0.323886076738365\n",
            "24 \t [5.80891976 6.22815082 5.         0.60791835 2.         0.19304152]\t 0.9476839298613445\t 0.6458620128690523\t 0.3259964748652283\t 0.3259964748652283\n",
            "25 \t [ 6.05189812  5.21423081 10.17947731  0.5        13.17947731  0.1       ]\t 0.9298424629235571\t 0.6458620128690523\t 0.327930032309593\t 0.3279294651923666\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[ 9.22558868 10.         15.          1.         14.81599467  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6457065030086862\u001b[0m\t \u001b[1m\u001b[92m0.6457065030086862\u001b[0m\t \u001b[1m\u001b[92m0.32945464850866135\u001b[0m\t \u001b[1m\u001b[92m0.32945497799420703\u001b[0m\n",
            "27 \t [ 6.72997514  0.60780575 14.          0.89835235 18.          0.97859978]\t 0.6669043358767854\t 0.6457065030086862\t 0.3273831915076434\t 0.3273831915076434\n",
            "28 \t [9.64880583 0.85455793 9.         0.80366346 1.         0.54097439]\t 0.7473671119907898\t 0.6457065030086862\t 0.3256416411681576\t 0.3256416411681576\n",
            "29 \t [10.         10.         14.00026162  1.          3.00026162  1.        ]\t 0.6480809050621559\t 0.6457065030086862\t 0.324842918286975\t 0.3248428837549304\n",
            "30 \t [ 6.70889282  4.76705147 14.80504615  1.          4.80504615  1.        ]\t 0.6476571742915229\t 0.6457065030086862\t 0.3230863013739161\t 0.32308701902798054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50481.71745089331"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulhEolsxaG4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45cda239-b270-4d4f-ba69-ef09d1b889f9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_exact_6 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_6 = dGPGO(surrogate_exact_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_6 = exact_6.getResult()[0]\n",
        "params_exact_6['max_depth'] = int(params_exact_6['max_depth'])\n",
        "params_exact_6['min_child_weight'] = int(params_exact_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_exact_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_exact_6 = xgb.train(params_exact_6, dX_exact_train6)\n",
        "pred_exact_6 = model_exact_6.predict(dX_exact_test6)\n",
        "\n",
        "rmse_exact_6 = np.sqrt(mean_squared_error(pred_exact_6, y_test6))\n",
        "rmse_exact_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8597082353696148\t 0.7312157182363477\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.8283267033366734\t 0.7312157182363477\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.7312157182363477\t 0.7312157182363477\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.835804847353631\t 0.7312157182363477\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0201879064028692\t 0.7312157182363477\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.019213535386702\t 0.7312157182363477\t 0.3429488605744742\t 0.3429488605744742\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.0290226001513474\t 0.7312157182363477\t 0.35435374476507975\t 0.35435374476507975\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0228902128409325\t 0.7312157182363477\t 0.36291012843192827\t 0.36291012843192827\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6519505196682808\u001b[0m\t \u001b[1m\u001b[92m0.6519505196682808\u001b[0m\t \u001b[1m\u001b[92m0.36885818085751304\u001b[0m\t \u001b[1m\u001b[92m0.36885818085676025\u001b[0m\n",
            "5  \t [ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\t 0.6939533330723558\t 0.6519505196682808\t 0.35840665417149176\t 0.35840665417149176\n",
            "6  \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]\t 0.9234519385526558\t 0.6519505196682808\t 0.3511044708059116\t 0.3511044708059116\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.0610911324495744\t 0.6519505196682808\t 0.3527120866875521\t 0.3527120866875521\n",
            "8  \t [ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]\t 0.6895189879978737\t 0.6519505196682808\t 0.3591261155729276\t 0.3591261155729276\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0250396556181756\t 0.6519505196682808\t 0.3534456619017012\t 0.3534456619017012\n",
            "10 \t [ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\t 0.6832941408312798\t 0.6519505196682808\t 0.3576946529753211\t 0.3576946529753211\n",
            "11 \t [ 8.51551086  2.70859558 10.          0.84297574  9.          0.42302662]\t 0.9225835870454052\t 0.6519505196682808\t 0.35259609544448894\t 0.35259609544448894\n",
            "12 \t [ 1.03080361  6.70895845  7.          0.73336025 19.          0.31104879]\t 1.016921838187168\t 0.6519505196682808\t 0.35358223369837666\t 0.35358223369837666\n",
            "13 \t [0.2400873  1.61429062 5.         0.72296529 1.         0.1077861 ]\t 1.0624531854847687\t 0.6519505196682808\t 0.3568582811076661\t 0.3568582826048718\n",
            "14 \t [9.89801174 9.77563967 9.         0.68555662 3.         0.83921118]\t 0.73813303625317\t 0.6519505196682808\t 0.36090688189995185\t 0.36090688189995185\n",
            "15 \t [ 0.50127522  1.94924928 11.          0.89270197 19.          0.91286914]\t 0.6768798166626013\t 0.6519505196682808\t 0.3577180886820655\t 0.3577180886820655\n",
            "16 \t [ 8.27965778  0.50999055  5.          0.77678861 11.          0.85564655]\t 0.7905013033543324\t 0.6519505196682808\t 0.35384450057949157\t 0.35384450057949157\n",
            "17 \t [5.45577791 0.01600384 5.         0.68033296 5.         0.47973584]\t 0.9614697348345509\t 0.6519505196682808\t 0.35215945890838146\t 0.35215945890838146\n",
            "\u001b[1m\u001b[92m18\u001b[0m\t \u001b[1m\u001b[92m[10.        10.        15.         1.        13.8347907  1.       ]\u001b[0m\t \u001b[1m\u001b[92m0.6508104247495371\u001b[0m\t \u001b[1m\u001b[92m0.6508104247495371\u001b[0m\t \u001b[1m\u001b[92m0.353603725028652\u001b[0m\t \u001b[1m\u001b[92m0.35360362069118195\u001b[0m\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.0599380721478096\t 0.6508104247495371\t 0.35008562712322516\t 0.35008562712322516\n",
            "20 \t [ 0.08217017  5.74710834 10.          0.94165761  5.          0.50303435]\t 0.8246545779716495\t 0.6508104247495371\t 0.3533754799841221\t 0.3533754799841221\n",
            "21 \t [4.70222718 7.76335614 9.         0.92367012 9.         0.28724782]\t 1.0152545517792837\t 0.6508104247495371\t 0.3524696845025964\t 0.3524696845025964\n",
            "22 \t [ 9.56780844  0.64608047 12.          0.83676299  2.          0.96098008]\t 0.6833221374902283\t 0.6508104247495371\t 0.354636835039966\t 0.354636835039966\n",
            "23 \t [ 5.35290297  4.65909019 13.4612496   1.         20.          1.        ]\t 0.6521815371682091\t 0.6508104247495371\t 0.3519035706516869\t 0.35190240345111545\n",
            "24 \t [0.02966045 1.1870223  6.         0.92997678 6.         0.66621503]\t 0.8113301041670242\t 0.6508104247495371\t 0.34907914162149073\t 0.34907914162149073\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.6893334668436607\t 0.6508104247495371\t 0.3482339125584517\t 0.3482339125584517\n",
            "26 \t [10.         10.          9.54909681  1.         20.          1.        ]\t 0.6611320833450127\t 0.6508104247495371\t 0.3460083796788279\t 0.3460077920078317\n",
            "27 \t [ 3.07145128  8.24536112 10.          0.9499357   1.          0.14212758]\t 1.0601608868750403\t 0.6508104247495371\t 0.34366311296511753\t 0.34366311296511753\n",
            "28 \t [10.          7.94654018  9.97172217  1.          9.97172217  1.        ]\t 0.6590604955094934\t 0.6508104247495371\t 0.3464146956015147\t 0.34641470361570353\n",
            "29 \t [ 1.0021313   4.9490761  14.          0.62016719  1.          0.18537333]\t 1.0636257139268357\t 0.6508104247495371\t 0.3441828856639355\t 0.34418301997310763\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.786373065109467\t 0.6508104247495371\t 0.34683401869846386\t 0.34683401869846386\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46629.15174803453"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYebx3RVaJ1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ffc8f51-897f-4f25-de01-3c73be2ecacc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_exact_7 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_7 = dGPGO(surrogate_exact_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_7 = exact_7.getResult()[0]\n",
        "params_exact_7['max_depth'] = int(params_exact_7['max_depth'])\n",
        "params_exact_7['min_child_weight'] = int(params_exact_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_exact_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_exact_7 = xgb.train(params_exact_7, dX_exact_train7)\n",
        "pred_exact_7 = model_exact_7.predict(dX_exact_test7)\n",
        "\n",
        "rmse_exact_7 = np.sqrt(mean_squared_error(pred_exact_7, y_test7))\n",
        "rmse_exact_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.6599162825175136\t 0.6529031062312245\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.6529031062312245\t 0.6529031062312245\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.7849988476524127\t 0.6529031062312245\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7434573966703171\t 0.6529031062312245\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.6887936732176462\t 0.6529031062312245\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.8461730749178773\t 0.6529031062312245\t 0.28238594131635086\t 0.28238594131635086\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7280339284910606\t 0.6529031062312245\t 0.29230833350135155\t 0.29230833350135155\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.6571137209723783\t 0.6529031062312245\t 0.2920426828038876\t 0.2920426828038876\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7458231993222018\t 0.6529031062312245\t 0.288475661405999\t 0.288475661405999\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.7838758112536788\t 0.6529031062312245\t 0.2894968179396361\t 0.2894968179396361\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.6787899501779286\t 0.6529031062312245\t 0.29190243471954597\t 0.29190243471954597\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.8531322761504475\t 0.6529031062312245\t 0.29004729773479043\t 0.29004729773479043\n",
            "8  \t [ 1.95327375  0.09413692  7.          0.63967551 19.          0.52105045]\t 0.718715865573951\t 0.6529031062312245\t 0.2945675051414616\t 0.2945675051414616\n",
            "9  \t [5.70513125 8.30861013 6.         0.98680016 3.         0.16134411]\t 0.9984088714580504\t 0.6529031062312245\t 0.2939717784185071\t 0.2939717784185071\n",
            "10 \t [ 0.25030147  5.86047618  7.          0.62148035 15.          0.70956246]\t 0.7144935773647406\t 0.6529031062312245\t 0.3026196459448975\t 0.3026196459448975\n",
            "11 \t [0.         0.         5.         0.5        9.52558393 0.1       ]\t 1.0011007755268673\t 0.6529031062312245\t 0.3014797481335567\t 0.3014797427224536\n",
            "12 \t [9.93412004 7.01728008 6.         0.60790736 8.         0.46475011]\t 0.8183353504315909\t 0.6529031062312245\t 0.30851008617638304\t 0.30851008617638304\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.7792188999132433\t 0.6529031062312245\t 0.30959525306187685\t 0.30959525306187685\n",
            "14 \t [ 5.05369665  2.67147005  5.          0.51290284 10.          0.64085   ]\t 0.7504591409344632\t 0.6529031062312245\t 0.30966586437928967\t 0.30966586437928967\n",
            "15 \t [ 7.27698082  9.82692974 11.          0.6446349   1.          0.67673022]\t 0.6974468561044718\t 0.6529031062312245\t 0.30913324203775955\t 0.30913324203775955\n",
            "\u001b[1m\u001b[92m16\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6415746011828174\u001b[0m\t \u001b[1m\u001b[92m0.6415746011828174\u001b[0m\t \u001b[1m\u001b[92m0.30754085266231795\u001b[0m\t \u001b[1m\u001b[92m0.3075407705578429\u001b[0m\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         12.43589204  1.          6.43589204  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6392991199859175\u001b[0m\t \u001b[1m\u001b[92m0.6392991199859175\u001b[0m\t \u001b[1m\u001b[92m0.30528167409025586\u001b[0m\t \u001b[1m\u001b[92m0.30528165286195685\u001b[0m\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.6910349298616485\t 0.6392991199859175\t 0.30317877288530287\t 0.30317877288530287\n",
            "19 \t [ 5.28371353  3.6868484  11.          0.82200641 19.          0.12021404]\t 0.9924220081561828\t 0.6392991199859175\t 0.30203534461412923\t 0.30203534461412923\n",
            "20 \t [ 9.02606866  9.9399456   5.          0.69325176 13.          0.80731892]\t 0.7457716132538541\t 0.6392991199859175\t 0.30652146037559613\t 0.30652146037559613\n",
            "21 \t [ 1.02977609  0.66145279  7.          0.5528148  14.          0.97405529]\t 0.6856334744458132\t 0.6392991199859175\t 0.3062648817478968\t 0.3062648817478968\n",
            "22 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0017306757451643\t 0.6392991199859175\t 0.30497603194409484\t 0.30497581904654486\n",
            "23 \t [ 9.74199865  2.5831282  14.82996334  1.          2.82996334  1.        ]\t 0.6408145367091512\t 0.6392991199859175\t 0.30899870456819517\t 0.3089986134548902\n",
            "24 \t [ 4.2776564   9.48283936 11.          0.71877499 12.          0.19591223]\t 0.9919884917700834\t 0.6392991199859175\t 0.3072534567424708\t 0.3072534567424708\n",
            "25 \t [10.          6.78050772 11.62035199  1.         17.62035199  1.        ]\t 0.6410204278890739\t 0.6392991199859175\t 0.31072423112198916\t 0.31072330700809664\n",
            "26 \t [ 7.50583035  7.42634963 14.          0.81352069  9.          0.10482848]\t 0.9927806614182308\t 0.6392991199859175\t 0.3091303763853263\t 0.3091303763853263\n",
            "27 \t [9.91546913 0.35662679 7.         0.87706909 8.         0.31009443]\t 0.8520314289074896\t 0.6392991199859175\t 0.31223443710667564\t 0.31223443710667564\n",
            "28 \t [ 9.910572    5.76876265 10.          0.62357248  4.          0.60901783]\t 0.7016274432002019\t 0.6392991199859175\t 0.31313613833557336\t 0.31313613833557336\n",
            "29 \t [ 9.92745389  2.10791379  6.          0.91867901 19.          0.37494465]\t 0.8675172360459502\t 0.6392991199859175\t 0.31225481794643467\t 0.31225481794643467\n",
            "30 \t [1.52216216 8.41306408 5.         0.57743997 1.         0.26594603]\t 0.888278592469768\t 0.6392991199859175\t 0.3133021150662358\t 0.3133021150662358\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50127.473180390705"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023d4909-b5c1-4e70-98fb-a1f84c7e20b7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_exact_8 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_8 = dGPGO(surrogate_exact_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_8 = exact_8.getResult()[0]\n",
        "params_exact_8['max_depth'] = int(params_exact_8['max_depth'])\n",
        "params_exact_8['min_child_weight'] = int(params_exact_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_exact_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_exact_8 = xgb.train(params_exact_8, dX_exact_train8)\n",
        "pred_exact_8 = model_exact_8.predict(dX_exact_test8)\n",
        "\n",
        "rmse_exact_8 = np.sqrt(mean_squared_error(pred_exact_8, y_test8))\n",
        "rmse_exact_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.8097437093843076\t 0.6653168057229354\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.676783388491471\t 0.6653168057229354\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8290150461838799\t 0.6653168057229354\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.704280612172438\t 0.6653168057229354\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.6653168057229354\t 0.6653168057229354\t    \t    \n",
            "1  \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\t 0.6939807861210728\t 0.6653168057229354\t 0.29530598409939274\t 0.29530598409939274\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8292448989696929\t 0.6653168057229354\t 0.2923121719696599\t 0.2923121719696599\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7238654894117781\t 0.6653168057229354\t 0.29811811123180404\t 0.29811811123180404\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8298868503374536\t 0.6653168057229354\t 0.2969669775234298\t 0.2969669775234298\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7298305735353544\t 0.6653168057229354\t 0.30094796238754046\t 0.30094796238754046\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.6713374162855336\t 0.6653168057229354\t 0.29998355795660303\t 0.29998355795660303\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8412489648220683\t 0.6653168057229354\t 0.2972038616621777\t 0.2972038616621777\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8281572228887775\t 0.6653168057229354\t 0.3005918394082364\t 0.3005918394082364\n",
            "9  \t [0.  0.  5.  0.5 1.  0.1]\t 0.9366264008615343\t 0.6653168057229354\t 0.3029878039354719\t 0.3029878035142273\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.6700820921354065\t 0.6653168057229354\t 0.30857305473519797\t 0.30857305473519797\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8403741678101049\t 0.6653168057229354\t 0.3059961669153296\t 0.3059961669153296\n",
            "12 \t [ 6.07416022  0.73060636  9.          0.91953118 17.          0.26381452]\t 0.824083830642531\t 0.6653168057229354\t 0.30790670220919025\t 0.30790670220919025\n",
            "13 \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]\t 0.9373386140641772\t 0.6653168057229354\t 0.30917253796029553\t 0.30917253796029553\n",
            "14 \t [1.36072521 8.96337054 5.         0.74382165 2.         0.12580076]\t 0.9379435984221122\t 0.6653168057229354\t 0.31312252875084307\t 0.31312252875084307\n",
            "15 \t [ 3.32794564  9.35873285 13.          0.95404271 12.          0.46503428]\t 0.8057168013419183\t 0.6653168057229354\t 0.31662985825226214\t 0.31662985825226214\n",
            "16 \t [2.33188869 0.42958899 6.09250392 0.5        9.09250392 0.1       ]\t 0.9343506859058938\t 0.6653168057229354\t 0.31687199590178444\t 0.31687199555363993\n",
            "17 \t [ 0.09889076  5.63526532 14.          0.81316857 16.          0.71340054]\t 0.6907172665844576\t 0.6653168057229354\t 0.3197544842755284\t 0.3197544842755284\n",
            "18 \t [ 8.81884199  0.29557486 11.          0.94612367  2.          0.80082225]\t 0.6729826219675135\t 0.6653168057229354\t 0.3178788688795133\t 0.3178788688795133\n",
            "19 \t [ 4.10272358  0.68972827 14.          0.96902802  1.          0.19814279]\t 0.9303071311772037\t 0.6653168057229354\t 0.31589175883498255\t 0.31589175883498255\n",
            "20 \t [ 1.37842187  7.92618907 14.          0.53493538  2.          0.9994541 ]\t 0.6778496323948628\t 0.6653168057229354\t 0.318385045715831\t 0.318385045715831\n",
            "21 \t [8.49304258 9.45420615 6.         0.52298498 5.         0.36186114]\t 0.8398941833093019\t 0.6653168057229354\t 0.31660316469862515\t 0.31660316469862515\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6454226853941064\u001b[0m\t \u001b[1m\u001b[92m0.6454226853941064\u001b[0m\t \u001b[1m\u001b[92m0.3173362359724581\u001b[0m\t \u001b[1m\u001b[92m0.3173362359724501\u001b[0m\n",
            "23 \t [ 9.52932664  9.97395786 14.86660448  1.          3.86660448  1.        ]\t 0.647499308728734\t 0.6454226853941064\t 0.31532197317385263\t 0.3153217241079026\n",
            "24 \t [ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]\t 0.6652912380850803\t 0.6454226853941064\t 0.3134646917850082\t 0.3134646917850082\n",
            "25 \t [ 2.00363843  0.25557305 13.          0.79852696 19.          0.41982126]\t 0.8045050796386125\t 0.6454226853941064\t 0.3119310576213629\t 0.3119310576213629\n",
            "26 \t [5.73496419 0.50535549 7.48043893 0.59642613 4.81088198 0.23276134]\t 0.9325451088795486\t 0.6454226853941064\t 0.312235373393975\t 0.31223559441647986\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8100270760776773\t 0.6454226853941064\t 0.31434244955139323\t 0.31434244955139323\n",
            "28 \t [ 1.06330602  9.84698732  5.          0.70744161 15.          0.6986094 ]\t 0.7398934603464837\t 0.6454226853941064\t 0.31462151938315935\t 0.31462151938315935\n",
            "29 \t [ 0.27915127  2.21091316  7.          0.63525922 18.          0.68442751]\t 0.7123197525509278\t 0.6454226853941064\t 0.31404994657115765\t 0.31404994657115765\n",
            "30 \t [8.66270612 8.68970778 9.         0.80306345 1.         0.23433357]\t 0.9299168982143875\t 0.6454226853941064\t 0.3132119295113267\t 0.3132119295113267\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51081.55924427656"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b770b09-3880-477c-ed16-4ffb80de838f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_exact_9 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_9 = dGPGO(surrogate_exact_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_9 = exact_9.getResult()[0]\n",
        "params_exact_9['max_depth'] = int(params_exact_9['max_depth'])\n",
        "params_exact_9['min_child_weight'] = int(params_exact_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_exact_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_exact_9 = xgb.train(params_exact_9, dX_exact_train9)\n",
        "pred_exact_9 = model_exact_9.predict(dX_exact_test9)\n",
        "\n",
        "rmse_exact_9 = np.sqrt(mean_squared_error(pred_exact_9, y_test9))\n",
        "rmse_exact_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 0.8449026536729003\t 0.6448358819228919\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 0.8430936233516066\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.6448358819228919\t 0.6448358819228919\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.7455250925664565\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.6542440322310401\t 0.6448358819228919\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.0516333409565926\t 0.6448358819228919\t 0.29983497120862285\t 0.29983497120862285\n",
            "2  \t [9.23885705 0.0495141  9.         0.5847098  7.         0.79832927]\t 0.6774051522557019\t 0.6448358819228919\t 0.3228827814144945\t 0.3228827814144945\n",
            "3  \t [ 3.67545472  4.78145311 14.          0.63123486 17.          0.4863889 ]\t 0.7930932442681178\t 0.6448358819228919\t 0.3159006125887972\t 0.3159006125887972\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.7396199848029671\t 0.6448358819228919\t 0.3159628745833061\t 0.3159628745833061\n",
            "5  \t [10. 10. 15.  1. 20.  1.]\t 0.6505488267879174\t 0.6448358819228919\t 0.313709717356761\t 0.31370971735676095\n",
            "6  \t [ 0.58316798  9.10724777  7.          0.55034291 18.          0.73246248]\t 0.7346285445714027\t 0.6448358819228919\t 0.30871999688103247\t 0.30871999688103247\n",
            "7  \t [ 0.65024006  0.20015298 14.          0.90298726 13.          0.95798937]\t 0.6479585144859159\t 0.6448358819228919\t 0.3073306641744736\t 0.3073306641744736\n",
            "8  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0517934452387856\t 0.6448358819228919\t 0.30356142503537303\t 0.30356142503508066\n",
            "9  \t [1.3954524  3.3924047  5.99902849 0.66180734 8.49292615 0.19961046]\t 1.0504038809376606\t 0.6448358819228919\t 0.31401405793929715\t 0.31401405793927034\n",
            "10 \t [ 8.9317907   9.240006   13.          0.55531212  4.          0.42887515]\t 0.8067241228581707\t 0.6448358819228919\t 0.3226526260562433\t 0.3226526260562433\n",
            "11 \t [ 2.72183423  9.69902384 13.          0.83330411  1.          0.50869592]\t 0.7457949006827783\t 0.6448358819228919\t 0.32259828556307474\t 0.32259828556307474\n",
            "12 \t [ 3.2619616   0.2475915   7.          0.55801432 16.          0.81247949]\t 0.697722603557653\t 0.6448358819228919\t 0.32108880811672796\t 0.32108880811672796\n",
            "13 \t [ 9.90759058  1.21564186 12.          0.74911905 17.          0.244927  ]\t 1.0470230913477547\t 0.6448358819228919\t 0.3187334922658954\t 0.3187334922658954\n",
            "14 \t [ 4.6542071   1.48576825 11.          0.81087875 13.          0.32744452]\t 0.8333502680307973\t 0.6448358819228919\t 0.3250232824038854\t 0.3250232824038854\n",
            "15 \t [2.17616972 7.47175906 6.         0.55382404 4.         0.64093097]\t 0.752401932457821\t 0.6448358819228919\t 0.3254188520817865\t 0.3254188520817865\n",
            "16 \t [9.39353565 9.93046622 5.         0.57188784 4.         0.83501032]\t 0.738886934813979\t 0.6448358819228919\t 0.32420287572449147\t 0.32420287572449147\n",
            "17 \t [ 7.81834149  9.72965303  8.          0.64259089 17.          0.22077726]\t 1.0465197239444557\t 0.6448358819228919\t 0.3228622737907809\t 0.3228622737907809\n",
            "18 \t [ 9.00084206  1.85673124 10.          0.98011614  2.          0.25530052]\t 0.83279328574821\t 0.6448358819228919\t 0.3277574339838488\t 0.3277574339838488\n",
            "19 \t [ 9.51504197  0.48338584  6.          0.77192355 13.          0.39589712]\t 0.8079627199466959\t 0.6448358819228919\t 0.3279534353709993\t 0.3279534353709993\n",
            "20 \t [ 5.06569568  9.95512019 10.          0.79200421  8.          0.9497448 ]\t 0.6524837713585139\t 0.6448358819228919\t 0.3277210754987224\t 0.3277210754987224\n",
            "21 \t [ 7.66179073  4.31797968  8.          0.58094349 18.          0.72416412]\t 0.7183963476604479\t 0.6448358819228919\t 0.3252928166583287\t 0.3252928166583287\n",
            "22 \t [ 4.99585633  9.84423212 13.          0.58601629 15.          0.62308889]\t 0.7423299571177332\t 0.6448358819228919\t 0.3238899961219007\t 0.3238899961219007\n",
            "23 \t [ 0.79581704  0.44548953 10.          0.5535323   5.          0.9139619 ]\t 0.6649440013666069\t 0.6448358819228919\t 0.32290510013270174\t 0.32290510013270174\n",
            "24 \t [ 2.42220116  6.1788397  13.          0.64865813 10.          0.13940747]\t 1.0466026780420001\t 0.6448358819228919\t 0.3210249496469808\t 0.3210249496469808\n",
            "25 \t [8.2007632  5.80436627 6.         0.76635233 7.         0.49444634]\t 0.808546353545904\t 0.6448358819228919\t 0.32483052198913215\t 0.32483052198913215\n",
            "26 \t [ 0.34910818  3.39479926 12.          0.75007153 14.          0.74419655]\t 0.6950503015339501\t 0.6448358819228919\t 0.3247552027563679\t 0.3247552027563679\n",
            "27 \t [ 0.45983101  9.28402862 13.          0.52786561  6.          0.42783681]\t 0.8036069849990609\t 0.6448358819228919\t 0.32333145483093123\t 0.32333145483093123\n",
            "28 \t [ 7.48807874  5.11462429 12.          0.72630446 14.          0.28208232]\t 0.834870831846418\t 0.6448358819228919\t 0.3232474147888579\t 0.3232474147888579\n",
            "29 \t [ 2.15240036  5.039039   13.70756964  1.          5.70756964  1.        ]\t 0.6478922453627118\t 0.6448358819228919\t 0.32354890005359477\t 0.3235488991686289\n",
            "30 \t [ 0.71982943  1.64712597  8.          0.95730675 13.          0.62848123]\t 0.7117012613015085\t 0.6448358819228919\t 0.3218231244333478\t 0.3218231244333478\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48075.00995818073"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8da0ff8-04c4-46f7-ca01-875c1216fe07"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_exact_10 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_10 = dGPGO(surrogate_exact_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_10 = exact_10.getResult()[0]\n",
        "params_exact_10['max_depth'] = int(params_exact_10['max_depth'])\n",
        "params_exact_10['min_child_weight'] = int(params_exact_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_exact_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_exact_10 = xgb.train(params_exact_10, dX_exact_train10)\n",
        "pred_exact_10 = model_exact_10.predict(dX_exact_test10)\n",
        "\n",
        "rmse_exact_10 = np.sqrt(mean_squared_error(pred_exact_10, y_test10))\n",
        "rmse_exact_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 0.8785010703819621\t 0.6669292375133978\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.6669292375133978\t 0.6669292375133978\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7012460140601039\t 0.6669292375133978\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7005965853529538\t 0.6669292375133978\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 0.880412005930048\t 0.6669292375133978\t    \t    \n",
            "1  \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\t 0.6770142260932797\t 0.6669292375133978\t 0.3076911021312796\t 0.3076911021312796\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.7417959722875219\t 0.6669292375133978\t 0.30174974776897906\t 0.30174974776897906\n",
            "3  \t [1.0517383  0.29626986 6.         0.71496305 2.         0.21703638]\t 0.8792946548244501\t 0.6669292375133978\t 0.30092577760604944\t 0.30092577760604944\n",
            "4  \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\t 0.7006385046040607\t 0.6669292375133978\t 0.30760086874051396\t 0.30760086874051396\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6455928988859453\u001b[0m\t \u001b[1m\u001b[92m0.6455928988859453\u001b[0m\t \u001b[1m\u001b[92m0.3046080437237625\u001b[0m\t \u001b[1m\u001b[92m0.30460804372376243\u001b[0m\n",
            "6  \t [ 9.8195229   7.4353827   6.          0.61370759 10.          0.85798549]\t 0.7015549121482302\t 0.6455928988859453\t 0.300234708756536\t 0.300234708756536\n",
            "7  \t [ 3.62490684  2.84275183 14.          0.74589397  2.          0.75096489]\t 0.6670230975290341\t 0.6455928988859453\t 0.29844161537579045\t 0.29844161537579045\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7069523757910561\t 0.6455928988859453\t 0.2958818348329214\t 0.2958818348329214\n",
            "9  \t [7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\t 0.661096368919013\t 0.6455928988859453\t 0.29483966070672574\t 0.29483966070672574\n",
            "10 \t [ 3.30148079  9.88907038 12.          0.72868817  1.          0.65479477]\t 0.6997345104361262\t 0.6455928988859453\t 0.29272778336089555\t 0.29272778336089555\n",
            "11 \t [5.00762913 1.53619492 9.         0.56892944 8.         0.96567366]\t 0.662454600529182\t 0.6455928988859453\t 0.2918425050100066\t 0.2918425050100066\n",
            "12 \t [ 2.40528406  7.71427622 14.          0.55203588 14.          0.3470708 ]\t 0.8154596077767258\t 0.6455928988859453\t 0.2901965998555511\t 0.2901965998555511\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         14.05053987  1.          7.05053987  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6431298994400969\u001b[0m\t \u001b[1m\u001b[92m0.6431298994400969\u001b[0m\t \u001b[1m\u001b[92m0.2923795107674344\u001b[0m\t \u001b[1m\u001b[92m0.2923795079893148\u001b[0m\n",
            "14 \t [ 0.2734411   0.20947276 13.          0.89386904  7.          0.27558279]\t 0.8166474442456968\t 0.6431298994400969\t 0.29050609246395803\t 0.29050609246395803\n",
            "15 \t [ 9.72703693  6.521415    7.          0.50173837 17.          0.28475777]\t 0.815168593089996\t 0.6431298994400969\t 0.29246956664447005\t 0.29246956664447005\n",
            "16 \t [ 8.95941594  0.86941552 12.          0.83050216  3.          0.94464191]\t 0.6482192885028333\t 0.6431298994400969\t 0.29419286106615533\t 0.29419286106615533\n",
            "17 \t [ 0.03333836  7.73565901  8.          0.63028199 18.          0.66078172]\t 0.6999224079617695\t 0.6431298994400969\t 0.29259624010874646\t 0.29259624010874646\n",
            "18 \t [ 3.35903512  5.65946459  5.          0.99895528 10.          0.94028903]\t 0.7198633628577074\t 0.6431298994400969\t 0.2920019309015848\t 0.2920019309015848\n",
            "19 \t [0.         0.         5.         0.5        8.92862398 0.1       ]\t 0.8813018879019564\t 0.6431298994400969\t 0.29179411647984593\t 0.29179411319342685\n",
            "20 \t [ 6.6230501 10.        15.         1.        15.9030355  1.       ]\t 0.6443490851593168\t 0.6431298994400969\t 0.2945278783131352\t 0.2945275769483285\n",
            "21 \t [ 7.22258807  6.23065969 12.          0.56635095 13.          0.86573749]\t 0.667894664145167\t 0.6431298994400969\t 0.2931208866845909\t 0.2931208866845909\n",
            "22 \t [ 9.43678992  0.9880373   6.          0.64942758 10.          0.75777997]\t 0.7009594179307976\t 0.6431298994400969\t 0.29214050090779053\t 0.29214050090779053\n",
            "23 \t [4.76122383 5.37906206 8.         0.72454772 2.         0.37435491]\t 0.8130617229633597\t 0.6431298994400969\t 0.29168711298751154\t 0.29168711298751154\n",
            "24 \t [ 0.83576406  4.3523579   5.          0.70563375 16.          0.45250813]\t 0.7600979001766136\t 0.6431298994400969\t 0.2929169489297058\t 0.2929169489297058\n",
            "25 \t [ 6.60529858  9.1738315  11.47415173  1.         20.          1.        ]\t 0.6472829600869499\t 0.6431298994400969\t 0.2932785854253291\t 0.29327819500746477\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[ 2.76071662  2.85083342 14.0376749   1.         11.0376749   1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6422970344997925\u001b[0m\t \u001b[1m\u001b[92m0.6422970344997925\u001b[0m\t \u001b[1m\u001b[92m0.29217813401322407\u001b[0m\t \u001b[1m\u001b[92m0.29217698513019313\u001b[0m\n",
            "27 \t [ 9.40854499  7.80841653 11.          0.95953726  2.          0.65169631]\t 0.6921338634127544\t 0.6422970344997925\t 0.29108817098501993\t 0.29108817098501993\n",
            "28 \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]\t 0.8822650514974324\t 0.6422970344997925\t 0.2906315357393745\t 0.2906315357393745\n",
            "29 \t [ 0.15356814  4.5107537  10.          0.76934228  3.          0.57910338]\t 0.7089716211388317\t 0.6422970344997925\t 0.29267896354411016\t 0.29267896354411016\n",
            "30 \t [ 7.48523074  9.74348988  9.          0.66544612 14.          0.64199162]\t 0.6952851433032754\t 0.6422970344997925\t 0.29239515344218775\t 0.29239515344218775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51059.50064492665"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd23371-0a45-4f5d-cc64-9de60d9ec9da"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_exact_11 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_11 = dGPGO(surrogate_exact_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_11 = exact_11.getResult()[0]\n",
        "params_exact_11['max_depth'] = int(params_exact_11['max_depth'])\n",
        "params_exact_11['min_child_weight'] = int(params_exact_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_exact_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_exact_11 = xgb.train(params_exact_11, dX_exact_train11)\n",
        "pred_exact_11 = model_exact_11.predict(dX_exact_test11)\n",
        "\n",
        "rmse_exact_11 = np.sqrt(mean_squared_error(pred_exact_11, y_test11))\n",
        "rmse_exact_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.7904007286371394\t 0.6894069737354023\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.727634308123781\t 0.6894069737354023\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.6894069737354023\t 0.6894069737354023\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7071657410132528\t 0.6894069737354023\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7012825433030343\t 0.6894069737354023\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.711031226877882\t 0.6894069737354023\t 0.2885980345291438\t 0.2885980345291438\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.2877808915237221\u001b[0m\t \u001b[1m\u001b[92m0.2877808915237221\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7648729702018928\t 0.6577294425265764\t 0.284293322185048\t 0.284293322185048\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 0.9235319432135773\t 0.6577294425265764\t 0.2869820646132957\t 0.2869820646132957\n",
            "5  \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]\t 0.7883201967902798\t 0.6577294425265764\t 0.2971371601629244\t 0.2971371601629244\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         15.67034797  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6381026907714851\u001b[0m\t \u001b[1m\u001b[92m0.6381026907714851\u001b[0m\t \u001b[1m\u001b[92m0.298918226731636\u001b[0m\t \u001b[1m\u001b[92m0.2989182267292521\u001b[0m\n",
            "7  \t [ 4.15094515  7.09288961  8.          0.62079813 14.          0.58741281]\t 0.735671533105253\t 0.6381026907714851\t 0.29516174208785745\t 0.29516174208785745\n",
            "8  \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]\t 0.8743477887688297\t 0.6381026907714851\t 0.2951296721746414\t 0.2951296721746414\n",
            "9  \t [ 7.64065289  8.8630116  14.          0.9254486   9.          0.47351621]\t 0.7626076284004604\t 0.6381026907714851\t 0.29950382698054817\t 0.29950382698054817\n",
            "10 \t [ 1.06054513  2.23745512 13.          0.92745502  9.          0.16992758]\t 0.9226798533243917\t 0.6381026907714851\t 0.2999344388010624\t 0.2999344388010624\n",
            "11 \t [ 0.23708771  7.99354078 13.          0.65974332 19.          0.67724424]\t 0.6950970831418338\t 0.6381026907714851\t 0.30487019427671946\t 0.30487019427671946\n",
            "12 \t [2.49649648 9.56561388 5.         0.80281761 9.         0.94453549]\t 0.712573326980913\t 0.6381026907714851\t 0.3032207130487368\t 0.3032207130487368\n",
            "13 \t [5.25943475 8.43895766 9.         0.84239601 5.         0.23871726]\t 0.9230087471537732\t 0.6381026907714851\t 0.30221033154134086\t 0.30221033154134086\n",
            "14 \t [3.05804163 0.         6.87570538 0.5        1.         0.1       ]\t 0.9313011031698311\t 0.6381026907714851\t 0.3061851593900733\t 0.3061851236850469\n",
            "15 \t [1.11163956 4.97558037 7.         0.57979481 7.         0.49674445]\t 0.7820730361773386\t 0.6381026907714851\t 0.3099682754102918\t 0.3099682754102918\n",
            "16 \t [ 8.16281368  3.58969423 13.          0.69582692 11.          0.52807397]\t 0.7303655873769592\t 0.6381026907714851\t 0.31007032668356616\t 0.31007032668356616\n",
            "17 \t [ 8.42222274  3.29986994 14.33404133  1.         19.33404133  0.80201088]\t 0.645795120099317\t 0.6381026907714851\t 0.30920513271694633\t 0.3092051807286629\n",
            "18 \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]\t 0.698358780864823\t 0.6381026907714851\t 0.30710553683800806\t 0.30710553683800806\n",
            "19 \t [ 1.41414587  5.82374358  8.          0.73371898 19.          0.60959215]\t 0.7312153103225351\t 0.6381026907714851\t 0.3058676659361316\t 0.3058676659361316\n",
            "20 \t [ 1.82088725  9.15875432 13.          0.70714197  2.          0.23699913]\t 0.9235017342249415\t 0.6381026907714851\t 0.3052911055989507\t 0.3052911055989507\n",
            "21 \t [9.80647192 0.96870215 6.         0.98951642 2.         0.21475285]\t 0.9278938669620349\t 0.6381026907714851\t 0.3081140447704868\t 0.3081140447704868\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7286740032592812\t 0.6381026907714851\t 0.31073034968669894\t 0.31073034968669894\n",
            "23 \t [ 7.09999192  4.47345685  5.          0.9460382  13.          0.80427626]\t 0.7278949453832291\t 0.6381026907714851\t 0.310011592758857\t 0.310011592758857\n",
            "24 \t [9.06829377 8.93961606 6.         0.58229519 2.         0.64167434]\t 0.7207061667898202\t 0.6381026907714851\t 0.3093320997677879\t 0.3093320997677879\n",
            "25 \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]\t 0.9247656684808231\t 0.6381026907714851\t 0.30856242189969507\t 0.30856242189969507\n",
            "26 \t [ 5.90188989  6.38867765 11.41502241  1.         17.41502241  0.71756332]\t 0.6917000452044801\t 0.6381026907714851\t 0.3107626453964561\t 0.3107632703512519\n",
            "27 \t [0.         0.         5.97258142 0.5        7.97258142 0.1       ]\t 0.9340141900105075\t 0.6381026907714851\t 0.3097010775326828\t 0.3097002036919678\n",
            "28 \t [ 7.80000006  9.9668728  15.          1.          3.52337629  1.        ]\t 0.6390272249905182\t 0.6381026907714851\t 0.3118598885800718\t 0.31185798610624105\n",
            "29 \t [ 7.90276645  0.         12.34866387  0.5         7.34866387  0.33150128]\t 0.8824402125969122\t 0.6381026907714851\t 0.31028782866751564\t 0.3102881996481715\n",
            "30 \t [ 6.16014534 10.         14.19972937  1.         20.          1.        ]\t 0.6381111600168861\t 0.6381026907714851\t 0.31159481759485386\t 0.31159386149332363\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50024.33952205649"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849c44d3-2756-49fe-b936-4fa057bd8ec8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_exact_12 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_12 = dGPGO(surrogate_exact_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_12 = exact_12.getResult()[0]\n",
        "params_exact_12['max_depth'] = int(params_exact_12['max_depth'])\n",
        "params_exact_12['min_child_weight'] = int(params_exact_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_exact_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_exact_12 = xgb.train(params_exact_12, dX_exact_train12)\n",
        "pred_exact_12 = model_exact_12.predict(dX_exact_test12)\n",
        "\n",
        "rmse_exact_12 = np.sqrt(mean_squared_error(pred_exact_12, y_test12))\n",
        "rmse_exact_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.9314271055202143\t 0.7056203424268611\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.7910532936167305\t 0.7056203424268611\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.7196830962696428\t 0.7056203424268611\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7056203424268611\t 0.7056203424268611\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.8082458628311272\t 0.7056203424268611\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.74699493326549\t 0.7056203424268611\t 0.3172746473679078\t 0.3172746473679078\n",
            "2  \t [ 7.57473716  9.63637997 12.          0.83444517 10.          0.18761713]\t 0.9247498596892157\t 0.7056203424268611\t 0.3141455540294768\t 0.3141455540294768\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 9.04517621  0.80881017 13.          0.96890904  5.          0.75400021]\u001b[0m\t \u001b[1m\u001b[92m0.6897808103544698\u001b[0m\t \u001b[1m\u001b[92m0.6897808103544698\u001b[0m\t \u001b[1m\u001b[92m0.3216328226487935\u001b[0m\t \u001b[1m\u001b[92m0.3216328226487935\u001b[0m\n",
            "4  \t [ 2.73241117  0.55778587 14.          0.70282167 15.          0.8966204 ]\t 0.6967406870158588\t 0.6897808103544698\t 0.31620001735515724\t 0.31620001735515724\n",
            "5  \t [ 6.66970674  0.03985694  6.          0.76922453 11.          0.18327615]\t 0.9302409127927834\t 0.6897808103544698\t 0.3121823950417558\t 0.3121823950417558\n",
            "6  \t [ 1.23389285  0.85357459 13.          0.93854198  3.          0.52598214]\t 0.7221002132069921\t 0.6897808103544698\t 0.31856653093512055\t 0.31856653093512055\n",
            "7  \t [ 0.57203639  5.0857779   9.          0.68290949 10.          0.94408458]\t 0.7012842559435354\t 0.6897808103544698\t 0.31591612992890716\t 0.31591612992890716\n",
            "8  \t [0.         0.67745925 5.         0.5        1.         0.1       ]\t 0.9380339511614821\t 0.6897808103544698\t 0.31306353974511414\t 0.3130635397361659\n",
            "9  \t [9.77568711 0.70796585 6.         0.73327465 3.         0.82051057]\t 0.7213506404912987\t 0.6897808103544698\t 0.3181856064529978\t 0.3181856064529978\n",
            "10 \t [ 9.20470536  7.96480391  5.          0.84400217 12.          0.74025549]\t 0.7417877006073502\t 0.6897808103544698\t 0.3161106150844287\t 0.3161106150844287\n",
            "\u001b[1m\u001b[92m11\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.650360917790661\u001b[0m\t \u001b[1m\u001b[92m0.650360917790661\u001b[0m\t \u001b[1m\u001b[92m0.3148055052233646\u001b[0m\t \u001b[1m\u001b[92m0.31480550522329137\u001b[0m\n",
            "12 \t [ 1.1215575   6.61045389 13.          0.73682382 17.          0.82385484]\t 0.6943570082727238\t 0.650360917790661\t 0.31163433302219046\t 0.31163433302219046\n",
            "13 \t [ 4.45674451  0.94208473 10.          0.94738373  7.          0.60125252]\t 0.7166741353060685\t 0.650360917790661\t 0.30970468779438304\t 0.30970468779438304\n",
            "14 \t [ 0.609825    8.87388875 14.          0.9069446   2.          0.82580346]\t 0.6998436682886817\t 0.650360917790661\t 0.30843102801776495\t 0.30843102801776495\n",
            "15 \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]\t 0.9310123715662361\t 0.650360917790661\t 0.3069618106450316\t 0.3069618106450316\n",
            "16 \t [ 9.86500554  3.24622219 14.          0.95268622 17.          0.83554836]\t 0.6861949687174898\t 0.650360917790661\t 0.31050269896091\t 0.31050269896091\n",
            "17 \t [0.17059882 0.49735145 6.         0.94724054 9.         0.97251917]\t 0.7200838686336246\t 0.650360917790661\t 0.30885175123657244\t 0.30885175123657244\n",
            "18 \t [ 1.40667435  9.60801033 13.          0.60326903 11.          0.82424216]\t 0.6997408299858809\t 0.650360917790661\t 0.30790374731214604\t 0.30790374731214604\n",
            "19 \t [5.58200824 6.47832626 5.         0.55772632 8.         0.94343024]\t 0.7445698470409463\t 0.650360917790661\t 0.3067095920132624\t 0.3067095920132624\n",
            "20 \t [ 9.98175567  0.8705802   6.          0.55210219 18.          0.50471737]\t 0.7496479603542527\t 0.650360917790661\t 0.3063131011595772\t 0.3063131011595772\n",
            "21 \t [ 4.91923868  9.45159785 12.60379882  0.9864316  19.81834933  1.        ]\t 0.6507675386482195\t 0.650360917790661\t 0.30602637112938225\t 0.3060262307724559\n",
            "22 \t [5.76471438 5.23960103 5.         0.5        1.         0.1       ]\t 0.938034092658342\t 0.650360917790661\t 0.30437241209098165\t 0.30437229316929554\n",
            "23 \t [ 9.41306296  8.67481182  7.99875648  1.         15.99875648  1.        ]\t 0.6811651265970322\t 0.650360917790661\t 0.30724169993086403\t 0.3072414616421407\n",
            "24 \t [8.76763879 4.36040002 9.         0.6751541  8.         0.94911869]\t 0.7027322856127343\t 0.650360917790661\t 0.30604575846475046\t 0.30604575846475046\n",
            "25 \t [ 3.95469902  4.43691502 14.          0.58535398 11.          0.45476493]\t 0.7762242661293977\t 0.650360917790661\t 0.30519577326509056\t 0.30519577326509056\n",
            "26 \t [8.97886962 5.1990592  8.         0.6115526  3.         0.92989751]\t 0.7062171777812216\t 0.650360917790661\t 0.30556938037805986\t 0.30556938037805986\n",
            "27 \t [ 2.9881373  10.          7.70018212  1.          8.70018212  1.        ]\t 0.679592210543832\t 0.650360917790661\t 0.30461235148094246\t 0.30461122329516743\n",
            "28 \t [ 9.13327668  0.92433654 12.          0.91412474 10.          0.85058075]\t 0.6905450567206979\t 0.650360917790661\t 0.3038325537494588\t 0.3038325537494588\n",
            "29 \t [ 3.8544074   5.22723842 10.          0.76354194  1.          0.13710805]\t 0.927143786270312\t 0.650360917790661\t 0.30301297266764554\t 0.30301297266764554\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[10.          8.41516271 11.44768018  1.          4.44768018  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6499571344941641\u001b[0m\t \u001b[1m\u001b[92m0.6499571344941641\u001b[0m\t \u001b[1m\u001b[92m0.3049873387613084\u001b[0m\t \u001b[1m\u001b[92m0.3049910680896625\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51431.10635933817"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc1eeab-72d8-4f2f-dcce-ee8ae3111a2f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_exact_13 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_13 = dGPGO(surrogate_exact_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_13 = exact_13.getResult()[0]\n",
        "params_exact_13['max_depth'] = int(params_exact_13['max_depth'])\n",
        "params_exact_13['min_child_weight'] = int(params_exact_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_exact_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_exact_13 = xgb.train(params_exact_13, dX_exact_train13)\n",
        "pred_exact_13 = model_exact_13.predict(dX_exact_test13)\n",
        "\n",
        "rmse_exact_13 = np.sqrt(mean_squared_error(pred_exact_13, y_test13))\n",
        "rmse_exact_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.6628876451121497\t 0.6628876451121497\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1013657958154304\t 0.6628876451121497\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.92150734169971\t 0.6628876451121497\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.71924819784624\t 0.6628876451121497\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1014421616742969\t 0.6628876451121497\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7207240599672383\t 0.6628876451121497\t 0.3670299499203164\t 0.3670299499203164\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[10.          8.76999345 15.          1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.648463895263151\u001b[0m\t \u001b[1m\u001b[92m0.648463895263151\u001b[0m\t \u001b[1m\u001b[92m0.35501098834879774\u001b[0m\t \u001b[1m\u001b[92m0.35501098833341127\u001b[0m\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7679544515659981\t 0.648463895263151\t 0.34290737578198405\t 0.34290737578198405\n",
            "4  \t [ 4.39024044  6.42906019 12.          0.96666124  5.          0.79403332]\t 0.6655222383347275\t 0.648463895263151\t 0.338566577668003\t 0.338566577668003\n",
            "5  \t [5.34651487 5.45650069 6.         0.93529094 7.         0.24078895]\t 1.0980632271289044\t 0.648463895263151\t 0.33124537850391933\t 0.33124537850391933\n",
            "6  \t [ 1.86840748  0.75206083 14.          0.81141351 17.          0.47108772]\t 0.8190622083881806\t 0.648463895263151\t 0.34341753852568774\t 0.34341753852568774\n",
            "7  \t [2.42114726 2.21731466 7.         0.52977639 2.         0.33969965]\t 0.9201419758889635\t 0.648463895263151\t 0.34194400270807324\t 0.34194400270807324\n",
            "8  \t [ 9.44002225  4.67426365 14.          0.69806573  1.          0.72511221]\t 0.7229243973927224\t 0.648463895263151\t 0.3441079687662372\t 0.3441079687662372\n",
            "9  \t [9.52796793 0.5269077  7.         0.61130342 2.         0.41024487]\t 0.8258632893631743\t 0.648463895263151\t 0.34014774986112106\t 0.34014774986112106\n",
            "10 \t [ 5.91640152  9.89232522  5.          0.52190423 15.          0.21991228]\t 1.0998703523971674\t 0.648463895263151\t 0.3393967397798484\t 0.3393967397798484\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7370906275446215\t 0.648463895263151\t 0.34690954586507927\t 0.34690954586507927\n",
            "12 \t [ 8.67074354  1.64396694 14.          0.83039094  7.          0.18845957]\t 1.1043508783594271\t 0.648463895263151\t 0.34384392608087727\t 0.34384392608087727\n",
            "13 \t [0.         0.         5.         0.5        7.77619938 0.1       ]\t 1.099828942687583\t 0.648463895263151\t 0.3502742395411518\t 0.35027423947350084\n",
            "14 \t [8.89376119 7.09293115 9.         0.78983641 3.         0.25997795]\t 0.9218455789450489\t 0.648463895263151\t 0.35576868606672\t 0.35576868606672\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.6686440552339279\t 0.648463895263151\t 0.3564101883266144\t 0.3564101883266144\n",
            "16 \t [9.66123717 1.6749164  7.         0.52601834 9.         0.78339475]\t 0.6982122839928836\t 0.648463895263151\t 0.3524691818351996\t 0.3524691818351996\n",
            "17 \t [1.72746041 9.05911241 9.         0.76972057 8.         0.72560219]\t 0.7119151444767224\t 0.648463895263151\t 0.3493038958546851\t 0.3493038958546851\n",
            "18 \t [ 0.94229296  2.02450761 13.          0.65000924  1.          0.22250131]\t 1.104491648360375\t 0.648463895263151\t 0.3466003336031471\t 0.3466003336031471\n",
            "19 \t [ 9.4287899  10.         12.82026372  1.          5.82026372  1.        ]\t 0.6486933892246464\t 0.648463895263151\t 0.3512149899110452\t 0.35121498989909994\n",
            "20 \t [ 9.35280568  2.44132886  8.          0.87489385 18.          0.92170626]\t 0.67440347483604\t 0.648463895263151\t 0.3478546289418817\t 0.3478546289418817\n",
            "21 \t [ 0.33371233  4.85712217  6.98466222  0.5        15.98466222  0.1       ]\t 1.1007126314952358\t 0.648463895263151\t 0.34504812233287624\t 0.3450481223326371\n",
            "22 \t [ 7.83111842  5.45254473 14.          0.60495399 17.          0.59120871]\t 0.7272082462623335\t 0.648463895263151\t 0.3491353104682128\t 0.3491353104682128\n",
            "23 \t [ 2.05622909  9.08047387  8.          0.8397078  17.          0.73365999]\t 0.7124011319640049\t 0.648463895263151\t 0.3471283467271816\t 0.3471283467271816\n",
            "24 \t [ 5.54617933  1.56123407 12.          0.78374404  3.          0.15837523]\t 1.104938811784906\t 0.648463895263151\t 0.34507876753933264\t 0.34507876753933264\n",
            "25 \t [ 1.31863824  8.38888205 14.          0.95097909  8.          0.13910651]\t 1.1022707045584863\t 0.648463895263151\t 0.34881731366633784\t 0.34881731366633784\n",
            "26 \t [2.82817177 7.85679171 5.         0.75925491 2.         0.28870643]\t 0.9160132100682634\t 0.648463895263151\t 0.35222653810823296\t 0.35222653810823296\n",
            "27 \t [ 5.85240254  2.29607078  6.          0.83156764 14.          0.75611542]\t 0.7093200501398801\t 0.648463895263151\t 0.35266040369959967\t 0.35266040369959967\n",
            "28 \t [ 9.03385543  8.30985065  9.          0.8338378  16.          0.1765382 ]\t 1.101578572523866\t 0.648463895263151\t 0.3506890761716946\t 0.3506895991767353\n",
            "29 \t [ 8.39231109  0.32510731 14.          0.5902879  19.          0.62232309]\t 0.7267306709791242\t 0.648463895263151\t 0.3537100492291378\t 0.3537100492291378\n",
            "30 \t [ 0.70251408  2.90157697 12.          0.70852125  6.          0.90296694]\t 0.6650910147401161\t 0.648463895263151\t 0.35199890442350656\t 0.35199890442350656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49288.16946361499"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAuEsXYbtOnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82adff6-a836-45ea-d4bf-50b10a43930e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_exact_14 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_14 = dGPGO(surrogate_exact_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_14 = exact_14.getResult()[0]\n",
        "params_exact_14['max_depth'] = int(params_exact_14['max_depth'])\n",
        "params_exact_14['min_child_weight'] = int(params_exact_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_exact_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_exact_14 = xgb.train(params_exact_14, dX_exact_train14)\n",
        "pred_exact_14 = model_exact_14.predict(dX_exact_test14)\n",
        "\n",
        "rmse_exact_14 = np.sqrt(mean_squared_error(pred_exact_14, y_test14))\n",
        "rmse_exact_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.8139066743222003\t 0.6747866005380063\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.6747866005380063\t 0.6747866005380063\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.977412427074478\t 0.6747866005380063\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.6774024187451972\t 0.6747866005380063\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 1.0197967308919336\t 0.6747866005380063\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 1.0126649561802825\t 0.6747866005380063\t 0.3371920067474154\t 0.3371920067474154\n",
            "2  \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]\t 0.9571856949825378\t 0.6747866005380063\t 0.34921565403432436\t 0.34921565403432436\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7245455903141328\t 0.6747866005380063\t 0.3540637697851143\t 0.3540637697851143\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 1.0111604668907606\t 0.6747866005380063\t 0.3466047642295713\t 0.3466047642295713\n",
            "5  \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]\t 0.9600990595782894\t 0.6747866005380063\t 0.3533633843706546\t 0.3533633843706546\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6502979285238808\u001b[0m\t \u001b[1m\u001b[92m0.6502979285238808\u001b[0m\t \u001b[1m\u001b[92m0.3564426623652536\u001b[0m\t \u001b[1m\u001b[92m0.3564426623652536\u001b[0m\n",
            "7  \t [ 0.57003128  6.21663363 13.          0.81050271  5.          0.20904924]\t 1.0121120103807468\t 0.6502979285238808\t 0.34874022927392173\t 0.34874022927392173\n",
            "8  \t [ 0.63353879  9.61017877  8.          0.96421247 18.          0.39200727]\t 0.8087127953472528\t 0.6502979285238808\t 0.3536537978970657\t 0.3536537978970657\n",
            "9  \t [ 8.76969774  6.4254199   8.          0.64683378 19.          0.24400256]\t 1.011399948588137\t 0.6502979285238808\t 0.3513645610919598\t 0.3513645610919598\n",
            "10 \t [ 1.6361515   9.65601963  6.          0.78645605 10.          0.24059194]\t 1.0163848571205125\t 0.6502979285238808\t 0.3553415175744268\t 0.3553415175744268\n",
            "11 \t [ 9.88809977  3.72297385  6.          0.68686416 11.          0.16446157]\t 1.0169921141610336\t 0.6502979285238808\t 0.35890155950964736\t 0.35890155950964736\n",
            "12 \t [ 2.3962028   7.36014903 14.          0.56524147 18.          0.26929367]\t 0.9601203476407975\t 0.6502979285238808\t 0.3620056268887856\t 0.3620056268887856\n",
            "13 \t [ 1.48556604  1.71732125 13.          0.7779625   9.          0.35101548]\t 0.9594313331116266\t 0.6502979285238808\t 0.36327612070688575\t 0.36327612070688575\n",
            "\u001b[1m\u001b[92m14\u001b[0m\t \u001b[1m\u001b[92m[10.          9.93940321 15.          1.          7.37023779  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.649473493609829\u001b[0m\t \u001b[1m\u001b[92m0.649473493609829\u001b[0m\t \u001b[1m\u001b[92m0.3643854011973512\u001b[0m\t \u001b[1m\u001b[92m0.3643853652866355\u001b[0m\n",
            "15 \t [5.73566512 8.66603361 8.         0.81300017 7.         0.72050723]\t 0.6856543899131531\t 0.649473493609829\t 0.35961383964206683\t 0.35961383964206683\n",
            "16 \t [ 5.21920054  9.35580917 14.          0.81835368  4.          0.54800317]\t 0.7211586025861135\t 0.649473493609829\t 0.3558047286926046\t 0.3558047286926046\n",
            "17 \t [ 1.02993124  0.1201973   8.          0.85143335 18.          0.97029247]\t 0.6777675347345953\t 0.649473493609829\t 0.3528600405534313\t 0.3528600405534313\n",
            "18 \t [ 9.40706915  0.91600736 13.          0.648599    7.          0.62885715]\t 0.6782712913254569\t 0.649473493609829\t 0.34953386594446806\t 0.34953386594446806\n",
            "19 \t [ 6.7258229   9.09121303  7.          0.59866387 14.          0.92807463]\t 0.6900997553621118\t 0.649473493609829\t 0.34647571377294417\t 0.34647571377294417\n",
            "20 \t [ 4.57870743  1.98552875 14.          0.65566453 14.          0.81792968]\t 0.6768346638837561\t 0.649473493609829\t 0.34380467228569284\t 0.34380467228569284\n",
            "21 \t [ 1.52900897  2.49551652 10.          0.74070159  3.          0.79386687]\t 0.6772839651254358\t 0.649473493609829\t 0.34115986701599077\t 0.34115986701599077\n",
            "22 \t [1.24403253 7.31158665 8.35258074 0.5        4.35258074 0.1       ]\t 1.0100954849169752\t 0.649473493609829\t 0.33870500601769826\t 0.3387048639731552\n",
            "23 \t [10.         10.         15.          1.         13.52878035  1.        ]\t 0.6496747559339833\t 0.649473493609829\t 0.34130148253463094\t 0.341301477706882\n",
            "24 \t [8.68356706 3.39368135 5.         0.96902719 1.         0.52647669]\t 0.7606090853553124\t 0.649473493609829\t 0.3387116613677662\t 0.3387116613677662\n",
            "25 \t [ 6.71198965  0.7988094   6.          0.93755772 17.          0.83354732]\t 0.7109212151666767\t 0.649473493609829\t 0.337556792737285\t 0.337556792737285\n",
            "26 \t [ 7.99859192  1.27814403 11.          0.87670998 12.          0.48785901]\t 0.8089215294655372\t 0.649473493609829\t 0.33589817695151303\t 0.33589824432604837\n",
            "27 \t [0.         0.         8.52096537 0.5        8.52096537 0.1       ]\t 1.0098091832445955\t 0.649473493609829\t 0.3354795900283129\t 0.33547904721183414\n",
            "28 \t [4.67246168 8.89222989 6.         0.98000557 3.         0.96185968]\t 0.7052214130755474\t 0.649473493609829\t 0.3377898991934965\t 0.3377898991934965\n",
            "29 \t [10.          5.82112683 13.00697085  1.          5.00697085  1.        ]\t 0.6495982786735853\t 0.649473493609829\t 0.33621874646054983\t 0.3362187397857001\n",
            "30 \t [ 4.84035975  4.60315859  7.          0.56564288 10.          0.14999938]\t 1.012036852276137\t 0.649473493609829\t 0.33420582205958793\t 0.33420582205958793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51426.81737728424"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a226e244-cd11-49ed-e462-9f514d07881b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_exact_15 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_15 = dGPGO(surrogate_exact_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_15 = exact_15.getResult()[0]\n",
        "params_exact_15['max_depth'] = int(params_exact_15['max_depth'])\n",
        "params_exact_15['min_child_weight'] = int(params_exact_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_exact_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_exact_15 = xgb.train(params_exact_15, dX_exact_train15)\n",
        "pred_exact_15 = model_exact_15.predict(dX_exact_test15)\n",
        "\n",
        "rmse_exact_15 = np.sqrt(mean_squared_error(pred_exact_15, y_test15))\n",
        "rmse_exact_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.6568473525973234\t 0.6568473525973234\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 0.9115777462403312\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 0.9091447847268881\t 0.6568473525973234\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.702826724376194\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 0.9107852583947551\t 0.6568473525973234\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.663179402460053\t 0.6568473525973234\t 0.3295785752099735\t 0.3295785752099735\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.8585273074032198\t 0.6568473525973234\t 0.3196632894606259\t 0.3196632894606259\n",
            "3  \t [ 1.91126037  0.99517267  5.          0.54111286 13.          0.82351196]\t 0.7380302996053825\t 0.6568473525973234\t 0.32302514853507647\t 0.32302514853507647\n",
            "4  \t [ 9.65016643  9.36315476  6.          0.59817648 12.          0.93115055]\t 0.703799488681527\t 0.6568473525973234\t 0.3195906765459467\t 0.3195906765459467\n",
            "5  \t [ 7.92634325  7.5869497  10.          0.81214373  5.          0.71583728]\t 0.6720659222110311\t 0.6568473525973234\t 0.31551375091852046\t 0.31551375091852046\n",
            "6  \t [ 7.93959095  1.14458347 12.          0.83279927 13.          0.31926382]\t 0.8514677232156771\t 0.6568473525973234\t 0.3110990969214054\t 0.3110990969214054\n",
            "7  \t [ 1.16848639  8.05538533  5.          0.78038294 17.          0.39890654]\t 0.8255978584765504\t 0.6568473525973234\t 0.31380555436892177\t 0.31380555436892177\n",
            "8  \t [ 2.92030295  6.55213539  7.          0.85743112 11.          0.10721562]\t 0.9101677934684653\t 0.6568473525973234\t 0.31513174745793937\t 0.31513174745793937\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.7097411329660293\t 0.6568473525973234\t 0.3190779967530785\t 0.3190779967530785\n",
            "10 \t [ 7.63220266  0.71776488 13.          0.94235703 19.          0.50312607]\t 0.6591343622016139\t 0.6568473525973234\t 0.3166466745395976\t 0.3166466745395976\n",
            "11 \t [7.86329715 0.45193827 6.         0.68312899 1.         0.69810196]\t 0.7252936528187457\t 0.6568473525973234\t 0.31335355024028533\t 0.31335355024028533\n",
            "\u001b[1m\u001b[92m12\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6491916518522693\u001b[0m\t \u001b[1m\u001b[92m0.6491916518522693\u001b[0m\t \u001b[1m\u001b[92m0.3119075662254854\u001b[0m\t \u001b[1m\u001b[92m0.3119075662254854\u001b[0m\n",
            "13 \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\t 0.6855937848974291\t 0.6491916518522693\t 0.3090456931764895\t 0.3090456931764895\n",
            "14 \t [ 7.74771021  6.65318771  6.          0.83647538 17.          0.81072392]\t 0.7061824016851268\t 0.6491916518522693\t 0.30717944257767404\t 0.30717944257767404\n",
            "15 \t [ 6.65116837  8.16324548 14.          0.95750787  1.          0.74925927]\t 0.6659910272710082\t 0.6491916518522693\t 0.3058926257883604\t 0.3058926257883604\n",
            "16 \t [ 1.01000548  1.96777104 12.          0.51504561  8.          0.68970296]\t 0.6828545569961324\t 0.6491916518522693\t 0.3040087985902153\t 0.3040087985902153\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 4.37932047  6.20385796 12.          0.97766072  9.          0.88967325]\u001b[0m\t \u001b[1m\u001b[92m0.6404286658351375\u001b[0m\t \u001b[1m\u001b[92m0.6404286658351375\u001b[0m\t \u001b[1m\u001b[92m0.30257942051166103\u001b[0m\t \u001b[1m\u001b[92m0.30257942051166103\u001b[0m\n",
            "18 \t [ 1.86027286  4.35430307 13.          0.53536444 15.          0.92334731]\t 0.6602836056414704\t 0.6404286658351375\t 0.30059922133258987\t 0.30059922133258987\n",
            "19 \t [ 6.18689053  4.41947903 10.          0.55970253  2.          0.89284311]\t 0.6634774918096769\t 0.6404286658351375\t 0.29907866577880715\t 0.29907866577880715\n",
            "20 \t [6.71458767 6.21192942 5.         0.70021974 1.         0.14733325]\t 0.9149321430036975\t 0.6404286658351375\t 0.2977250517898569\t 0.2977250517898569\n",
            "21 \t [0.77398289 6.88386985 5.         0.5        7.29947997 0.1       ]\t 0.9160935971368735\t 0.6404286658351375\t 0.30070479590728305\t 0.3007047869529437\n",
            "22 \t [ 9.31305405  2.68340802  7.          0.59348541 12.          0.97471219]\t 0.6816029222172933\t 0.6404286658351375\t 0.3034504604895149\t 0.3034504604895149\n",
            "23 \t [ 7.26711337  0.14235978  5.          0.76462611 16.          0.41351262]\t 0.8266718126292492\t 0.6404286658351375\t 0.3023428419130107\t 0.3023428419130107\n",
            "24 \t [ 7.76649344  1.163194   14.          0.89685392  1.          0.90591323]\t 0.6511140602736504\t 0.6404286658351375\t 0.30336590122724005\t 0.30336590122724005\n",
            "25 \t [ 9.28741494 10.         15.          1.         14.25947896  1.        ]\t 0.6457723809896091\t 0.6404286658351375\t 0.30196688082044665\t 0.3019664765787805\n",
            "26 \t [ 7.4679151   6.11968454 14.          0.59617872 16.          0.1338107 ]\t 0.9124887462916614\t 0.6404286658351375\t 0.300594405064192\t 0.300594405064192\n",
            "27 \t [ 9.9822358   7.62766742 15.          1.          9.5510336   1.        ]\t 0.6475064476857713\t 0.6404286658351375\t 0.30284825456895875\t 0.30284825445657343\n",
            "28 \t [ 9.88829338 10.         10.6991311   1.          8.6991311   1.        ]\t 0.6520598303585712\t 0.6404286658351375\t 0.301556014993261\t 0.30155537586790526\n",
            "29 \t [ 4.65617249  4.2358638  14.          0.83630546  4.          0.12527477]\t 0.9111271550835559\t 0.6404286658351375\t 0.3003849914813295\t 0.3003849914813295\n",
            "30 \t [ 9.40435768  7.598465   10.          0.97457018 15.          0.31309738]\t 0.847985472604506\t 0.6404286658351375\t 0.30242888961551007\t 0.30242888961551007\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50042.62774515855"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TaP6RoGuiNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e26d0fa-c7de-43f8-c5f9-2d2bf793b63d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_exact_16 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_16 = dGPGO(surrogate_exact_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_16 = exact_16.getResult()[0]\n",
        "params_exact_16['max_depth'] = int(params_exact_16['max_depth'])\n",
        "params_exact_16['min_child_weight'] = int(params_exact_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_exact_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_exact_16 = xgb.train(params_exact_16, dX_exact_train16)\n",
        "pred_exact_16 = model_exact_16.predict(dX_exact_test16)\n",
        "\n",
        "rmse_exact_16 = np.sqrt(mean_squared_error(pred_exact_16, y_test16))\n",
        "rmse_exact_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 0.9529819347295859\t 0.8883829281923242\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 0.9481041389252269\t 0.8883829281923242\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.8883829281923242\t 0.8883829281923242\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 0.9564077542414676\t 0.8883829281923242\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 0.9552184743546004\t 0.8883829281923242\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.3752148540161885\u001b[0m\t \u001b[1m\u001b[92m0.3752148540161885\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 0.8747438848890932\t 0.6878693399983744\t 0.36038168604389414\t 0.36038168604389414\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.8608053593354814\t 0.6878693399983744\t 0.35878680567321586\t 0.35878680567321586\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 0.9494553422981233\t 0.6878693399983744\t 0.35689418506729026\t 0.35689418506729026\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.8646755374886521\t 0.6878693399983744\t 0.35938768089084805\t 0.35938768089084805\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.7307340308882677\t 0.6878693399983744\t 0.3579770704184243\t 0.3579770704184243\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 0.9623426051674955\t 0.6878693399983744\t 0.35245714276704776\t 0.35245714276704776\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.7620148611738933\t 0.6878693399983744\t 0.3551762277085254\t 0.3551762277085254\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.3515127885791405\u001b[0m\t \u001b[1m\u001b[92m0.3515127885791405\u001b[0m\n",
            "10 \t [0.  0.  5.  0.5 1.  0.1]\t 0.9761208022264058\t 0.6730441336589406\t 0.3462387217991105\t 0.3462387205461694\n",
            "11 \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]\t 0.9735436243628346\t 0.6730441336589406\t 0.3492884248211207\t 0.3492884248211207\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.7141008345477899\t 0.6730441336589406\t 0.35185535877305973\t 0.35185535877305973\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.3482719629763609\u001b[0m\t \u001b[1m\u001b[92m0.3482719629763609\u001b[0m\n",
            "14 \t [ 9.63904847  1.13624975 14.          0.67706869  2.          0.95236673]\t 0.6655207401201757\t 0.6551680070961308\t 0.34402226920645373\t 0.34402226920645373\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 0.8854668121365705\t 0.6551680070961308\t 0.3403442335110746\t 0.3403442335110746\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.7778153254020743\t 0.6551680070961308\t 0.34100113729732856\t 0.34100113729732856\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 0.9718611347031094\t 0.6551680070961308\t 0.33960220350937576\t 0.33960220350937576\n",
            "18 \t [ 0.27887436  5.35249607  5.          0.53060455 10.          0.99538283]\t 0.7208146068785257\t 0.6551680070961308\t 0.3419328185711209\t 0.3419328185711209\n",
            "19 \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]\t 0.8664298555004347\t 0.6551680070961308\t 0.3397527569716965\t 0.3397527569716965\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.8073058384557079\t 0.6551680070961308\t 0.34000039854220776\t 0.34000039854220776\n",
            "21 \t [ 9.99386934  5.02816989  8.          0.55649553 14.          0.90191945]\t 0.6762300545524115\t 0.6551680070961308\t 0.3393017535579221\t 0.3393017535579221\n",
            "22 \t [1.06221729 0.         5.         0.5        9.56507722 0.1       ]\t 0.9756897016398189\t 0.6551680070961308\t 0.3368909890255862\t 0.33689021705098765\n",
            "23 \t [ 3.65536835  8.11784641  8.          0.98715029 16.          0.54731662]\t 0.77590743437461\t 0.6551680070961308\t 0.3389773734172859\t 0.3389773734172859\n",
            "24 \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]\t 0.7113005276137964\t 0.6551680070961308\t 0.3379692272742115\t 0.3379692272742115\n",
            "\u001b[1m\u001b[92m25\u001b[0m\t \u001b[1m\u001b[92m[ 7.11570529 10.         14.09028906  1.          8.09028906  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6470779178382641\u001b[0m\t \u001b[1m\u001b[92m0.6470779178382641\u001b[0m\t \u001b[1m\u001b[92m0.3362422030475238\u001b[0m\t \u001b[1m\u001b[92m0.3362422009289902\u001b[0m\n",
            "26 \t [ 5.38505352  0.27838384  8.          0.64624975 19.          0.94943729]\t 0.6741571003845405\t 0.6470779178382641\t 0.3339369534682468\t 0.3339369534682468\n",
            "27 \t [ 0.2375092   5.20448002  7.          0.887766   16.          0.16167958]\t 0.971082975245141\t 0.6470779178382641\t 0.33203919433318485\t 0.33203919433318485\n",
            "28 \t [ 1.9619463   0.16028995 10.          0.50330845  2.          0.6207421 ]\t 0.7893707891931834\t 0.6470779178382641\t 0.3339083761001737\t 0.3339083761001737\n",
            "29 \t [ 2.85481198  1.91621026 14.          0.54622477 17.          0.11441312]\t 0.9744815425855189\t 0.6470779178382641\t 0.33334991640644146\t 0.33334991640644146\n",
            "30 \t [ 4.09115251  8.7531525  14.85872848  1.          3.85872848  0.99918402]\t 0.6540273057189099\t 0.6470779178382641\t 0.33510627125027614\t 0.33510691684206007\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49831.7587544266"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOaMUmgulbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719cf415-e025-4345-9071-afdd21161e2b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_exact_17 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_17 = dGPGO(surrogate_exact_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_17 = exact_17.getResult()[0]\n",
        "params_exact_17['max_depth'] = int(params_exact_17['max_depth'])\n",
        "params_exact_17['min_child_weight'] = int(params_exact_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_exact_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_exact_17 = xgb.train(params_exact_17, dX_exact_train17)\n",
        "pred_exact_17 = model_exact_17.predict(dX_exact_test17)\n",
        "\n",
        "rmse_exact_17 = np.sqrt(mean_squared_error(pred_exact_17, y_test17))\n",
        "rmse_exact_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.7141038418197827\t 0.7141038418197827\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.8024876355160464\t 0.7141038418197827\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.7659849712152795\t 0.7141038418197827\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9684453836634761\t 0.7141038418197827\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.8556892362199922\t 0.7141038418197827\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.86898292288902\t 0.7141038418197827\t 0.3270025542460203\t 0.3270025542460203\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.778300364354035\t 0.7141038418197827\t 0.33036248288508874\t 0.33036248288508874\n",
            "3  \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\t 0.726434848802118\t 0.7141038418197827\t 0.32759830801541495\t 0.32759830801541495\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9672674042711217\t 0.7141038418197827\t 0.32311604618747775\t 0.32311604618747775\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.826366430225874\t 0.7141038418197827\t 0.3306791318502007\t 0.3306791318502007\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.8659399691320455\t 0.7141038418197827\t 0.3318141689458407\t 0.3318141689458407\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.7563633439329396\t 0.7141038418197827\t 0.331958861787517\t 0.331958861787517\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.861798864893942\t 0.7141038418197827\t 0.3295468862871227\t 0.3295468862871227\n",
            "9  \t [ 1.2716555   3.78378689  5.          0.57556817 17.          0.18163876]\t 0.9716163961274858\t 0.7141038418197827\t 0.3306657358607556\t 0.3306657358607556\n",
            "10 \t [1.38490793 6.87002541 5.         0.73931504 9.         0.41767138]\t 0.829976302946727\t 0.7141038418197827\t 0.3350550348654543\t 0.3350550348654543\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.8069651446453449\t 0.7141038418197827\t 0.33479364401306244\t 0.33479364401306244\n",
            "12 \t [ 0.          0.05792963  9.60265257  0.5        13.60265257  0.1       ]\t 0.9717734124498569\t 0.7141038418197827\t 0.33400432891053083\t 0.3340043167334271\n",
            "13 \t [0.  0.  5.  0.5 1.  0.1]\t 0.973743062796521\t 0.7141038418197827\t 0.3373982759705306\t 0.3373982083555756\n",
            "14 \t [ 7.35111323  4.42247898 14.          0.92954426  7.          0.31778445]\t 0.8561431043387969\t 0.7141038418197827\t 0.3404364783191504\t 0.3404364783191504\n",
            "15 \t [ 9.19532326  8.42928342 11.          0.5289521  11.          0.74996998]\t 0.7306673350944987\t 0.7141038418197827\t 0.3404952843200085\t 0.3404952843200085\n",
            "16 \t [6.14842106 3.92031042 5.         0.80436272 5.         0.42842685]\t 0.8298337600349435\t 0.7141038418197827\t 0.3388184059068429\t 0.3388184059068429\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 7.93462308 10.         14.68514013  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6458261258217902\u001b[0m\t \u001b[1m\u001b[92m0.6458261258217902\u001b[0m\t \u001b[1m\u001b[92m0.3378753586334344\u001b[0m\t \u001b[1m\u001b[92m0.3378746908751809\u001b[0m\n",
            "18 \t [ 1.83368891  8.1756677   8.          0.96471075 17.          0.14868642]\t 0.9653693800994253\t 0.6458261258217902\t 0.3346461717770013\t 0.3346461717770013\n",
            "19 \t [ 1.32113565  9.62738611 14.          0.55066636 15.          0.36069244]\t 0.8636922015613553\t 0.6458261258217902\t 0.33699873748772985\t 0.33699873748772985\n",
            "20 \t [ 6.88175573  0.68997438  9.          0.55006192 19.          0.74555899]\t 0.7341056462061506\t 0.6458261258217902\t 0.3373173662914706\t 0.3373173662914706\n",
            "21 \t [ 7.32262595  0.987487   14.          0.78324612 14.          0.76403633]\t 0.7129217809179572\t 0.6458261258217902\t 0.33565221825940234\t 0.33565221825940234\n",
            "22 \t [ 6.72796419  6.10053296 14.          0.56325639  2.          0.91580991]\t 0.672911524877989\t 0.6458261258217902\t 0.333826748722113\t 0.33382705031526155\n",
            "23 \t [ 7.07271536  8.13007518  5.          0.98530219 19.          0.92839144]\t 0.7288961616067631\t 0.6458261258217902\t 0.33209289417535554\t 0.33209289417535554\n",
            "24 \t [0.85666329 5.92364698 9.         0.69191689 5.         0.98975497]\t 0.6651465396376819\t 0.6458261258217902\t 0.3302637642494432\t 0.3302637642494432\n",
            "25 \t [9.66959108 0.03423869 5.         0.63791788 7.         0.65549808]\t 0.7797393754763862\t 0.6458261258217902\t 0.328239295482144\t 0.328239295482144\n",
            "26 \t [ 3.61406382  9.87735751 10.          0.70199599  8.          0.85082246]\t 0.721371984674188\t 0.6458261258217902\t 0.327681466009072\t 0.327681466009072\n",
            "27 \t [ 5.62137526  0.50742571 12.          0.60891749  1.          0.89299215]\t 0.6736748141470514\t 0.6458261258217902\t 0.3268752945640919\t 0.3268752945640919\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 8.00674591 10.         15.          1.         14.7502302   1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6454808272106777\u001b[0m\t \u001b[1m\u001b[92m0.6454808272106777\u001b[0m\t \u001b[1m\u001b[92m0.3248220829190007\u001b[0m\t \u001b[1m\u001b[92m0.32482104314560145\u001b[0m\n",
            "29 \t [ 0.30609514  2.49894713 14.          0.69397027 18.          0.71750058]\t 0.7193266691045255\t 0.6454808272106777\t 0.3229886579943967\t 0.3229886579943967\n",
            "30 \t [6.87315371 8.0573145  9.         0.75725    3.         0.56369239]\t 0.7599113236373156\t 0.6454808272106777\t 0.3219864927313254\t 0.321986934159379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48192.61443002094"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42ffa47-ee9a-4108-9c5e-38719fa2a0e7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_exact_18 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_18 = dGPGO(surrogate_exact_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_18 = exact_18.getResult()[0]\n",
        "params_exact_18['max_depth'] = int(params_exact_18['max_depth'])\n",
        "params_exact_18['min_child_weight'] = int(params_exact_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_exact_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_exact_18 = xgb.train(params_exact_18, dX_exact_train18)\n",
        "pred_exact_18 = model_exact_18.predict(dX_exact_test18)\n",
        "\n",
        "rmse_exact_18 = np.sqrt(mean_squared_error(pred_exact_18, y_test18))\n",
        "rmse_exact_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.9953081887469889\t 0.7220763687473127\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.7220763687473127\t 0.7220763687473127\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.9889075947558364\t 0.7220763687473127\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.7606594495187335\t 0.7220763687473127\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.7225304513182221\t 0.7220763687473127\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.8181138208820815\t 0.7220763687473127\t 0.3372234771586742\t 0.3372234771586742\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.6527007643358951\u001b[0m\t \u001b[1m\u001b[92m0.6527007643358951\u001b[0m\t \u001b[1m\u001b[92m0.3354406146334005\u001b[0m\t \u001b[1m\u001b[92m0.3354406146334005\u001b[0m\n",
            "3  \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]\t 0.7581381331811782\t 0.6527007643358951\t 0.3257793748105796\t 0.3257793748105796\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.995752758561317\t 0.6527007643358951\t 0.32295580466324597\t 0.32295580466324597\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.7153197782842456\t 0.6527007643358951\t 0.33251170803352986\t 0.33251170803352986\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 1.0132763479062032\t 0.6527007643358951\t 0.3276654135808916\t 0.3276654135808916\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 1.0120318552286456\t 0.6527007643358951\t 0.33573746679105276\t 0.33573746679105276\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.745004296865836\t 0.6527007643358951\t 0.3415726899130897\t 0.3415726899130897\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.7386631133573338\t 0.6527007643358951\t 0.3383669900754267\t 0.3383669900754267\n",
            "10 \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]\t 0.664354143494327\t 0.6527007643358951\t 0.3354354738008038\t 0.3354354790568517\n",
            "11 \t [ 0.2637722   4.11659493  5.          0.61604637 11.          0.22374653]\t 1.0148667858309313\t 0.6527007643358951\t 0.33120820493260184\t 0.33120820493260184\n",
            "12 \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]\t 0.7593781021734818\t 0.6527007643358951\t 0.33628532158442453\t 0.33628532158442453\n",
            "13 \t [ 1.3916722   9.15131624  5.          0.92812295 18.          0.82773453]\t 0.7760470257675838\t 0.6527007643358951\t 0.3344163504038887\t 0.3344163504038887\n",
            "14 \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]\t 0.8424181577085037\t 0.6527007643358951\t 0.3330860282137087\t 0.3330860282137087\n",
            "15 \t [3.36125149 0.38066674 7.         0.83604387 7.         0.55591318]\t 0.7706447307033153\t 0.6527007643358951\t 0.33324391782708507\t 0.33324391782708507\n",
            "16 \t [ 9.04557073  7.9579056  13.          0.79457459 11.          0.37545445]\t 0.832676964286102\t 0.6527007643358951\t 0.33200206398271986\t 0.33200206398271986\n",
            "17 \t [ 2.34351425  1.27586471  9.          0.74485285 16.          0.89346344]\t 0.6601079893289068\t 0.6527007643358951\t 0.3320106179139063\t 0.3320106179139063\n",
            "18 \t [ 1.87278882  0.         10.33831418  0.5         2.33831418  0.1       ]\t 1.0093178374483471\t 0.6527007643358951\t 0.32920019894965286\t 0.3292003337510998\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 1.0088210680321927\t 0.6527007643358951\t 0.3329189063078721\t 0.3329189063078721\n",
            "20 \t [ 4.76072579  8.40341692  8.52417273  1.         19.52417273  0.633643  ]\t 0.7181009685550676\t 0.6527007643358951\t 0.33591835688057853\t 0.33591892620831043\n",
            "21 \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]\t 0.8196793624782129\t 0.6527007643358951\t 0.33408193107307266\t 0.33408193107307266\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[ 5.12329501  5.46481104 15.          1.          9.5323051   1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6429163326920502\u001b[0m\t \u001b[1m\u001b[92m0.6429163326920502\u001b[0m\t \u001b[1m\u001b[92m0.3338122021915187\u001b[0m\t \u001b[1m\u001b[92m0.3338110068806767\u001b[0m\n",
            "23 \t [ 9.73631216  7.46194167 14.          0.919988    1.          0.18982878]\t 1.0037909714736977\t 0.6429163326920502\t 0.3312706296720145\t 0.3312706296720145\n",
            "24 \t [ 2.61567385  0.01777662 13.          0.8245822  14.          0.91600971]\t 0.6449654916972964\t 0.6429163326920502\t 0.3341417362308709\t 0.3341417362308709\n",
            "25 \t [1.07172211 9.91320527 6.         0.98176043 4.         0.24706724]\t 1.0106629985673714\t 0.6429163326920502\t 0.33163922159900083\t 0.33163922159900083\n",
            "26 \t [ 8.83163785  4.45932285  9.39109983  1.         16.39109983  1.        ]\t 0.6545053421299464\t 0.6429163326920502\t 0.3342713034364131\t 0.33427025645129027\n",
            "27 \t [ 2.85275846  9.66613058 14.57076379  1.         15.57076379  0.80494147]\t 0.6577462651850989\t 0.6429163326920502\t 0.3321620695704683\t 0.33216200037309557\n",
            "28 \t [0.68687496 7.61952967 6.         0.69420959 8.         0.10232955]\t 1.0098398215101554\t 0.6429163326920502\t 0.33034738313085044\t 0.33034738313085044\n",
            "29 \t [9.89337178 3.81875947 5.         0.59649267 7.         0.86884145]\t 0.7753063665062683\t 0.6429163326920502\t 0.33277714263804264\t 0.33277714263804264\n",
            "30 \t [ 0.          0.          5.          0.5        14.57048237  0.1       ]\t 1.016751509906702\t 0.6429163326920502\t 0.3319765385468809\t 0.33197596897591247\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48197.157594511"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zaPbk2uuzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3a515d-c1bb-4fe0-b1e1-be45e52d6cff"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_exact_19 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_19 = dGPGO(surrogate_exact_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_19 = exact_19.getResult()[0]\n",
        "params_exact_19['max_depth'] = int(params_exact_19['max_depth'])\n",
        "params_exact_19['min_child_weight'] = int(params_exact_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_exact_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_exact_19 = xgb.train(params_exact_19, dX_exact_train19)\n",
        "pred_exact_19 = model_exact_19.predict(dX_exact_test19)\n",
        "\n",
        "rmse_exact_19 = np.sqrt(mean_squared_error(pred_exact_19, y_test19))\n",
        "rmse_exact_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.7381578397530673\t 0.7295721630591281\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.7470234185181706\t 0.7295721630591281\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.018052265694813\t 0.7295721630591281\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.7455570460653044\t 0.7295721630591281\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.7295721630591281\t 0.7295721630591281\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.31920645780629253\u001b[0m\t \u001b[1m\u001b[92m0.31920645780629253\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.7019341665321482\t 0.6773838424850286\t 0.3115797201652415\t 0.3115797201652415\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.0199606306890758\t 0.6773838424850286\t 0.30727117328789294\t 0.30727117328789294\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.7327508164518542\t 0.6773838424850286\t 0.3214189336371386\t 0.3214189336371386\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.8626234515673594\t 0.6773838424850286\t 0.3183176431253634\t 0.3183176431253634\n",
            "6  \t [ 1.32803357  6.14469168  5.          0.5        11.31850088  0.1       ]\t 1.0123750103467304\t 0.6773838424850286\t 0.3209930457205859\t 0.3209930456587387\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[ 9.4686931  10.         13.33146213  1.          9.33146213  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6504093874669943\u001b[0m\t \u001b[1m\u001b[92m0.6504093874669943\u001b[0m\t \u001b[1m\u001b[92m0.32939114603861447\u001b[0m\t \u001b[1m\u001b[92m0.329391146038611\u001b[0m\n",
            "8  \t [ 8.91661877  0.81129414 14.          0.76941451 18.          0.38451622]\t 0.739345489918133\t 0.6504093874669943\t 0.3241413602932722\t 0.3241413602932722\n",
            "9  \t [ 7.79697396  2.4759708  14.          0.85704175 10.          0.8747867 ]\t 0.6661208346027878\t 0.6504093874669943\t 0.32199032295699176\t 0.32199032295699176\n",
            "10 \t [0.  0.  5.  0.5 1.  0.1]\t 1.012959712728477\t 0.6504093874669943\t 0.31830245134864493\t 0.31830244322446866\n",
            "11 \t [ 8.347612    9.05501181  5.          0.50033019 10.          0.41046448]\t 0.7834119309620006\t 0.6504093874669943\t 0.3247293456917465\t 0.3247293456917465\n",
            "12 \t [ 6.11039048  8.9398787   9.          0.84431675 14.          0.73928782]\t 0.7102000973560662\t 0.6504093874669943\t 0.3239807137620224\t 0.3239807137620224\n",
            "13 \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]\t 1.0149681655113947\t 0.6504093874669943\t 0.32173164347705113\t 0.32173164347705113\n",
            "14 \t [ 0.76961365  0.71322479  7.          0.76261327 16.          0.65707922]\t 0.7283281329156809\t 0.6504093874669943\t 0.32690862294640594\t 0.32690862294640594\n",
            "15 \t [ 5.84124648  6.227347   10.00656641  1.         20.          1.        ]\t 0.6567579646960292\t 0.6504093874669943\t 0.32509691026755916\t 0.3250969108435748\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.7391934581482711\t 0.6504093874669943\t 0.3222359342892445\t 0.3222359342892445\n",
            "17 \t [9.42305669 0.3423134  7.         0.77066127 8.         0.63693457]\t 0.7280806792663158\t 0.6504093874669943\t 0.32098686179146335\t 0.32098686179146335\n",
            "18 \t [ 9.95511956  7.60041193  6.          0.68015183 19.          0.83239317]\t 0.709906904841392\t 0.6504093874669943\t 0.31966261762023207\t 0.31966261762023207\n",
            "19 \t [ 1.5998037   2.07899705 13.          0.69607466 16.          0.66181568]\t 0.7053392217903056\t 0.6504093874669943\t 0.31816464714794046\t 0.31816464714794046\n",
            "20 \t [ 9.47745808  9.50911305 13.          0.70555451  1.          0.87222907]\t 0.6776716071409558\t 0.6504093874669943\t 0.316717619229422\t 0.316717619229422\n",
            "21 \t [ 3.16526468  9.88957695 14.          0.66718624  2.          0.49421519]\t 0.754638877583424\t 0.6504093874669943\t 0.314994052667432\t 0.314994052667432\n",
            "22 \t [ 2.09634932  0.14030298  6.          0.5964387  10.          0.52444645]\t 0.7482123766842939\t 0.6504093874669943\t 0.3144694527177299\t 0.3144694527177299\n",
            "23 \t [1.60895472e-01 8.27074864e-03 1.30000000e+01 6.91893018e-01\n",
            " 5.00000000e+00 4.60327119e-01]\t 0.7458028061131368\t 0.6504093874669943\t 0.31389218171617544\t 0.31389218171617544\n",
            "24 \t [9.2527463  5.48357582 5.         0.70904629 2.         0.53145819]\t 0.7709681184461903\t 0.6504093874669943\t 0.31332267534883984\t 0.31332267534883984\n",
            "25 \t [ 8.28202559  0.45721202  6.          0.9018841  19.          0.27559296]\t 0.8619873306358585\t 0.6504093874669943\t 0.31312603480379253\t 0.31312603480379253\n",
            "26 \t [ 3.61202122  0.         10.58038252  0.5         1.          0.1       ]\t 1.018785316316397\t 0.6504093874669943\t 0.3141998311783506\t 0.3141995704092779\n",
            "27 \t [ 4.59052191  5.6077033  13.99546761  1.          4.99546761  1.        ]\t 0.6517331858361427\t 0.6504093874669943\t 0.31759349704930195\t 0.3175935169044815\n",
            "28 \t [8.3735996  5.34104024 8.         0.56456303 7.         0.59553385]\t 0.7245806620781778\t 0.6504093874669943\t 0.3159525508924227\t 0.3159528454902746\n",
            "29 \t [1.29619202 7.0308562  6.30562327 0.5        1.         0.1       ]\t 1.014538930910223\t 0.6504093874669943\t 0.315170980668318\t 0.3151710736206701\n",
            "30 \t [ 9.80949062  0.42526047 11.          0.61085682  4.          0.94165398]\t 0.6776829311951872\t 0.6504093874669943\t 0.3181661098508785\t 0.3181661098508785\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49131.68094915563"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkuHKlQuxRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a3d209-59e3-4ecf-9903-5cd3b22a668c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_exact_20 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_20 = dGPGO(surrogate_exact_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_20 = exact_20.getResult()[0]\n",
        "params_exact_20['max_depth'] = int(params_exact_20['max_depth'])\n",
        "params_exact_20['min_child_weight'] = int(params_exact_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_exact_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_exact_20 = xgb.train(params_exact_20, dX_exact_train20)\n",
        "pred_exact_20 = model_exact_20.predict(dX_exact_test20)\n",
        "\n",
        "rmse_exact_20 = np.sqrt(mean_squared_error(pred_exact_20, y_test20))\n",
        "rmse_exact_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.6597299542050263\t 0.6597299542050263\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.6983733363249625\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0633118913318171\t 0.6597299542050263\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.8790653027854468\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.8778581695963045\t 0.6597299542050263\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.8825953654337161\t 0.6597299542050263\t 0.3383723349263821\t 0.3383723349263821\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0635732061044851\t 0.6597299542050263\t 0.3403957614639891\t 0.3403957614639891\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[10.        10.        15.         1.        17.4599503  1.       ]\u001b[0m\t \u001b[1m\u001b[92m0.6401374028449338\u001b[0m\t \u001b[1m\u001b[92m0.6401374028449338\u001b[0m\t \u001b[1m\u001b[92m0.35360385401873795\u001b[0m\t \u001b[1m\u001b[92m0.3536038540187377\u001b[0m\n",
            "4  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0679096170180373\t 0.6401374028449338\t 0.3428679911528112\t 0.3428679911514544\n",
            "5  \t [ 7.50758902  2.31989813 13.          0.92794435  1.          0.52943075]\t 0.7559982376783114\t 0.6401374028449338\t 0.35307752448856916\t 0.35307752448856916\n",
            "6  \t [ 0.55198982  4.75264073 14.          0.93528567 13.          0.58376745]\t 0.7405528896365979\t 0.6401374028449338\t 0.3482722080158299\t 0.3482722080158299\n",
            "7  \t [ 1.01837104  4.41995744  6.          0.52021829 12.          0.99601116]\t 0.7078573361250974\t 0.6401374028449338\t 0.34396878828938793\t 0.34396878828938793\n",
            "8  \t [ 0.54239845  2.74182658 10.          0.793938    8.          0.40512022]\t 0.8006633302852804\t 0.6401374028449338\t 0.3391122265339446\t 0.3391122265339446\n",
            "9  \t [1.40842154 7.81898154 9.         0.57297042 1.         0.11610409]\t 1.0651952678837315\t 0.6401374028449338\t 0.3376381150213154\t 0.3376381150213154\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.8036859734991779\t 0.6401374028449338\t 0.34473779663987053\t 0.34473779663987053\n",
            "11 \t [ 9.3606342   3.21248061 14.          0.65614013 17.          0.10926152]\t 1.0624486911635314\t 0.6401374028449338\t 0.3430623916947627\t 0.3430623916947627\n",
            "12 \t [ 1.82697381  3.23883023 14.          0.52727974  1.          0.42452427]\t 0.828664138263217\t 0.6401374028449338\t 0.3486608859186337\t 0.3486608859186337\n",
            "13 \t [ 3.51322154  8.79998304 14.          0.91142182  1.          0.35103611]\t 0.8922088424958478\t 0.6401374028449338\t 0.3477288554047331\t 0.3477288554047331\n",
            "14 \t [ 2.78517086  0.20608894 12.          0.52669069 17.          0.68320382]\t 0.6983391825028334\t 0.6401374028449338\t 0.3480910566381251\t 0.3480910566381251\n",
            "15 \t [ 9.90619221  7.05528672  5.          0.91932487 18.          0.63366006]\t 0.7328927505356351\t 0.6401374028449338\t 0.3448776589718129\t 0.3448776589718129\n",
            "16 \t [ 7.65146653  2.36586786 13.          0.71989624  7.          0.80860445]\t 0.6888973472758477\t 0.6401374028449338\t 0.34235322712881844\t 0.34235322712881844\n",
            "17 \t [ 8.3723055   9.68266939 11.          0.50145124  1.          0.82596229]\t 0.7117644991570005\t 0.6401374028449338\t 0.3394426684148542\t 0.3394426684148542\n",
            "18 \t [ 9.6068935   0.80663714  8.          0.73945426 19.          0.81169876]\t 0.6946194207600972\t 0.6401374028449338\t 0.3371186313241651\t 0.3371186313241651\n",
            "19 \t [0.74035504 4.5748447  5.         0.89363317 5.         0.49127349]\t 0.8310222116990836\t 0.6401374028449338\t 0.33473344047044545\t 0.33473344047044545\n",
            "20 \t [9.77613663 2.80327235 8.         0.65089037 2.         0.68605672]\t 0.7015374046471099\t 0.6401374028449338\t 0.3346004947237828\t 0.3346004947237828\n",
            "21 \t [ 2.16891361  0.40236972  6.          0.57865056 19.          0.33900997]\t 0.8933558323113931\t 0.6401374028449338\t 0.33265905721604366\t 0.33265905721604366\n",
            "22 \t [ 9.41379303  0.90177992 11.          0.70724067 13.          0.84884535]\t 0.6905070716835877\t 0.6401374028449338\t 0.3335316413059656\t 0.3335316413059656\n",
            "23 \t [ 5.86852957  9.2552543  14.          0.74343957 14.          0.26209686]\t 0.8830540745289366\t 0.6401374028449338\t 0.33156266917298766\t 0.33156266917298766\n",
            "24 \t [8.80668839 9.74974177 8.         0.78186711 8.         0.24236328]\t 1.0595424210891182\t 0.6401374028449338\t 0.33239198514905266\t 0.33239198514905266\n",
            "25 \t [ 0.83358887  9.71793838 12.          0.52075624 11.          0.67770945]\t 0.6983988113329787\t 0.6401374028449338\t 0.335843707006409\t 0.335843707006409\n",
            "26 \t [ 0.96616103  8.61825128  6.          0.54652057 18.          0.73561745]\t 0.7195663176706344\t 0.6401374028449338\t 0.3340942287495572\t 0.3340942287495572\n",
            "27 \t [10.          7.90969886 10.45083702  1.         20.          1.        ]\t 0.6438960621134096\t 0.6401374028449338\t 0.332680920534472\t 0.3326797955391764\n",
            "28 \t [0.         0.         5.         0.5        9.85493975 0.1       ]\t 1.0673951734730103\t 0.6401374028449338\t 0.33057482988192194\t 0.33057393380710104\n",
            "29 \t [ 7.19997824  0.84742136  6.29869529  0.5        12.29869529  0.1       ]\t 1.0658522980140046\t 0.6401374028449338\t 0.3338605553174134\t 0.3338597827083278\n",
            "30 \t [ 0.89195001  6.01604215 14.          0.84121292  7.          0.44798682]\t 0.8038070345544759\t 0.6401374028449338\t 0.3369014873416536\t 0.3369014939610592\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48896.62839356588"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKuwvS3uzrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c86893-1d61-47a2-ba75-4acc1c71a9e5"
      },
      "source": [
        "end_exact = time.time()\n",
        "end_exact\n",
        "\n",
        "time_exact = end_exact - start_exact\n",
        "time_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2043.581844329834"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59b31c2-5f42-4e6a-b6fd-2c04a9087612"
      },
      "source": [
        "rmse_approx = [rmse_approx_1,\n",
        "rmse_approx_2,\n",
        "rmse_approx_3,\n",
        "rmse_approx_4,\n",
        "rmse_approx_5,\n",
        "rmse_approx_6,\n",
        "rmse_approx_7,\n",
        "rmse_approx_8,\n",
        "rmse_approx_9,\n",
        "rmse_approx_10,\n",
        "rmse_approx_11,\n",
        "rmse_approx_12,\n",
        "rmse_approx_13,\n",
        "rmse_approx_14,\n",
        "rmse_approx_15,\n",
        "rmse_approx_16,\n",
        "rmse_approx_17,\n",
        "rmse_approx_18,\n",
        "rmse_approx_19,\n",
        "rmse_approx_20]\n",
        "\n",
        "np.mean(rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50246.38246783489"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ53FsWXu3J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2aa57f-a074-4135-d1d0-572f3659de04"
      },
      "source": [
        "rmse_exact = [rmse_exact_1,\n",
        "rmse_exact_2,\n",
        "rmse_exact_3,\n",
        "rmse_exact_4,\n",
        "rmse_exact_5,\n",
        "rmse_exact_6,\n",
        "rmse_exact_7,\n",
        "rmse_exact_8,\n",
        "rmse_exact_9,\n",
        "rmse_exact_10,\n",
        "rmse_exact_11,\n",
        "rmse_exact_12,\n",
        "rmse_exact_13,\n",
        "rmse_exact_14,\n",
        "rmse_exact_15,\n",
        "rmse_exact_16,\n",
        "rmse_exact_17,\n",
        "rmse_exact_18,\n",
        "rmse_exact_19,\n",
        "rmse_exact_20]\n",
        "\n",
        "np.mean(rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49378.55659368912"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9FOyoH8u5Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4beda122-2c35-4e95-8148-7fec7c280648"
      },
      "source": [
        "min_rmse_approx = min_max_array(rmse_approx)\n",
        "min_rmse_approx, len(min_rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([48973.66312746987,\n",
              "  48973.66312746987,\n",
              "  48925.8432544791,\n",
              "  48925.8432544791,\n",
              "  48925.8432544791,\n",
              "  48925.8432544791,\n",
              "  48925.8432544791,\n",
              "  48925.8432544791,\n",
              "  48075.00995818073,\n",
              "  48075.00995818073,\n",
              "  48075.00995818073,\n",
              "  48075.00995818073,\n",
              "  48075.00995818073,\n",
              "  48075.00995818073,\n",
              "  48075.00995818073,\n",
              "  48075.00995818073,\n",
              "  47888.08332240055,\n",
              "  47888.08332240055,\n",
              "  47888.08332240055,\n",
              "  47888.08332240055],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b70e0f-0520-4bbb-ce4f-31ebb6af57ba"
      },
      "source": [
        "min_rmse_exact = min_max_array(rmse_exact)\n",
        "min_rmse_exact, len(min_rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([47122.48782091602,\n",
              "  47122.48782091602,\n",
              "  47122.48782091602,\n",
              "  47122.48782091602,\n",
              "  47122.48782091602,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453,\n",
              "  46629.15174803453],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d23e508-3f63-46fc-d38c-22895fd8c188"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_approx, color = 'Green', label='RMSE: Approx GP ERM gradients')\n",
        "plt.plot(min_rmse_exact, color = 'Blue', label='RMSE: Exact GP dERM gradients', ls='--')# r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold', family = 'Arial') # x-axis label\n",
        "plt.ylabel('RMSE (US Dollars $)', weight = 'bold', family = 'Arial') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_approx)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualise!\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4a7852-a153-4659-deaf-dcb3c0300f9d"
      },
      "source": [
        "time_approx, time_exact\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2079.729005098343, 2043.581844329834)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abda6b6f-db63-4939-c9aa-a781ee7a8f19"
      },
      "source": [
        "min(min_rmse_exact), min(min_rmse_approx)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46629.15174803453, 47888.08332240055)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNBRy3W0GY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}