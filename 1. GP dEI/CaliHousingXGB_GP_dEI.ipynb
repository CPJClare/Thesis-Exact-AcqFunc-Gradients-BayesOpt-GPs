{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9wHutsqZUcn"
      },
      "source": [
        "XGBoost Regression - 'real-world' example: Californian Housing Dataset\n",
        "\n",
        "https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-0Pe1i4Z2R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4da9353-13e1-4508-fed9-0d63cc62d336"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyGPGO\n",
            "  Downloading pyGPGO-0.5.1.tar.gz (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.21.6)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (2019.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.7.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.2)\n",
            "Collecting Theano-PyMC\n",
            "  Downloading Theano-PyMC-1.1.2.tar.gz (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 3.5 MB/s \n",
            "\u001b[?25hCollecting pyMC3\n",
            "  Downloading pymc3-3.11.5-py3-none-any.whl (872 kB)\n",
            "\u001b[K     |████████████████████████████████| 872 kB 38.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->pyGPGO) (2022.1.0)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.0.3)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.2)\n",
            "Requirement already satisfied: arviz>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.12.1)\n",
            "Collecting semver>=2.13.0\n",
            "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting deprecat\n",
            "  Downloading deprecat-2.1.1-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.3.5.1)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.2.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from Theano-PyMC->pyGPGO) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (21.3)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (1.6.0)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (57.4.0)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.20.2)\n",
            "Requirement already satisfied: xarray-einstats>=0.2 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (0.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from arviz>=0.11.0->pyMC3->pyGPGO) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->arviz>=0.11.0->pyMC3->pyGPGO) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->pyMC3->pyGPGO) (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->pyMC3->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (4.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecat->pyMC3->pyGPGO) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->xarray>=0.16.1->arviz>=0.11.0->pyMC3->pyGPGO) (3.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.7/dist-packages (from netcdf4->arviz>=0.11.0->pyMC3->pyGPGO) (1.6.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyGPGO) (3.1.0)\n",
            "Building wheels for collected packages: pyGPGO, Theano-PyMC\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.5.1-py3-none-any.whl size=19879 sha256=3a7948fc776e14ef0a805ccb60962305c2fdc1dc03a85c646d7e9d592422315d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5d/0b/2160114e2f1b87791c51b66cf07f89831dbb6f49167950316f\n",
            "  Building wheel for Theano-PyMC (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Theano-PyMC: filename=Theano_PyMC-1.1.2-py3-none-any.whl size=1529963 sha256=d2cc9bb039c7abc048f3cd6f4b0ea96f78a9e517dca71f24ae802f10d496ebbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/af/8c/5dd7553522d74c52a7813806fc7ee1a9caa20a3f7c8fd850d5\n",
            "Successfully built pyGPGO Theano-PyMC\n",
            "Installing collected packages: Theano-PyMC, semver, deprecat, pyMC3, pyGPGO\n",
            "Successfully installed Theano-PyMC-1.1.2 deprecat-2.1.1 pyGPGO-0.5.1 pyMC3-3.11.5 semver-2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7zDTf1naBsH"
      },
      "source": [
        "# Load some default Python modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "from matplotlib.pyplot import rc\n",
        "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
        "rc('text', usetex=False)\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import norm\n",
        "from joblib import Parallel, delayed\n",
        "import itertools\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "from pandas_datareader import data\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXicekJhaE0P"
      },
      "source": [
        "# Read data in pandas dataframe:\n",
        "df_train =  pd.read_csv('/content/sample_data/california_housing_train.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0mDzt_cBmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "95f6eb09-fde3-4108-d162-a6ca21aa239a"
      },
      "source": [
        "# List first rows:\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be308c76-18d9-46de-ad9e-512ee39596ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be308c76-18d9-46de-ad9e-512ee39596ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be308c76-18d9-46de-ad9e-512ee39596ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be308c76-18d9-46de-ad9e-512ee39596ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTVDAD2KchTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec53227-e715-4495-9009-7114efb8a2a8"
      },
      "source": [
        "# Remove missing data:\n",
        "\n",
        "df_train = df_train.dropna(how = 'any', axis = 'rows')\n",
        "print('New size: %d' % len(df_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New size: 17000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXgSHPyYcnuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "2f8cec14-f04c-4511-f48e-5a8a5890580c"
      },
      "source": [
        "# Histogram fare plot:\n",
        "\n",
        "df_train.median_house_value.hist(bins=100, figsize=(16,5), color = \"red\")\n",
        "plt.xlabel('$ US Dollars', weight = 'bold', family = 'Arial')\n",
        "plt.title('Median Californian House Price', weight = 'bold', family = 'Arial')\n",
        "plt.grid(b=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMSdAAjcr4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0ac7d6-9d15-4e53-c936-800e647dcbbe"
      },
      "source": [
        "y = df_train.median_house_value.values + 1e-10\n",
        "y ### for supervised learning: output vector y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 66900.,  80100.,  85700., ..., 103600.,  85800.,  94600.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FOeHvi3cu1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "75ad5421-b1b0-46e9-9e97-208aa3c88121"
      },
      "source": [
        "# List first rows (post-cleaning):\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1015.0       472.0         1.4936             66900.0  \n",
              "1      1129.0       463.0         1.8200             80100.0  \n",
              "2       333.0       117.0         1.6509             85700.0  \n",
              "3       515.0       226.0         3.1917             73400.0  \n",
              "4       624.0       262.0         1.9250             65500.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f96609d7-867a-457b-9ad2-3dfb8cc293a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f96609d7-867a-457b-9ad2-3dfb8cc293a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f96609d7-867a-457b-9ad2-3dfb8cc293a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f96609d7-867a-457b-9ad2-3dfb8cc293a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-lT9BBicw4P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8566e416-2b7a-46ba-b1c4-e02a03f1093b"
      },
      "source": [
        "X = df_train.drop(['median_house_value'], axis = 1)\n",
        "X.head() ### for supervised learning: input matrix X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1    -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2    -114.56     33.69                17.0        720.0           174.0   \n",
              "3    -114.57     33.64                14.0       1501.0           337.0   \n",
              "4    -114.57     33.57                20.0       1454.0           326.0   \n",
              "\n",
              "   population  households  median_income  \n",
              "0      1015.0       472.0         1.4936  \n",
              "1      1129.0       463.0         1.8200  \n",
              "2       333.0       117.0         1.6509  \n",
              "3       515.0       226.0         3.1917  \n",
              "4       624.0       262.0         1.9250  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d4824d9-cf41-4ce8-a30b-e01ba2c9da89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d4824d9-cf41-4ce8-a30b-e01ba2c9da89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d4824d9-cf41-4ce8-a30b-e01ba2c9da89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d4824d9-cf41-4ce8-a30b-e01ba2c9da89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eC8SDPzczNY"
      },
      "source": [
        "### Optimum rmse: regression model objective function is Root Mean Square Error (RMSE); \n",
        "### Should be minimized (as close to zero as possible):\n",
        "\n",
        "y_global_orig = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoTmWEhSc1qQ"
      },
      "source": [
        "### Bayesian Optimization - inputs:\n",
        "\n",
        "obj_func = 'XGBoost'\n",
        "n_test = 500 # test points\n",
        "\n",
        "util = 'EI'\n",
        "n_init = 5 # random initialisations\n",
        "opt = True\n",
        "\n",
        "test_perc = 0.1\n",
        "train_perc = 1 - test_perc\n",
        "\n",
        "n_test = int(len(df_train) * test_perc)\n",
        "n_train = int(len(df_train) - n_test)\n",
        "\n",
        "eps = 1e-08"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ngnRxbc7cg"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'XGBoost': # 6-D\n",
        "            \n",
        "    # Constraints:\n",
        "    param_lb_alpha = 0\n",
        "    param_ub_alpha = 10\n",
        "    \n",
        "    param_lb_gamma = 0\n",
        "    param_ub_gamma = 10\n",
        "    \n",
        "    param_lb_max_depth = 5\n",
        "    param_ub_max_depth = 15\n",
        "    \n",
        "    param_lb_min_child_weight = 1\n",
        "    param_ub_min_child_weight = 20\n",
        "    \n",
        "    param_lb_subsample = .5\n",
        "    param_ub_subsample = 1\n",
        "    \n",
        "    param_lb_colsample = .1\n",
        "    param_ub_colsample = 1\n",
        "    \n",
        "    # 6-D inputs' parameter bounds:\n",
        "    param = { 'alpha':  ('cont', (param_lb_alpha, param_ub_alpha)),\n",
        "         'gamma':  ('cont', (param_lb_gamma, param_ub_gamma)),     \n",
        "         'max_depth':  ('int', (param_lb_max_depth, param_ub_max_depth)),\n",
        "         'subsample':  ('cont', (param_lb_subsample, param_ub_subsample)),\n",
        "          'min_child_weight':  ('int', (param_lb_min_child_weight, param_ub_min_child_weight)),\n",
        "            'colsample': ('cont', (param_lb_colsample, param_ub_colsample))\n",
        "        }\n",
        "       \n",
        "    # True y bounds:\n",
        "    dim = 6\n",
        "    \n",
        "    max_iter = 30  # iterations of Bayesian optimization\n",
        "    \n",
        "    operator = 1 \n",
        "    \n",
        "    n_est = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3pmZYhVl9Hb"
      },
      "source": [
        "n_start_AcqFunc = max_iter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmJsNX29c_xA"
      },
      "source": [
        "### Surrogate derivatives: \n",
        "\n",
        "cov_func = squaredExponential()\n",
        "\n",
        "def kronDelta(X, Xstar):                     # Kronecker's Delta method\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\n",
        "\n",
        "def se(X, Xstar, sigmaf, l, sigman):         # S.E. kernel method\n",
        "    return sigmaf * np.exp(-0.5 * cdist(X, Xstar) ** 2 / l ** 2) + sigman * kronDelta(X, Xstar)\n",
        "\n",
        "def delta(X, Xstar):                         # Distance between training X and test Xstar vectors\n",
        "    return (X - Xstar)\n",
        "   \n",
        "def der_covmat(X, Xstar, sigmaf, l, sigman): # Covariance matrix derivative terms (i.e. exact, first-order)\n",
        "    nx = len(X)\n",
        "    ny = len(Xstar)\n",
        "    return np.round(np.array([(delta(np.atleast_2d(i), np.atleast_2d(j))[0] * se(np.atleast_2d(i), np.atleast_2d(j), sigmaf, l, sigman)[0]).sum() for (i, j) in itertools.product(X, Xstar)]).reshape(nx, ny), 8)\n",
        "\n",
        "class dGaussianProcess(GaussianProcess):    # Via inheritance, also optimises hyperparameters when opt = TRUE\n",
        "    \n",
        "    def AcqGrad(self, Xstar):               # Method returning exact, first-order derivatives of the GP's posterior mean and standard deviation\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = self.covfunc.K(self.X, Xstar).T\n",
        "        \n",
        "        dKstar = der_covmat(self.X, Xstar, self.covfunc.sigmaf, self.covfunc.l, self.covfunc.sigman).T\n",
        "        alpha_Kstar = np.dot(np.linalg.inv(self.K + (self.covfunc.sigman**2) * np.eye(len(self.X))), Kstar.T)\n",
        "        \n",
        "        dm = np.dot(dKstar, self.alpha)\n",
        "        ds = -2 * np.dot(dKstar, alpha_Kstar)\n",
        "        \n",
        "        return dm, ds           \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ZuEB2VdE0W"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 1\n",
        "run_num_2 = 2\n",
        "run_num_3 = 3\n",
        "run_num_4 = 4\n",
        "run_num_5 = 5\n",
        "run_num_6 = 6\n",
        "run_num_7 = 7\n",
        "run_num_8 = 8\n",
        "run_num_9 = 9\n",
        "run_num_10 = 10\n",
        "run_num_11 = 11\n",
        "run_num_12 = 12\n",
        "run_num_13 = 13\n",
        "run_num_14 = 14\n",
        "run_num_15 = 15\n",
        "run_num_16 = 16\n",
        "run_num_17 = 17\n",
        "run_num_18 = 18\n",
        "run_num_19 = 19\n",
        "run_num_20 = 20\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgHMFEyPdCk4"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Add exact acquisition function gradient as attribute:\n",
        "\n",
        "class Acquisition_grad(Acquisition):    \n",
        "    def __init__(self, mode, eps=eps, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'EI': self.EI\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "    \n",
        "    def EI(self, tau, mean, std, ds, dm):\n",
        "        gamma = (mean - tau - self.eps) / (std + self.eps)\n",
        "        gamma_h = (mean - tau) / (std + self.eps)\n",
        "        dsdx = ds / (2 * (std + self.eps))\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\n",
        "        \n",
        "        f = (std + self.eps) * (gamma * norm.cdf(gamma) + norm.pdf(gamma))\n",
        "        df1 = f / (std + self.eps) * dsdx \n",
        "        df2 = (std + self.eps) * norm.cdf(gamma) * dmdx\n",
        "        df = (df1 + df2)[0]\n",
        "        df_arr = []\n",
        "\n",
        "        for j in range(0, dim):\n",
        "          df_arr.append(df)\n",
        "        return f, np.asarray(df_arr).transpose()\n",
        "        \n",
        "    def d_eval(self, tau, mean, std, ds, dm):\n",
        "    \n",
        "        return self.f(tau, mean, std, ds, dm, **self.params)\n",
        "        "
      ],
      "metadata": {
        "id": "ZIh5RYGkwBUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAK8N5bwfuJ7"
      },
      "source": [
        "## GPGO_multi: \n",
        "\n",
        "class GPGO_multi(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        " \n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm)\n",
        "\n",
        "        return -f\n",
        "   \n",
        "    def _optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        \n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr        \n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_exact = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_exact = np.empty((n_start,))\n",
        "        opt_exact = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_exact = np.array([res.x for res in opt_exact])\n",
        "        f_best_exact = np.array([np.atleast_1d(res.fun)[0] for res in opt_exact])\n",
        "        f_best_min_exact = min(f_best_exact)\n",
        "\n",
        "        self.x_best_exact = x_best_exact\n",
        "        self.f_best_exact = f_best_exact\n",
        "        self.f_best_min_exact = f_best_min_exact\n",
        "        self.best_exact = x_best_exact[np.argmin(f_best_exact)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_exact)\n",
        "\n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_exact = str(inverse * self.f_best_min_exact)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_exact = BOLD + OKGREEN + max_acqfunc_exact + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc_exact, max_acqfunc))\n",
        "        \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self._optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S422jNLsdIMm"
      },
      "source": [
        "## dGPGO:\n",
        "\n",
        "class dGPGO(GPGO):\n",
        "    n_start = n_start_AcqFunc\n",
        "\n",
        "    def __init__(self, surrogate, acquisition, f, parameter_dict, n_jobs=1):\n",
        "        self.GP = surrogate\n",
        "        self.A = acquisition\n",
        "        self.f = f\n",
        "        self.parameters = parameter_dict\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.parameter_key = list(parameter_dict.keys())\n",
        "        self.parameter_value = list(parameter_dict.values())\n",
        "        self.parameter_type = [p[0] for p in self.parameter_value]\n",
        "        self.parameter_range = [p[1] for p in self.parameter_value]\n",
        "\n",
        "        self.history = []\n",
        "        self.header =   'Evaluation \\t Proposed point \\t  Current eval. \\t  Best eval. \\t         Max. ExactAcqFunc \\t Max. ApproxAcqFunc '\n",
        "        self.template = '{:3}\\t {}\\t {:3}\\t {:3}\\t {:3}\\t {:3}'\n",
        "\n",
        "    def acqfuncExact(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm)\n",
        "\n",
        "        return -f, -df\n",
        "   \n",
        "    def acqfuncApprox(self, xnew, n_start=n_start_AcqFunc):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + eps)\n",
        "        dm, ds = self.GP.AcqGrad(xnew)\n",
        "        f, df = self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm)\n",
        "\n",
        "        return -f\n",
        "\n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start_AcqFunc):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncExact,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "        f_best_min = min(f_best)\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.f_best_min = f_best_min\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min)\n",
        "\n",
        "        x_best_approx = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best_approx = np.empty((n_start,))\n",
        "        opt_approx = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.acqfuncApprox,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = False,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best_approx = np.array([res.x for res in opt_approx])\n",
        "        f_best_approx = np.array([np.atleast_1d(res.fun)[0] for res in opt_approx])\n",
        "        f_best_min_approx = min(f_best_approx)\n",
        "\n",
        "        self.x_best_approx = x_best_approx\n",
        "        self.f_best_approx = f_best_approx\n",
        "        self.f_best_min_approx = f_best_min_approx\n",
        "        self.best_approx = x_best_approx[np.argmin(f_best_approx)]\n",
        "        self.start_points_arr = start_points_arr\n",
        "        self.history.append(self.f_best_min_approx)\n",
        "    \n",
        "    def _printInit(self):\n",
        "        print(self.header)\n",
        "        inverse = -1\n",
        "        for init_eval in range(self.init_evals):\n",
        "            print(self.template.format('init', self.GP.X[init_eval], inverse * self.GP.y[init_eval], inverse * self.tau, '', ''))\n",
        "      \n",
        "    def _printCurrent(self):\n",
        "        OKGREEN = '\\033[92m'\n",
        "        ENDC = '\\033[0m'\n",
        "        BOLD = '\\033[1m'\n",
        "        inverse = -1\n",
        "        eval = str(len(self.GP.y) - self.init_evals)\n",
        "        proposed = str(self.best)\n",
        "        curr_eval = str(inverse * self.GP.y[-1])\n",
        "        curr_best = str(inverse * self.tau)\n",
        "        max_acqfunc = str(inverse * self.f_best_min)\n",
        "        max_acqfunc_approx = str(inverse * self.f_best_min_approx)\n",
        "        if float(curr_eval) <= float(curr_best):\n",
        "            eval = BOLD + OKGREEN + eval + ENDC\n",
        "            proposed = BOLD + OKGREEN + proposed + ENDC\n",
        "            curr_eval = BOLD + OKGREEN + curr_eval + ENDC\n",
        "            curr_best = BOLD + OKGREEN + curr_best + ENDC\n",
        "            max_acqfunc = BOLD + OKGREEN + max_acqfunc + ENDC\n",
        "            max_acqfunc_approx = BOLD + OKGREEN + max_acqfunc_approx + ENDC\n",
        "        print(self.template.format(eval, proposed, curr_eval, curr_best, max_acqfunc, max_acqfunc_approx))\n",
        "\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self._printInit()\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self._printCurrent()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlilveEgdIR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d429f192-2fa7-4b79-cf1f-8001d2b6522e"
      },
      "source": [
        "start_approx = time.time()\n",
        "start_approx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663852393.9629128"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlzDSHbUG-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c35a8d9-5815-4317-fd34-30c11c57b423"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_approx_1 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_1 = GPGO_multi(surrogate_approx_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # define BayesOpt\n",
        "approx_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_1 = approx_1.getResult()[0]\n",
        "params_approx_1['max_depth'] = int(params_approx_1['max_depth'])\n",
        "params_approx_1['min_child_weight'] = int(params_approx_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_approx_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_approx_1 = xgb.train(params_approx_1, dX_approx_train1)\n",
        "pred_approx_1 = model_approx_1.predict(dX_approx_test1)\n",
        "\n",
        "rmse_approx_1 = np.sqrt(mean_squared_error(pred_approx_1, y_test1))\n",
        "rmse_approx_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 1.0028690365100252\t 0.6536753952667645\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7391862019705779\t 0.6536753952667645\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8806962872539386\t 0.6536753952667645\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.6536753952667645\t 0.6536753952667645\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 1.062518544792604\t 0.6536753952667645\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8659738506300403\t 0.6536753952667645\t 0.7709551930853659\t 0.7709551930853659\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 1.0589776023267656\t 0.6536753952667645\t 0.7701844514649209\t 0.7701844514649209\n",
            "3  \t [ 3.61274713  8.16007507 11.          0.84840025 19.          0.76215891]\t 0.6771887207267527\t 0.6536753952667645\t 0.7787070305878608\t 0.7787070305878608\n",
            "4  \t [ 9.28266952  0.44927819  7.          0.97265422 12.          0.93288355]\t 0.6820774846874944\t 0.6536753952667645\t 0.7709451767560833\t 0.7709451767560833\n",
            "5  \t [7.26893753 4.77012994 6.         0.80503254 3.         0.5748569 ]\t 0.8345963893957073\t 0.6536753952667645\t 0.7649651639686715\t 0.7649651639679055\n",
            "6  \t [ 5.1476318   2.63826491  5.          0.83046451 17.          0.39543049]\t 0.9004243658767852\t 0.6536753952667645\t 0.7641729579835587\t 0.7641729579835587\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 1.0042308077866626\t 0.6536753952667645\t 0.765328976833414\t 0.765328976833414\n",
            "8  \t [1.97196346 6.91027342 6.         0.70962747 4.         0.32017066]\t 1.003362317360003\t 0.6536753952667645\t 0.7691383331609416\t 0.7691383331437716\n",
            "9  \t [ 2.08878558  0.52993661 12.          0.75288969  1.          0.24822289]\t 1.0632523501795186\t 0.6536753952667645\t 0.7723189749379175\t 0.7723189745720467\n",
            "10 \t [ 9.11336104  7.53362458  9.          0.74107696 16.          0.6810286 ]\t 0.7469510576000753\t 0.6536753952667645\t 0.7765400539893954\t 0.7765400539893954\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 1.061946992849472\t 0.6536753952667645\t 0.7736779769883559\t 0.7736779769883559\n",
            "12 \t [ 1.88604523  9.48103721 11.          0.62052948 13.          0.76002949]\t 0.6847474575843426\t 0.6536753952667645\t 0.7772503052542443\t 0.7772503052542443\n",
            "13 \t [ 0.31984184  8.77960419  5.          0.79374224 16.          0.99761184]\t 0.7310969316491746\t 0.6536753952667645\t 0.7737912659369114\t 0.7737912659369114\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7499303794197336\t 0.6536753952667645\t 0.7713260740317156\t 0.7713260740317156\n",
            "15 \t [ 9.20512342  1.60831322 11.          0.87041344  2.          0.50117029]\t 0.8186293003915115\t 0.6536753952667645\t 0.7693638268576936\t 0.7693638237268244\n",
            "16 \t [ 0.28990425  5.36117717 14.          0.57624837 11.          0.76620972]\t 0.684834878460344\t 0.6536753952667645\t 0.7685109630294742\t 0.7685102310780434\n",
            "17 \t [ 9.05451551  8.43196135 13.          0.88399349 12.          0.71276317]\t 0.7394602490781731\t 0.6536753952667645\t 0.766103147889369\t 0.766103147889369\n",
            "18 \t [7.53620606 9.21585827 9.         0.6102649  4.         0.74959467]\t 0.7555390919337681\t 0.6536753952667645\t 0.7645133595147442\t 0.7645133595147442\n",
            "19 \t [0.02000301 0.98539011 7.         0.81225498 5.         0.83272223]\t 0.7016321198241581\t 0.6536753952667645\t 0.7632324168559921\t 0.7632324168559921\n",
            "20 \t [ 5.83284604  4.19854596  7.          0.61565946 12.          0.69058075]\t 0.7667881430973947\t 0.6536753952667645\t 0.7614889780926208\t 0.7614887328582629\n",
            "21 \t [ 8.31884352  7.48611185 14.          0.79056923 18.          0.91287819]\t 0.6570802060505262\t 0.6536753952667645\t 0.7605564590594969\t 0.7605564590594969\n",
            "22 \t [ 4.65410509  7.57869444  5.          0.7635136  15.          0.8131422 ]\t 0.7396988098813949\t 0.6536753952667645\t 0.7586360598102795\t 0.7586360598102795\n",
            "23 \t [9.75910946 3.15553839 5.         0.81190775 7.         0.66076168]\t 0.8026335283678844\t 0.6536753952667645\t 0.757599190525269\t 0.757599190525269\n",
            "24 \t [ 7.04750175  3.42465254 14.          0.6398927  13.          0.58870141]\t 0.815252067284572\t 0.6536753952667645\t 0.7572487112279676\t 0.7572487112279676\n",
            "25 \t [3.92428694 0.68431362 6.         0.64283095 9.         0.2162494 ]\t 1.0619895012405975\t 0.6536753952667645\t 0.7570518263458721\t 0.7570518263458721\n",
            "26 \t [ 1.03968583  3.49943563 14.          0.82879876  3.          0.98366866]\t 0.6562345271802523\t 0.6536753952667645\t 0.7595731462900321\t 0.7595731462900321\n",
            "27 \t [ 2.52136808  8.51741902 14.          0.89185963  6.          0.23066693]\t 1.0608073786807473\t 0.6536753952667645\t 0.7579858112829696\t 0.7579858112829696\n",
            "28 \t [ 0.15246909  0.64891005  5.          0.82057511 17.          0.55392553]\t 0.8471082658020649\t 0.6536753952667645\t 0.7602947250705676\t 0.7602947250705676\n",
            "29 \t [ 4.97713018  1.9194936  14.85861157  0.86091788  8.35825786  0.1       ]\t 1.0609211578562572\t 0.6536753952667645\t 0.7603078991801834\t 0.760306825233729\n",
            "30 \t [0.01760125 4.20168637 5.         0.62711786 8.         0.78825566]\t 0.7378644330521015\t 0.6536753952667645\t 0.7624219332124159\t 0.7624219332124159\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48973.66312746987"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClJ9rN2KUJzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea462016-4e0e-459c-f35d-e90d0ad00144"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_approx_2 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_2 = GPGO_multi(surrogate_approx_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # define BayesOpt\n",
        "approx_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_2 = approx_2.getResult()[0]\n",
        "params_approx_2['max_depth'] = int(params_approx_2['max_depth'])\n",
        "params_approx_2['min_child_weight'] = int(params_approx_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_approx_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_approx_2 = xgb.train(params_approx_2, dX_approx_train2)\n",
        "pred_approx_2 = model_approx_2.predict(dX_approx_test2)\n",
        "\n",
        "rmse_approx_2 = np.sqrt(mean_squared_error(pred_approx_2, y_test2))\n",
        "rmse_approx_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.778909206070606\t 0.681387807728051\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.681387807728051\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.7040746477543849\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.7953147984784036\t 0.681387807728051\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.7954413972964868\t 0.681387807728051\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.7560589160240606\u001b[0m\t \u001b[1m\u001b[92m0.7560589160240606\u001b[0m\n",
            "2  \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\t 0.7341430302765248\t 0.6807577751383148\t 0.7525465118812166\t 0.7525465118812166\n",
            "3  \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]\t 0.7073935536898857\t 0.6807577751383148\t 0.7523077377011698\t 0.7523077377011698\n",
            "4  \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]\t 0.7899041327973497\t 0.6807577751383148\t 0.7512771597589967\t 0.7512771597589967\n",
            "5  \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]\t 0.7887181971022355\t 0.6807577751383148\t 0.752899933264899\t 0.752899933264899\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.754248125090027\u001b[0m\t \u001b[1m\u001b[92m0.754248125090027\u001b[0m\n",
            "7  \t [ 9.14946201  2.43697872  6.          0.997805   19.          0.45949208]\t 0.8064071783057642\t 0.67907472219801\t 0.751235522947184\t 0.751235522947184\n",
            "8  \t [3.03571116 4.83939078 5.         0.66625528 1.         0.23130028]\t 0.872344629033322\t 0.67907472219801\t 0.7527302293019899\t 0.7527302293019899\n",
            "9  \t [ 4.57706999  8.33565192 11.          0.6188546   7.          0.54017925]\t 0.7035850285613279\t 0.67907472219801\t 0.7555599922415924\t 0.7555599922415924\n",
            "10 \t [2.51973603 9.74135258 5.         0.69633293 8.         0.1952065 ]\t 0.8718341605674269\t 0.67907472219801\t 0.7545733083006153\t 0.7545733083006153\n",
            "11 \t [ 8.6330652   9.62113163 11.          0.50355876 13.          0.80231095]\t 0.6810729676933972\t 0.67907472219801\t 0.7567772284315581\t 0.7567772284315581\n",
            "12 \t [9.23912622 8.640165   6.7297076  0.82440767 7.49827914 1.        ]\t 0.7066138335850702\t 0.67907472219801\t 0.7554963775337494\t 0.7554963747318593\n",
            "13 \t [ 7.86086296  9.53235807  5.          0.78700181 16.          0.22516618]\t 0.8728710854388536\t 0.67907472219801\t 0.7547325127769233\t 0.7547325127769233\n",
            "14 \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]\t 0.7143733066956096\t 0.67907472219801\t 0.7566242905607294\t 0.7566242905607294\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 8.6950785   0.99410218 13.          0.66782851 17.          0.9323419 ]\u001b[0m\t \u001b[1m\u001b[92m0.6668275525286983\u001b[0m\t \u001b[1m\u001b[92m0.6668275525286983\u001b[0m\t \u001b[1m\u001b[92m0.7559844779893589\u001b[0m\t \u001b[1m\u001b[92m0.7559844779893589\u001b[0m\n",
            "16 \t [ 8.16820063  1.301455    6.          0.90777702 13.          0.62357246]\t 0.7390406028289974\t 0.6668275525286983\t 0.7449056959220522\t 0.7449056959220522\n",
            "17 \t [ 9.61885664  9.78589131 14.          0.8903706   1.          0.14094172]\t 0.86262646699532\t 0.6668275525286983\t 0.7446668546243176\t 0.7446668519561791\n",
            "18 \t [ 5.64670451  8.85432647 14.          0.95807607 10.          0.35707694]\t 0.7882609808277333\t 0.6668275525286983\t 0.7461365237512466\t 0.7461365237512466\n",
            "19 \t [ 0.34964202  6.10551304 14.          0.81887518  8.          0.79373024]\t 0.6685630386219239\t 0.6668275525286983\t 0.7464486091708625\t 0.7464486091708625\n",
            "20 \t [0.62273619 1.29124124 6.         0.81123451 8.         0.42451055]\t 0.8085428854730617\t 0.6668275525286983\t 0.7455089728191298\t 0.7455089728191298\n",
            "21 \t [7.13284983 1.18470919 5.         0.63977211 3.         0.12223048]\t 0.8717594731267366\t 0.6668275525286983\t 0.7460841595059078\t 0.7460841595059078\n",
            "22 \t [ 0.51057799  7.98632671  8.          0.8773209  13.          0.97148281]\t 0.6760991691526478\t 0.6668275525286983\t 0.7473506616492933\t 0.7473506616492933\n",
            "23 \t [ 1.14769908  9.46854425 10.          0.58022432 19.          0.87672068]\t 0.6763818131586096\t 0.6668275525286983\t 0.7465155862782504\t 0.7465155862782504\n",
            "24 \t [ 5.48814708  1.96120195 13.          0.89659682  1.          0.34125713]\t 0.7953122343367733\t 0.6668275525286983\t 0.7457459066941202\t 0.7457459066941202\n",
            "25 \t [ 2.55390985  1.0433692  14.          0.50090092 18.          0.75542228]\t 0.6809836782112952\t 0.6668275525286983\t 0.7461059141940974\t 0.7461059141940974\n",
            "26 \t [ 9.66040016  0.29905702 10.          0.89892954  1.          0.25631182]\t 0.7948250927895766\t 0.6668275525286983\t 0.7454362581448809\t 0.7454362581445388\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.6817048020092698\t 0.6668275525286983\t 0.7457786206183191\t 0.7457786206183191\n",
            "28 \t [ 7.32261517  3.77223908 13.          0.66532455  8.          0.34613674]\t 0.7978087661541414\t 0.6668275525286983\t 0.7451663968846183\t 0.7451663968846183\n",
            "29 \t [0.38863914 8.65182136 9.74691381 0.83255187 4.48198735 0.73367666]\t 0.6772353709239944\t 0.6668275525286983\t 0.7454906544102856\t 0.745489100555299\n",
            "30 \t [ 0.09807255  0.         14.80609686  0.88209209  8.80555475  0.28602464]\t 0.7908844353227085\t 0.6668275525286983\t 0.7448899383579859\t 0.744888898782361\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49083.90726217171"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-45l3NU4UNiI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552a5276-9e52-4f40-d7c8-0f42daa22e61"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_approx_3 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_3 = GPGO_multi(surrogate_approx_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # define BayesOpt\n",
        "approx_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_3 = approx_3.getResult()[0]\n",
        "params_approx_3['max_depth'] = int(params_approx_3['max_depth'])\n",
        "params_approx_3['min_child_weight'] = int(params_approx_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_approx_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_approx_3 = xgb.train(params_approx_3, dX_approx_train3)\n",
        "pred_approx_3 = model_approx_3.predict(dX_approx_test3)\n",
        "\n",
        "rmse_approx_3 = np.sqrt(mean_squared_error(pred_approx_3, y_test3))\n",
        "rmse_approx_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.0213644638508028\t 0.7688389438662246\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.022822678309975\t 0.7688389438662246\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.7688389438662246\t 0.7688389438662246\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0239688135226253\t 0.7688389438662246\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8703298117399682\t 0.7688389438662246\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8050626816251143\t 0.7688389438662246\t 0.8803862854675509\t 0.8803862854675509\n",
            "2  \t [ 7.69133691  0.25025283 10.          0.52101543 12.          0.10383979]\t 1.0212658686211613\t 0.7688389438662246\t 0.8740711069939675\t 0.8740711069939675\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0239673069901083\t 0.7688389438662246\t 0.8781440483203176\t 0.8781440483203176\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 4.06522402  9.52384028  5.          0.68629723 13.          0.87617671]\u001b[0m\t \u001b[1m\u001b[92m0.7354945860729\u001b[0m\t \u001b[1m\u001b[92m0.7354945860729\u001b[0m\t \u001b[1m\u001b[92m0.8812899306874933\u001b[0m\t \u001b[1m\u001b[92m0.8812899306874933\u001b[0m\n",
            "5  \t [3.68953475 2.95525094 5.         0.6894371  8.         0.99869195]\t 0.7371180474782232\t 0.7354945860729\t 0.8488027752716415\t 0.8488027752716415\n",
            "6  \t [9.87422438 6.71772444 5.         0.63287091 5.         0.98483042]\t 0.7384798879960105\t 0.7354945860729\t 0.8437685072735122\t 0.8437685072735122\n",
            "7  \t [ 0.17111676  3.41676478 14.03411148  0.5        18.73748955  0.58878362]\t 0.764335239670282\t 0.7354945860729\t 0.839653237210083\t 0.8396532375307824\n",
            "8  \t [2.6278521  1.48922274 6.         0.63082487 1.         0.15934029]\t 1.0282950487417917\t 0.7354945860729\t 0.8367239372627746\t 0.8367239334585993\n",
            "9  \t [ 2.90369752  3.11254054  6.          0.81932406 16.          0.23613277]\t 1.028007118123578\t 0.7354945860729\t 0.8400379456449637\t 0.8400379456445403\n",
            "10 \t [ 9.79592734  3.47621065  8.          0.77016975 18.          0.46117986]\t 0.8696334480254722\t 0.7354945860729\t 0.8428604949883094\t 0.8428604949883094\n",
            "\u001b[1m\u001b[92m11\u001b[0m\t \u001b[1m\u001b[92m[ 1.02918863  9.32189805 13.          0.88333707  1.          0.86998588]\u001b[0m\t \u001b[1m\u001b[92m0.7135039231979946\u001b[0m\t \u001b[1m\u001b[92m0.7135039231979946\u001b[0m\t \u001b[1m\u001b[92m0.8421320361535236\u001b[0m\t \u001b[1m\u001b[92m0.8421320361535236\u001b[0m\n",
            "\u001b[1m\u001b[92m12\u001b[0m\t \u001b[1m\u001b[92m[ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\u001b[0m\t \u001b[1m\u001b[92m0.6998375974069359\u001b[0m\t \u001b[1m\u001b[92m0.6998375974069359\u001b[0m\t \u001b[1m\u001b[92m0.8216502893840208\u001b[0m\t \u001b[1m\u001b[92m0.8216502893840208\u001b[0m\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 9.33577729  2.46045418 12.          0.8699722   6.          0.97914461]\u001b[0m\t \u001b[1m\u001b[92m0.682832117112808\u001b[0m\t \u001b[1m\u001b[92m0.682832117112808\u001b[0m\t \u001b[1m\u001b[92m0.8079070495835731\u001b[0m\t \u001b[1m\u001b[92m0.8079070495835731\u001b[0m\n",
            "14 \t [ 9.85636221  3.89791593  9.          0.61925349 14.          0.90156475]\t 0.692118262463878\t 0.682832117112808\t 0.7916458682547327\t 0.7916458682547327\n",
            "15 \t [ 8.62571354  0.85358219 14.59245184  1.         15.09235062  0.1       ]\t 1.0280251039788522\t 0.682832117112808\t 0.7891051295861057\t 0.7891054688106244\n",
            "16 \t [ 1.04436425  9.32284009 12.          0.59300158  7.          0.9522161 ]\t 0.6890303982456368\t 0.682832117112808\t 0.7916886323041611\t 0.7916886323041611\n",
            "17 \t [ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\t 0.7059876882234674\t 0.682832117112808\t 0.7893576666353136\t 0.7893576665913171\n",
            "18 \t [3.49108815 6.63325237 9.         0.84362681 3.         0.27070428]\t 0.976179607552821\t 0.682832117112808\t 0.7874110586325812\t 0.7874101200418623\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8649856112240915\t 0.682832117112808\t 0.788975048957705\t 0.7889748278162461\n",
            "20 \t [8.97398363 2.41897649 7.         0.81773512 8.         0.28324604]\t 0.9772699327834455\t 0.682832117112808\t 0.7889665200441084\t 0.7889665056884613\n",
            "21 \t [7.66786548 9.63378327 6.         0.67341055 1.         0.88994805]\t 0.7192271436083939\t 0.682832117112808\t 0.7903539106848859\t 0.7903539106848859\n",
            "22 \t [ 8.78137031  9.07562973 14.          0.81240153 17.          0.56901188]\t 0.7561549263719795\t 0.682832117112808\t 0.788794854681703\t 0.7887948546791107\n",
            "23 \t [ 6.64966697  8.448574    5.          0.65443865 19.          0.53636799]\t 0.8070932341305113\t 0.682832117112808\t 0.7876893039783758\t 0.7876893039783758\n",
            "24 \t [ 0.04997226  0.57243486  5.          0.9748128  12.          0.24835402]\t 1.0287999951759097\t 0.682832117112808\t 0.7871395711044699\t 0.7871395711044699\n",
            "25 \t [8.10694301 4.17712073 5.         0.80634144 1.         0.66433498]\t 0.7742548953777686\t 0.682832117112808\t 0.7890069978422228\t 0.7890069978422228\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[10.          0.25309623 11.38665219  0.5         1.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6750828660524446\u001b[0m\t \u001b[1m\u001b[92m0.6750828660524446\u001b[0m\t \u001b[1m\u001b[92m0.7881601160340034\u001b[0m\t \u001b[1m\u001b[92m0.7881607679100611\u001b[0m\n",
            "27 \t [ 0.50161196  6.73842363  5.          0.62422734 11.          0.68966684]\t 0.7728211277583844\t 0.6750828660524446\t 0.7804954271294279\t 0.7804954271294279\n",
            "28 \t [10.          0.          7.07595769  0.5         3.33900461  0.1       ]\t 1.0227043290709652\t 0.6750828660524446\t 0.7797564941549091\t 0.7797567679389099\n",
            "29 \t [0.33715852 0.41541443 9.         0.53276138 6.         0.26454539]\t 0.9783805417169177\t 0.6750828660524446\t 0.7813869842259871\t 0.7813869842259871\n",
            "30 \t [ 0.50646974  6.72570721  7.          0.51798099 18.          0.75487674]\t 0.7188022076639518\t 0.6750828660524446\t 0.7824697919688817\t 0.7824697919688817\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51445.095716519514"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voPfk1UDUQU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00f5f4b-608e-4ea4-9815-00926cd1e709"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_approx_4 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_4 = GPGO_multi(surrogate_approx_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # define BayesOpt\n",
        "approx_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_4 = approx_4.getResult()[0]\n",
        "params_approx_4['max_depth'] = int(params_approx_4['max_depth'])\n",
        "params_approx_4['min_child_weight'] = int(params_approx_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_approx_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_approx_4 = xgb.train(params_approx_4, dX_approx_train4)\n",
        "pred_approx_4 = model_approx_4.predict(dX_approx_test4)\n",
        "\n",
        "rmse_approx_4 = np.sqrt(mean_squared_error(pred_approx_4, y_test4))\n",
        "rmse_approx_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7356156069458683\t 0.6641721421409617\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7070759857649549\t 0.6641721421409617\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 0.9423811784101735\t 0.6641721421409617\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.6641721421409617\t 0.6641721421409617\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.8244425146132294\t 0.6641721421409617\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 0.9441431878307984\t 0.6641721421409617\t 0.7500033112311408\t 0.7500033112311408\n",
            "2  \t [ 0.90674561  6.32290535 11.          0.94435129  1.          0.40346185]\t 0.7807426885653221\t 0.6641721421409617\t 0.7583013466771482\t 0.7583013466771482\n",
            "3  \t [ 7.37481669  1.69273565 11.          0.93066167  4.          0.26673965]\t 0.8222887232504895\t 0.6641721421409617\t 0.7571106204475303\t 0.7571106204475303\n",
            "4  \t [ 5.92074392  7.05411368 14.          0.56897417 18.          0.54051446]\t 0.7168223003470561\t 0.6641721421409617\t 0.7576834442271202\t 0.7576834442271202\n",
            "5  \t [ 5.20011211  1.13096048 14.          0.976894    9.          0.7504566 ]\t 0.6811978551681726\t 0.6641721421409617\t 0.7549480093604417\t 0.7549480089434363\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 0.9390440646887555\t 0.6641721421409617\t 0.7518688649579028\t 0.7518688649579028\n",
            "7  \t [0.85218043 8.76361565 5.         0.95141234 5.         0.18096954]\t 0.9409624334450053\t 0.6641721421409617\t 0.756072951131373\t 0.756072951131373\n",
            "8  \t [3.86538132 1.78391589 5.         0.96297978 2.         0.70393647]\t 0.754992983638292\t 0.6641721421409617\t 0.7596105139216331\t 0.7596105139216331\n",
            "9  \t [ 3.4576838   6.55355466  6.          0.72569372 18.          0.65149337]\t 0.7402639669497775\t 0.6641721421409617\t 0.7583351649289338\t 0.7583351646867681\n",
            "10 \t [ 9.3450382   8.82768787 11.          0.76868692  7.          0.8502727 ]\t 0.6886255429382424\t 0.6641721421409617\t 0.7569629566765758\t 0.7569629566765758\n",
            "11 \t [ 9.65147322  0.33792642 12.          0.92327424 17.          0.84355403]\t 0.681769217592037\t 0.6641721421409617\t 0.7549026567909882\t 0.7549026567909882\n",
            "12 \t [ 9.41900145  9.87951567  6.          0.74915436 10.          0.33908788]\t 0.8242430610923144\t 0.6641721421409617\t 0.7529910134639461\t 0.7529910134639461\n",
            "13 \t [0.69118951 0.05924245 6.         0.53870729 9.         0.9249957 ]\t 0.7094683558071616\t 0.6641721421409617\t 0.7535380620650595\t 0.7535380620650595\n",
            "14 \t [ 0.51187296  7.77314276 11.          0.63389119 15.          0.16589245]\t 0.9414371483413593\t 0.6641721421409617\t 0.752292373193006\t 0.752292373193006\n",
            "15 \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]\t 0.7682434061303821\t 0.6641721421409617\t 0.7547473979942131\t 0.7547473979942131\n",
            "16 \t [ 1.59376327  9.3637724   5.          0.56698742 13.          0.29635446]\t 0.8312840491127815\t 0.6641721421409617\t 0.7543356858231337\t 0.7543356858231337\n",
            "17 \t [ 5.61148944  3.45544791  5.          0.91442364 14.          0.13327309]\t 0.9395179340997094\t 0.6641721421409617\t 0.7548075797955076\t 0.7548075797955076\n",
            "18 \t [ 4.82972366  5.4211619  12.          0.82490157 12.          0.16791728]\t 0.9440096983258506\t 0.6641721421409617\t 0.7567830095159496\t 0.7567830095159496\n",
            "19 \t [6.04758549 0.99675153 5.         0.67521977 7.         0.8442095 ]\t 0.7543233654111011\t 0.6641721421409617\t 0.7586423722099908\t 0.7586423722025158\n",
            "20 \t [ 7.97119076  8.60858359  5.          0.89580835 19.          0.23533594]\t 0.9392342883690045\t 0.6641721421409617\t 0.7579838768957682\t 0.7579838765911882\n",
            "21 \t [ 2.5544629   5.29923202 14.          0.70981162  6.          0.74924795]\t 0.7082426501019057\t 0.6641721421409617\t 0.7595799643548997\t 0.7595799643548997\n",
            "22 \t [ 2.56416717  0.15610938 12.          0.9617952   2.          0.74332064]\t 0.7056949638714144\t 0.6641721421409617\t 0.7584817366429786\t 0.758481736641812\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 0.9412996363676764\t 0.6641721421409617\t 0.7574392681616064\t 0.7574392681616064\n",
            "24 \t [ 9.80678487  3.95044929 10.          0.72584344 13.          0.44065799]\t 0.7744169895010555\t 0.6641721421409617\t 0.7589099589138466\t 0.7589099589138466\n",
            "25 \t [ 2.07051041  1.52366516 10.          0.69512439 11.          0.21098416]\t 0.9419409250143087\t 0.6641721421409617\t 0.7585423319609602\t 0.7585423319609602\n",
            "26 \t [4.98189219 9.19296718 7.         0.90407002 2.         0.86829268]\t 0.7083350851770749\t 0.6641721421409617\t 0.7598791996072781\t 0.7598790543482133\n",
            "27 \t [ 0.44266617  0.60324342 13.          0.75682501 16.          0.11563354]\t 0.9429887777286539\t 0.6641721421409617\t 0.7589516548369193\t 0.7589515824247199\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 9.328728    0.19822705 12.          0.75281018 11.          0.88551078]\u001b[0m\t \u001b[1m\u001b[92m0.6617709003888801\u001b[0m\t \u001b[1m\u001b[92m0.6617709003888801\u001b[0m\t \u001b[1m\u001b[92m0.7602077042063391\u001b[0m\t \u001b[1m\u001b[92m0.7602077042063391\u001b[0m\n",
            "29 \t [ 8.18178764  9.98869521 14.          0.83418368 10.          0.41151726]\t 0.7724215015699015\t 0.6617709003888801\t 0.757081545510893\t 0.7570811775672587\n",
            "30 \t [ 1.72078221  1.85338202  5.          0.88677213 19.          0.37340399]\t 0.830888552375632\t 0.6617709003888801\t 0.7566953041801117\t 0.7566949807908413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51356.14273002872"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kEnTd7MUdlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8715ee5-e3b4-4c95-d1ce-9f4714f7178a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_approx_5 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_5 = GPGO_multi(surrogate_approx_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # define BayesOpt\n",
        "approx_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_5 = approx_5.getResult()[0]\n",
        "params_approx_5['max_depth'] = int(params_approx_5['max_depth'])\n",
        "params_approx_5['min_child_weight'] = int(params_approx_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_approx_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_approx_5 = xgb.train(params_approx_5, dX_approx_train5)\n",
        "pred_approx_5 = model_approx_5.predict(dX_approx_test5)\n",
        "\n",
        "rmse_approx_5 = np.sqrt(mean_squared_error(pred_approx_5, y_test5))\n",
        "rmse_approx_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7403320965261992\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7493104333264211\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9342492295788805\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.939514214921639\t 0.7403320965261992\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.921290745787579\t 0.7403320965261992\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9436861715841889\t 0.7403320965261992\t 0.8307757424254011\t 0.8307757424254011\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9276450520884063\t 0.7403320965261992\t 0.8351876237820846\t 0.8351876237820846\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.8376427386399233\u001b[0m\t \u001b[1m\u001b[92m0.8376427386399233\u001b[0m\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.9276698902289097\t 0.7398148307506893\t 0.8345699130171362\t 0.8345699130171362\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.8349503125715962\u001b[0m\t \u001b[1m\u001b[92m0.8349503125715962\u001b[0m\n",
            "6  \t [0.43749481 8.4213957  8.         0.8974006  1.         0.32861568]\t 0.92565009216999\t 0.6989575443158274\t 0.7979933663675036\t 0.7979933663674998\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8160533272968584\t 0.6989575443158274\t 0.7999580812948952\t 0.7999580812948952\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m0.6747588495441635\u001b[0m\t \u001b[1m\u001b[92m0.7989403936270718\u001b[0m\t \u001b[1m\u001b[92m0.7989403936270718\u001b[0m\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9277423136052668\t 0.6747588495441635\t 0.7761941503818416\t 0.7761941503818416\n",
            "10 \t [10.        10.        13.8114705  0.5       20.         0.1      ]\t 0.929718398277674\t 0.6747588495441635\t 0.7780195478010857\t 0.778019547841491\n",
            "11 \t [9.83467698 2.51972621 7.         0.55927725 8.         0.21207992]\t 0.9330525752501477\t 0.6747588495441635\t 0.7796394025623001\t 0.7796394025623001\n",
            "12 \t [ 0.49416106  7.25080418  6.          0.86593272 15.          0.18239415]\t 0.9413523398005076\t 0.6747588495441635\t 0.7811196819816969\t 0.7811196819816969\n",
            "13 \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]\t 0.7130088179210804\t 0.6747588495441635\t 0.7825787373156826\t 0.7825787373156826\n",
            "14 \t [ 9.58736014  2.45468429 12.          0.89338522 12.          0.76778503]\t 0.6833142835714986\t 0.6747588495441635\t 0.7803009353197398\t 0.7803009352467267\n",
            "15 \t [ 1.02937954  1.87162456 12.          0.80403735 18.          0.49076122]\t 0.779444839237101\t 0.6747588495441635\t 0.7778825127465472\t 0.777882502007063\n",
            "16 \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]\t 0.8392510578678525\t 0.6747588495441635\t 0.7769055564694838\t 0.7769055564694838\n",
            "17 \t [3.35483601 6.04519575 9.         0.66543363 5.         0.97731627]\t 0.6817324649068157\t 0.6747588495441635\t 0.7768116162449205\t 0.7768116162449205\n",
            "18 \t [ 9.73905766  7.12200775  5.          0.85875901 11.          0.99496281]\t 0.7281481211112614\t 0.6747588495441635\t 0.7748553393270301\t 0.7748553393270301\n",
            "19 \t [0.46851775 6.62135776 5.         1.         8.82598123 0.1       ]\t 1.0126646291812975\t 0.6747588495441635\t 0.7735543464794177\t 0.773554569811932\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7616619440927369\t 0.6747588495441635\t 0.7765418180608654\t 0.7765418180608654\n",
            "21 \t [ 0.15773168  2.32643207  7.          0.74406654 13.          0.24500907]\t 0.9325527483241955\t 0.6747588495441635\t 0.7750180761582921\t 0.7750180761582921\n",
            "22 \t [ 7.64692807  0.89890376 12.02113481  0.67731004  7.55055944  0.76086225]\t 0.6904976055252272\t 0.6747588495441635\t 0.7761079398975815\t 0.776106746063291\n",
            "23 \t [ 8.85833446  6.12544872 14.          0.9709687  16.          0.80797559]\t 0.6786656891163739\t 0.6747588495441635\t 0.7746154489623197\t 0.7746153836460307\n",
            "24 \t [ 0.         10.         10.36140848  1.         20.          0.1       ]\t 1.0033129683753572\t 0.6747588495441635\t 0.7731265883523369\t 0.7731268430708845\n",
            "25 \t [ 1.32021909  1.55653441 10.05497587  0.55320834  8.83016529  0.80000531]\t 0.6936836709238523\t 0.6747588495441635\t 0.7749844768045514\t 0.7749833739174509\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[ 4.98037549  0.          8.99999968  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6648120084316756\u001b[0m\t \u001b[1m\u001b[92m0.6648120084316756\u001b[0m\t \u001b[1m\u001b[92m0.7737014445732306\u001b[0m\t \u001b[1m\u001b[92m0.7737019441387033\u001b[0m\n",
            "27 \t [ 6.72997514  0.60780575 14.          0.89835235 18.          0.97859978]\t 0.6669043358767854\t 0.6648120084316756\t 0.7644224052841831\t 0.7644224052841831\n",
            "28 \t [9.64880583 0.85455793 9.         0.80366346 1.         0.54097439]\t 0.7473671119907898\t 0.6648120084316756\t 0.7635710381702914\t 0.7635710381702914\n",
            "29 \t [ 3.14006356  4.19464608 14.          0.50534541 10.          0.31510518]\t 0.932875387887278\t 0.6648120084316756\t 0.7624400243972982\t 0.7624393529896358\n",
            "30 \t [ 0.45754279  0.         12.71041258  1.          1.          0.1       ]\t 1.0039955228900503\t 0.6648120084316756\t 0.7634300849384428\t 0.7634297087172599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51522.848648623716"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVSH6caUgyy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df8e8c16-b89a-4858-a761-7f6942e847b2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_approx_6 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_6 = GPGO_multi(surrogate_approx_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # define BayesOpt\n",
        "approx_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_6 = approx_6.getResult()[0]\n",
        "params_approx_6['max_depth'] = int(params_approx_6['max_depth'])\n",
        "params_approx_6['min_child_weight'] = int(params_approx_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_approx_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_approx_6 = xgb.train(params_approx_6, dX_approx_train6)\n",
        "pred_approx_6 = model_approx_6.predict(dX_approx_test6)\n",
        "\n",
        "rmse_approx_6 = np.sqrt(mean_squared_error(pred_approx_6, y_test6))\n",
        "rmse_approx_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8597082353696148\t 0.7312157182363477\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.8283267033366734\t 0.7312157182363477\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.7312157182363477\t 0.7312157182363477\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.835804847353631\t 0.7312157182363477\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0201879064028692\t 0.7312157182363477\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.019213535386702\t 0.7312157182363477\t 0.8256502022984815\t 0.8256502022984815\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.0290226001513474\t 0.7312157182363477\t 0.8336863137033097\t 0.8336863137033097\n",
            "3  \t [8.90357673 8.23982464 5.         0.66456142 9.         0.34395649]\t 1.0228902128409325\t 0.7312157182363477\t 0.8398324733166328\t 0.8398324733163676\n",
            "4  \t [ 8.97809086  0.52071511 12.          0.96314156 10.          0.21133381]\t 1.0595990180003476\t 0.7312157182363477\t 0.8441609599872713\t 0.8441609599860888\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m0.6939533330723558\u001b[0m\t \u001b[1m\u001b[92m0.8488425398108821\u001b[0m\t \u001b[1m\u001b[92m0.8488425398108821\u001b[0m\n",
            "6  \t [ 8.37754293  7.69636444  8.          0.98881796 16.          0.46623185]\t 0.9234519385526558\t 0.6939533330723558\t 0.8133950628533112\t 0.8133950628526802\n",
            "7  \t [ 0.5654966   9.52584762 14.          0.82016688  4.          0.10717254]\t 1.0610911324495744\t 0.6939533330723558\t 0.81352026293104\t 0.81352026293104\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 6.75909949  0.94220097  9.          0.71741448 19.          0.94972086]\u001b[0m\t \u001b[1m\u001b[92m0.6895189879978737\u001b[0m\t \u001b[1m\u001b[92m0.6895189879978737\u001b[0m\t \u001b[1m\u001b[92m0.8173277781136988\u001b[0m\t \u001b[1m\u001b[92m0.8173277781131854\u001b[0m\n",
            "9  \t [ 1.43292764  9.31823681  5.          0.51738676 10.          0.30600768]\t 1.0250396556181756\t 0.6895189879978737\t 0.8090217452238593\t 0.8090217452238593\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 0.09135886  8.11961466 10.          0.74013552 12.          0.97362941]\u001b[0m\t \u001b[1m\u001b[92m0.6832941408312798\u001b[0m\t \u001b[1m\u001b[92m0.6832941408312798\u001b[0m\t \u001b[1m\u001b[92m0.8115024580172172\u001b[0m\t \u001b[1m\u001b[92m0.8115024580172172\u001b[0m\n",
            "11 \t [ 9.49126464  2.25575335  7.          0.89398566 13.          0.76947203]\t 0.7493845671941612\t 0.6832941408312798\t 0.8024041850485473\t 0.8024041783371232\n",
            "12 \t [ 2.98453858  8.8700865   6.          0.73955182 19.          0.28620498]\t 1.0180101584031926\t 0.6832941408312798\t 0.7996920361078513\t 0.7996920361078513\n",
            "13 \t [0.         1.27395757 5.         0.5        1.         0.1       ]\t 1.0641944470930125\t 0.6832941408312798\t 0.8018454933124328\t 0.8018454928776888\n",
            "14 \t [9.89801174 9.77563967 9.         0.68555662 3.         0.83921118]\t 0.73813303625317\t 0.6832941408312798\t 0.804673311996674\t 0.8046732471083914\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 0.50127522  1.94924928 11.          0.89270197 19.          0.91286914]\u001b[0m\t \u001b[1m\u001b[92m0.6768798166626013\u001b[0m\t \u001b[1m\u001b[92m0.6768798166626013\u001b[0m\t \u001b[1m\u001b[92m0.8020961139410776\u001b[0m\t \u001b[1m\u001b[92m0.8020961139410776\u001b[0m\n",
            "16 \t [6.55109905 2.29203942 6.         0.7269974  8.         0.87997636]\t 0.7181103319607761\t 0.6768798166626013\t 0.7940735837773509\t 0.7940735639157187\n",
            "17 \t [ 5.34746512  3.38521677 14.          0.73339647  4.          0.14820244]\t 1.0618182880471418\t 0.6768798166626013\t 0.7917809733406009\t 0.7917809733405704\n",
            "18 \t [0.75190021 2.99821111 7.         0.73112778 8.         0.11979456]\t 1.060673835734707\t 0.6768798166626013\t 0.794320879987779\t 0.794320879987779\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.0599380721478096\t 0.6768798166626013\t 0.7966135502118996\t 0.7966135502118996\n",
            "20 \t [ 0.09987636  2.02964824 11.39807531  0.5        12.99832185  0.1       ]\t 1.0608261896346503\t 0.6768798166626013\t 0.7986659202917877\t 0.7986648422609874\n",
            "21 \t [4.70222718 7.76335614 9.         0.92367012 9.         0.28724782]\t 1.0152545517792837\t 0.6768798166626013\t 0.8006153853258272\t 0.8006153853219996\n",
            "22 \t [ 0.15151883  3.04875397  5.          0.61495161 19.          0.79420245]\t 0.7938992290953346\t 0.6768798166626013\t 0.8017877261682789\t 0.8017877261682789\n",
            "23 \t [0.09752792 7.56070281 9.         0.95937939 3.         0.71279346]\t 0.7751689886400943\t 0.6768798166626013\t 0.8003925922113113\t 0.800392366935738\n",
            "24 \t [ 9.55684885  4.02134483 11.          0.82079508  6.          0.83404351]\t 0.7299947122757273\t 0.6768798166626013\t 0.798972241477897\t 0.798972241477897\n",
            "25 \t [ 3.81847995  9.43141013 12.          0.56182914 19.          0.95661081]\t 0.6893334668436607\t 0.6768798166626013\t 0.7972316329969027\t 0.7972316329969027\n",
            "\u001b[1m\u001b[92m26\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         12.61471492  1.          8.99946115  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6527689075714267\u001b[0m\t \u001b[1m\u001b[92m0.6527689075714267\u001b[0m\t \u001b[1m\u001b[92m0.7952568192364957\u001b[0m\t \u001b[1m\u001b[92m0.795257211282006\u001b[0m\n",
            "27 \t [ 4.39573464  8.5671894  10.45302963  0.9588928   1.          0.1       ]\t 1.0596308771945506\t 0.6527689075714267\t 0.7745724151909354\t 0.7745710023241776\n",
            "28 \t [ 9.76034622  3.85059288 11.10220954  0.5        16.25164026  0.34106196]\t 1.022324962621585\t 0.6527689075714267\t 0.7762821345450488\t 0.7762805613483561\n",
            "29 \t [ 1.0021313   4.9490761  14.          0.62016719  1.          0.18537333]\t 1.0636257139268357\t 0.6527689075714267\t 0.7774837381893763\t 0.7774832901231482\n",
            "30 \t [ 6.80447195  6.69417926  5.          0.74586765 13.          0.74060763]\t 0.8347742213240951\t 0.6527689075714267\t 0.7790642300634627\t 0.7790642300634627\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48068.332581319075"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WsphKSUj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a93251-78a5-44b7-88a2-8d2288848199"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_approx_7 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_7 = GPGO_multi(surrogate_approx_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # define BayesOpt\n",
        "approx_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_7 = approx_7.getResult()[0]\n",
        "params_approx_7['max_depth'] = int(params_approx_7['max_depth'])\n",
        "params_approx_7['min_child_weight'] = int(params_approx_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_approx_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_approx_7 = xgb.train(params_approx_7, dX_approx_train7)\n",
        "pred_approx_7 = model_approx_7.predict(dX_approx_test7)\n",
        "\n",
        "rmse_approx_7 = np.sqrt(mean_squared_error(pred_approx_7, y_test7))\n",
        "rmse_approx_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.6599162825175136\t 0.6529031062312245\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.6529031062312245\t 0.6529031062312245\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.7849988476524127\t 0.6529031062312245\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7434573966703171\t 0.6529031062312245\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.6887936732176462\t 0.6529031062312245\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.8461730749178773\t 0.6529031062312245\t 0.7211214507322005\t 0.7211214507322005\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7280339284910606\t 0.6529031062312245\t 0.7277003276934555\t 0.7277003276934555\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.6571137209723783\t 0.6529031062312245\t 0.7275217885714056\t 0.7275217885714056\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7458231993222018\t 0.6529031062312245\t 0.7251370704301654\t 0.7251370704301654\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.7838758112536788\t 0.6529031062312245\t 0.7258173449579699\t 0.7258173449579699\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.6787899501779286\t 0.6529031062312245\t 0.7274275823919338\t 0.7274275823919338\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.8531322761504475\t 0.6529031062312245\t 0.7261848717832742\t 0.7261848717832742\n",
            "8  \t [ 1.95327375  0.09413692  7.          0.63967551 19.          0.52105045]\t 0.718715865573951\t 0.6529031062312245\t 0.7292238595169062\t 0.7292238595169062\n",
            "9  \t [5.70513125 8.30861013 6.         0.98680016 3.         0.16134411]\t 0.9984088714580504\t 0.6529031062312245\t 0.7288212195026392\t 0.7288212195026392\n",
            "10 \t [ 0.25030147  5.86047618  7.          0.62148035 15.          0.70956246]\t 0.7144935773647406\t 0.6529031062312245\t 0.7347275061504588\t 0.7347275061504588\n",
            "11 \t [ 6.35215     9.71205645 11.          0.67733044  6.          0.80174708]\t 0.6867359020307766\t 0.6529031062312245\t 0.7339415707544829\t 0.7339415620296479\n",
            "12 \t [9.93412004 7.01728008 6.         0.60790736 8.         0.46475011]\t 0.8183353504315909\t 0.6529031062312245\t 0.7328108837728508\t 0.7328108837728508\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.7792188999132433\t 0.6529031062312245\t 0.7339321000029073\t 0.7339321000029073\n",
            "14 \t [ 1.45077723  9.99574495  5.          0.58320457 19.          0.8020368 ]\t 0.7455249373416325\t 0.6529031062312245\t 0.7342970801271882\t 0.7342970801271882\n",
            "15 \t [ 0.30180848  0.36339665 10.          0.99951435 11.          0.54137142]\t 0.6900449537968393\t 0.6529031062312245\t 0.7341323919215664\t 0.7341323919215664\n",
            "16 \t [7.5058071  0.77198166 5.         0.94542975 7.         0.89710815]\t 0.7217956619874041\t 0.6529031062312245\t 0.7332600758736388\t 0.7332600752612997\n",
            "17 \t [ 0.08258912  2.04682383 12.          0.59206459 18.          0.58057909]\t 0.6960149194291863\t 0.6529031062312245\t 0.7328585777011026\t 0.7328585777011026\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.6910349298616485\t 0.6529031062312245\t 0.7321909174443166\t 0.7321909174271639\n",
            "19 \t [ 8.02008913  6.8951761  13.          0.63880909 19.          0.69330995]\t 0.6893407861836052\t 0.6529031062312245\t 0.7315260978654805\t 0.7315260978654805\n",
            "20 \t [ 9.02606866  9.9399456   5.          0.69325176 13.          0.80731892]\t 0.7457716132538541\t 0.6529031062312245\t 0.7308984686397928\t 0.7308984686397928\n",
            "21 \t [ 3.09348613  3.96247234  8.          0.81774087 13.          0.58941598]\t 0.7015179019308584\t 0.6529031062312245\t 0.730911678951343\t 0.730911678951343\n",
            "22 \t [ 2.21548548  9.34072297 10.          0.96109934 13.          0.7636836 ]\t 0.6798017103904265\t 0.6529031062312245\t 0.730474464645961\t 0.730474464645961\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[ 1.10150879  4.93737158 13.          0.87840594  8.          0.95224738]\u001b[0m\t \u001b[1m\u001b[92m0.6467893306949126\u001b[0m\t \u001b[1m\u001b[92m0.6467893306949126\u001b[0m\t \u001b[1m\u001b[92m0.7298627255419283\u001b[0m\t \u001b[1m\u001b[92m0.7298627255419283\u001b[0m\n",
            "24 \t [ 8.17909255  8.95640578 13.          0.94174624  1.          0.89014148]\t 0.6509486270988182\t 0.6467893306949126\t 0.724054650174644\t 0.724054650174644\n",
            "25 \t [ 0.          6.83150235 15.          1.         12.28412696  0.1       ]\t 1.0027505156759997\t 0.6467893306949126\t 0.7232902423131118\t 0.723289649773088\n",
            "26 \t [ 5.03032449  1.46993678 12.          0.54826603 16.          0.88093043]\t 0.6584236565498969\t 0.6467893306949126\t 0.7261496427675176\t 0.7261496427675176\n",
            "27 \t [ 9.72265512  3.8270652  10.          0.71648686  6.          0.86209857]\t 0.6848726653905244\t 0.6467893306949126\t 0.7254240225347545\t 0.725423809604102\n",
            "28 \t [ 5.50533402  5.98134311 11.          0.606747    9.          0.23402402]\t 0.993933313945832\t 0.6467893306949126\t 0.7249535112546984\t 0.7249535112546984\n",
            "29 \t [ 9.92745389  2.10791379  6.          0.91867901 19.          0.37494465]\t 0.8675172360459502\t 0.6467893306949126\t 0.7273964667440193\t 0.7273964667440193\n",
            "30 \t [1.66779279 0.54723135 6.         0.82307279 8.         0.95931183]\t 0.6973128000849222\t 0.6467893306949126\t 0.7284225667671929\t 0.7284225667671929\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49673.760083321315"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hI8sFP4ZUmOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9dd84d-e58c-469b-8cc0-6280cd759207"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_approx_8 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_8 = GPGO_multi(surrogate_approx_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # define BayesOpt\n",
        "approx_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_8 = approx_8.getResult()[0]\n",
        "params_approx_8['max_depth'] = int(params_approx_8['max_depth'])\n",
        "params_approx_8['min_child_weight'] = int(params_approx_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_approx_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_approx_8 = xgb.train(params_approx_8, dX_approx_train8)\n",
        "pred_approx_8 = model_approx_8.predict(dX_approx_test8)\n",
        "\n",
        "rmse_approx_8 = np.sqrt(mean_squared_error(pred_approx_8, y_test8))\n",
        "rmse_approx_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.8097437093843076\t 0.6653168057229354\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.676783388491471\t 0.6653168057229354\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8290150461838799\t 0.6653168057229354\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.704280612172438\t 0.6653168057229354\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.6653168057229354\t 0.6653168057229354\t    \t    \n",
            "1  \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\t 0.6939807861210728\t 0.6653168057229354\t 0.7398208900291442\t 0.7398208900291442\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8292448989696929\t 0.6653168057229354\t 0.7378301892426625\t 0.7378301892426625\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7238654894117781\t 0.6653168057229354\t 0.7417057000977814\t 0.7417057000977814\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8298868503374536\t 0.6653168057229354\t 0.7409324331191866\t 0.7409324331191866\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7298305735353544\t 0.6653168057229354\t 0.7436166701822383\t 0.7436166701822383\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.6713374162855336\t 0.6653168057229354\t 0.7429638266458657\t 0.7429638266458657\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8412489648220683\t 0.6653168057229354\t 0.7410913638790863\t 0.7410913638790863\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8281572228887775\t 0.6653168057229354\t 0.7433754061761333\t 0.7433754061761333\n",
            "9  \t [ 0.45485069  5.92046568 13.          0.54575641 15.          0.3753516 ]\t 0.8133506998200086\t 0.6653168057229354\t 0.7450028727994088\t 0.7450028721174221\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.6700820921354065\t 0.6653168057229354\t 0.7460852533022603\t 0.7460852532874173\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8403741678101049\t 0.6653168057229354\t 0.7444889861156282\t 0.7444889861156282\n",
            "12 \t [3.47378168 0.90493309 7.         0.70332668 6.         0.717685  ]\t 0.7108804508392579\t 0.6653168057229354\t 0.7459681949320525\t 0.7459681949320522\n",
            "13 \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]\t 0.9373386140641772\t 0.6653168057229354\t 0.7451597351586965\t 0.7451597351586965\n",
            "14 \t [1.36072521 8.96337054 5.         0.74382165 2.         0.12580076]\t 0.9379435984221122\t 0.6653168057229354\t 0.7481456669826121\t 0.7481456669826121\n",
            "15 \t [ 3.32794564  9.35873285 13.          0.95404271 12.          0.46503428]\t 0.8057168013419183\t 0.6653168057229354\t 0.7508187499648225\t 0.7508186253073212\n",
            "16 \t [ 6.35979139  1.00897047 10.          0.55338934  9.          0.8992107 ]\t 0.6742016407056493\t 0.6653168057229354\t 0.7511714351488924\t 0.7511714351488924\n",
            "17 \t [0.26711089 1.47965823 5.         0.94483199 1.         0.67844469]\t 0.7386069861707144\t 0.6653168057229354\t 0.7498441365750379\t 0.7498441365552042\n",
            "18 \t [ 8.81884199  0.29557486 11.          0.94612367  2.          0.80082225]\t 0.6729826219675135\t 0.6653168057229354\t 0.7493717622682153\t 0.7493717622682153\n",
            "19 \t [ 4.10272358  0.68972827 14.          0.96902802  1.          0.19814279]\t 0.9303071311772037\t 0.6653168057229354\t 0.748222429725093\t 0.748222429725093\n",
            "20 \t [ 1.37842187  7.92618907 14.          0.53493538  2.          0.9994541 ]\t 0.6778496323948628\t 0.6653168057229354\t 0.7502302981681976\t 0.7502302668939616\n",
            "21 \t [8.49304258 9.45420615 6.         0.52298498 5.         0.36186114]\t 0.8398941833093019\t 0.6653168057229354\t 0.749186600701187\t 0.7491865823266688\n",
            "22 \t [ 0.76637948  1.6718521   5.          0.89180884 15.          0.76035097]\t 0.7285188069721016\t 0.6653168057229354\t 0.7499066381787262\t 0.7499066381787262\n",
            "23 \t [ 5.51401011 10.          7.98396669  0.86728977  1.14539204  0.1       ]\t 0.931684683478203\t 0.6653168057229354\t 0.7494217220916878\t 0.7494203550722324\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[ 9.32779145  5.8517174  11.          0.74437014 12.          0.90919993]\u001b[0m\t \u001b[1m\u001b[92m0.6652912380850803\u001b[0m\t \u001b[1m\u001b[92m0.6652912380850803\u001b[0m\t \u001b[1m\u001b[92m0.7511142105455445\u001b[0m\t \u001b[1m\u001b[92m0.751114042725429\u001b[0m\n",
            "25 \t [ 2.00363843  0.25557305 13.          0.79852696 19.          0.41982126]\t 0.8045050796386125\t 0.6652912380850803\t 0.750061034042746\t 0.750061034042746\n",
            "26 \t [10.          6.27924374  5.          1.         11.31543427  0.1       ]\t 0.9653061246881615\t 0.6652912380850803\t 0.7503090119368758\t 0.7503087664114715\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8100270760776773\t 0.6652912380850803\t 0.7521726433933318\t 0.7521726433933318\n",
            "28 \t [ 1.06330602  9.84698732  5.          0.70744161 15.          0.6986094 ]\t 0.7398934603464837\t 0.6652912380850803\t 0.7523886896542483\t 0.7523886896542483\n",
            "29 \t [ 9.6464663   0.98885701  8.          0.8054878  19.          0.70201828]\t 0.699572467500549\t 0.6652912380850803\t 0.7520074159103217\t 0.7520074159103217\n",
            "30 \t [ 6.56126126  1.25177273  5.          0.60554055 11.          0.89113205]\t 0.7253897845864579\t 0.6652912380850803\t 0.751318932757471\t 0.7513186540003822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52609.47902158823"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw5IYus6UpAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2424ac3e-53be-467c-f41f-1b620a1871f1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_approx_9 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_9 = GPGO_multi(surrogate_approx_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # define BayesOpt\n",
        "approx_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_9 = approx_9.getResult()[0]\n",
        "params_approx_9['max_depth'] = int(params_approx_9['max_depth'])\n",
        "params_approx_9['min_child_weight'] = int(params_approx_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_approx_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_approx_9 = xgb.train(params_approx_9, dX_approx_train9)\n",
        "pred_approx_9 = model_approx_9.predict(dX_approx_test9)\n",
        "\n",
        "rmse_approx_9 = np.sqrt(mean_squared_error(pred_approx_9, y_test9))\n",
        "rmse_approx_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 0.8449026536729003\t 0.6448358819228919\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 0.8430936233516066\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.6448358819228919\t 0.6448358819228919\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.7455250925664565\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.6542440322310401\t 0.6448358819228919\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.0516333409565926\t 0.6448358819228919\t 0.7263090534109926\t 0.7263090534109926\n",
            "2  \t [9.23885705 0.0495141  9.         0.5847098  7.         0.79832927]\t 0.6774051522557019\t 0.6448358819228919\t 0.742686185833593\t 0.742686185833593\n",
            "3  \t [ 3.67545472  4.78145311 14.          0.63123486 17.          0.4863889 ]\t 0.7930932442681178\t 0.6448358819228919\t 0.7376383541421366\t 0.7376383541421366\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.7396199848029671\t 0.6448358819228919\t 0.7376830480463931\t 0.7376830480463931\n",
            "5  \t [ 1.86381009  9.16177979  5.          0.9344438  17.          0.81379931]\t 0.7377720407232845\t 0.6448358819228919\t 0.7360693893552984\t 0.7360693893552984\n",
            "6  \t [ 2.35563756  1.41309797  5.          0.61127581 14.          0.85229383]\t 0.7381603779527465\t 0.6448358819228919\t 0.7347261153508796\t 0.7347261153508796\n",
            "7  \t [ 0.65024006  0.20015298 14.          0.90298726 13.          0.95798937]\t 0.6479585144859159\t 0.6448358819228919\t 0.7336346569508181\t 0.7336346569508181\n",
            "8  \t [ 9.89935012  1.80411649  9.          0.642097   16.          0.9768379 ]\t 0.6624923928604278\t 0.6448358819228919\t 0.7308238750412718\t 0.7308238750412718\n",
            "9  \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]\t 0.788150408197674\t 0.6448358819228919\t 0.7287053521988817\t 0.7287053521988817\n",
            "10 \t [ 8.9317907   9.240006   13.          0.55531212  4.          0.42887515]\t 0.8067241228581707\t 0.6448358819228919\t 0.7292707885380583\t 0.7292707885380582\n",
            "11 \t [2.63920029 2.84662126 8.         0.81372528 9.         0.70958016]\t 0.7107155274108488\t 0.6448358819228919\t 0.7301215984497749\t 0.7301215984497749\n",
            "12 \t [1.13081555 8.89608809 5.         0.68242063 1.         0.25767085]\t 0.8508904111239197\t 0.6448358819228919\t 0.729200839573263\t 0.7292008395732629\n",
            "13 \t [ 8.01493798  7.33950965 10.          0.50609192 18.          0.9957267 ]\t 0.6703192470045024\t 0.6448358819228919\t 0.7307425403388548\t 0.7307425403373259\n",
            "14 \t [ 8.08392893  1.91862949 14.          0.6384648  17.          0.1890016 ]\t 1.0461857744698733\t 0.6448358819228919\t 0.7293234845275981\t 0.7293234728491738\n",
            "15 \t [9.88943457 8.53804591 8.         0.65243257 7.         0.28069664]\t 0.8352977818443392\t 0.6448358819228919\t 0.734248576711283\t 0.734248576711283\n",
            "16 \t [ 3.66353781  7.3371628  13.          0.91928424 11.          0.42437688]\t 0.78680708804053\t 0.6448358819228919\t 0.7350603674199394\t 0.7350603674199394\n",
            "17 \t [ 1.01403007  4.17086177  6.          0.95687904 19.          0.93022379]\t 0.6958192358474726\t 0.6448358819228919\t 0.7351145492070924\t 0.7351145492070924\n",
            "18 \t [ 9.00084206  1.85673124 10.          0.98011614  2.          0.25530052]\t 0.83279328574821\t 0.6448358819228919\t 0.7340502787481877\t 0.7340502770627619\n",
            "19 \t [2.39281114 8.24027537 6.         0.62412974 6.         0.7547697 ]\t 0.7107399222825\t 0.6448358819228919\t 0.7347320896256639\t 0.7347320778420868\n",
            "20 \t [ 5.06569568  9.95512019 10.          0.79200421  8.          0.9497448 ]\t 0.6524837713585139\t 0.6448358819228919\t 0.7339309286275558\t 0.7339309286274326\n",
            "21 \t [ 4.2953213   0.27911896 10.          0.9783586  19.          0.46300401]\t 0.7860315206098012\t 0.6448358819228919\t 0.7326146866397524\t 0.732614686608643\n",
            "22 \t [5.69641029 8.40739134 9.         0.78375397 1.         0.13665985]\t 1.0469513005500544\t 0.6448358819228919\t 0.7327443207296401\t 0.7327443207296401\n",
            "23 \t [ 7.07313313  8.94084339  5.          0.99439529 19.          0.33798274]\t 0.8491103282876022\t 0.6448358819228919\t 0.7360820165469445\t 0.7360820165469445\n",
            "24 \t [1.76701563 1.7346788  7.         0.94361827 2.         0.93288306]\t 0.6754110020522134\t 0.6448358819228919\t 0.7367455675979576\t 0.7367455675979576\n",
            "25 \t [ 9.01552706  3.25572905  5.          0.56123527 16.          0.5672937 ]\t 0.797912270059593\t 0.6448358819228919\t 0.735708990826443\t 0.7357089904057176\n",
            "26 \t [4.86659604 3.67943735 9.         0.97224139 1.         0.90536162]\t 0.6576745506297413\t 0.6448358819228919\t 0.735831677457404\t 0.7358316754415487\n",
            "27 \t [ 0.45983101  9.28402862 13.          0.52786561  6.          0.42783681]\t 0.8036069849990609\t 0.6448358819228919\t 0.7347512008367432\t 0.7347512008367432\n",
            "28 \t [7.20425099 1.56266186 5.         0.88211354 9.         0.78887069]\t 0.7368960706458181\t 0.6448358819228919\t 0.7349486332198991\t 0.7349486332198991\n",
            "29 \t [3.08321869 0.87587118 5.         0.75683721 6.         0.32966687]\t 0.8525276760004173\t 0.6448358819228919\t 0.7345680658377454\t 0.7345679019088922\n",
            "30 \t [ 6.14078962  2.31372054 11.          0.9240952  13.          0.361681  ]\t 0.8314074749252223\t 0.6448358819228919\t 0.7351913971652063\t 0.7351913971652063\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48075.00995818073"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD494io_Ur7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138e704c-60d1-496a-e6a3-f94815818be7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_approx_10 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_10 = GPGO_multi(surrogate_approx_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # define BayesOpt\n",
        "approx_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_10 = approx_10.getResult()[0]\n",
        "params_approx_10['max_depth'] = int(params_approx_10['max_depth'])\n",
        "params_approx_10['min_child_weight'] = int(params_approx_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_approx_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_approx_10 = xgb.train(params_approx_10, dX_approx_train10)\n",
        "pred_approx_10 = model_approx_10.predict(dX_approx_test10)\n",
        "\n",
        "rmse_approx_10 = np.sqrt(mean_squared_error(pred_approx_10, y_test10))\n",
        "rmse_approx_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 0.8785010703819621\t 0.6669292375133978\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.6669292375133978\t 0.6669292375133978\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7012460140601039\t 0.6669292375133978\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7005965853529538\t 0.6669292375133978\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 0.880412005930048\t 0.6669292375133978\t    \t    \n",
            "1  \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\t 0.6770142260932797\t 0.6669292375133978\t 0.7495260602026695\t 0.7495260602026695\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.7417959722875219\t 0.6669292375133978\t 0.7454679568537242\t 0.7454679568537242\n",
            "3  \t [1.0517383  0.29626986 6.         0.71496305 2.         0.21703638]\t 0.8792946548244501\t 0.6669292375133978\t 0.7449099712401652\t 0.7449099712401652\n",
            "4  \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\t 0.7006385046040607\t 0.6669292375133978\t 0.7494639804046281\t 0.7494639804046281\n",
            "5  \t [ 2.36407072  4.99081503 14.          0.6287111   1.          0.46714602]\t 0.7578758817373941\t 0.6669292375133978\t 0.7474127169463525\t 0.7474127169463525\n",
            "6  \t [ 9.8195229   7.4353827   6.          0.61370759 10.          0.85798549]\t 0.7015549121482302\t 0.6669292375133978\t 0.7472590006732353\t 0.7472590006732353\n",
            "7  \t [8.82521763 9.96779345 8.         0.82356907 1.         0.3598298 ]\t 0.8142907394883079\t 0.6669292375133978\t 0.7457987496848895\t 0.7457987496848637\n",
            "8  \t [ 9.67396075  2.8020106  13.          0.65074314 10.          0.54373377]\t 0.7069523757910561\t 0.6669292375133978\t 0.747124992323711\t 0.747124992323711\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\u001b[0m\t \u001b[1m\u001b[92m0.661096368919013\u001b[0m\t \u001b[1m\u001b[92m0.661096368919013\u001b[0m\t \u001b[1m\u001b[92m0.7460042017530256\u001b[0m\t \u001b[1m\u001b[92m0.7460042017530256\u001b[0m\n",
            "10 \t [ 9.32751793  9.16094516  5.          0.70577301 16.          0.29580142]\t 0.8234668645210068\t 0.661096368919013\t 0.7395075757481139\t 0.7395075751960506\n",
            "11 \t [5.00762913 1.53619492 9.         0.56892944 8.         0.96567366]\t 0.662454600529182\t 0.661096368919013\t 0.74086268182933\t 0.7408626817911447\n",
            "12 \t [ 2.40528406  7.71427622 14.          0.55203588 14.          0.3470708 ]\t 0.8154596077767258\t 0.661096368919013\t 0.7393550582339149\t 0.7393550582339149\n",
            "13 \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]\t 0.823119322181516\t 0.661096368919013\t 0.7404203117771307\t 0.7404203117771307\n",
            "14 \t [ 0.2734411   0.20947276 13.          0.89386904  7.          0.27558279]\t 0.8166474442456968\t 0.661096368919013\t 0.7414928369172453\t 0.7414928369041399\n",
            "15 \t [ 9.86913094  2.54287696 14.          0.86051843  2.          0.74044264]\t 0.6976866250322032\t 0.661096368919013\t 0.7423504511985058\t 0.7423504511985058\n",
            "16 \t [ 3.32064678  9.82322091 10.          0.61729748  2.          0.52189899]\t 0.7141379767240427\t 0.661096368919013\t 0.7415031118376102\t 0.7415030925520187\n",
            "17 \t [ 4.63020556  1.51436379 11.          0.68034517  2.          0.42766971]\t 0.7486371706886035\t 0.661096368919013\t 0.7409349368752045\t 0.7409349187435162\n",
            "18 \t [ 3.35903512  5.65946459  5.          0.99895528 10.          0.94028903]\t 0.7198633628577074\t 0.661096368919013\t 0.740830946954804\t 0.740830946954804\n",
            "19 \t [ 7.82641344  8.43235645 13.          0.61872216  7.          0.69024191]\t 0.6971262650078873\t 0.661096368919013\t 0.7404052676115279\t 0.7404052671743729\n",
            "20 \t [ 5.34009624 10.          7.39063498  1.          9.95349009  1.        ]\t 0.6736114850805691\t 0.661096368919013\t 0.739772521342674\t 0.7397722928306779\n",
            "21 \t [ 7.22258807  6.23065969 12.          0.56635095 13.          0.86573749]\t 0.667894664145167\t 0.661096368919013\t 0.7389583813280406\t 0.7389580434310276\n",
            "22 \t [ 6.19948038  6.36838188  8.          0.76805564 19.          0.53627741]\t 0.711941213153515\t 0.661096368919013\t 0.7381526781429415\t 0.7381526781427661\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[ 9.44951582  5.99779679 14.          0.85197424 19.          0.91766982]\u001b[0m\t \u001b[1m\u001b[92m0.6447978921360024\u001b[0m\t \u001b[1m\u001b[92m0.6447978921360024\u001b[0m\t \u001b[1m\u001b[92m0.7378125090025892\u001b[0m\t \u001b[1m\u001b[92m0.7378125090025892\u001b[0m\n",
            "24 \t [ 4.11986688  9.81320751 11.          0.98131964 17.          0.2975892 ]\t 0.81020927033387\t 0.6447978921360024\t 0.7236987371340651\t 0.7236987371340651\n",
            "25 \t [4.66195218 5.96776172 7.         0.68043003 1.         0.11094684]\t 0.8818491623143119\t 0.6447978921360024\t 0.7243692736912666\t 0.7243692736912666\n",
            "26 \t [ 0.05631801  1.70542835  5.          0.81169587 13.          0.87766862]\t 0.7170536065005569\t 0.6447978921360024\t 0.7257377927431805\t 0.7257377927431805\n",
            "27 \t [0.73638155 5.44724197 9.         0.90159859 3.         0.84981348]\t 0.6619468807381774\t 0.6447978921360024\t 0.7254548054135381\t 0.7254548054135381\n",
            "28 \t [ 0.          7.68262336 12.92699578  1.         20.          0.1       ]\t 1.056999794347736\t 0.6447978921360024\t 0.7247518270386444\t 0.7247520008807882\n",
            "29 \t [ 6.16349263  8.99102846 14.          0.6618501   2.          0.7403865 ]\t 0.7025994843252346\t 0.6447978921360024\t 0.7278726905298935\t 0.7278726905298935\n",
            "30 \t [ 4.12960127  3.58845181 14.          0.58485529  7.          0.89968719]\t 0.6580697473446084\t 0.6447978921360024\t 0.727442072546489\t 0.727442072546489\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50036.815054908904"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N03Sq0TvUuhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4794bb-d9b4-4a01-b7da-3c756171a865"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_approx_11 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_11 = GPGO_multi(surrogate_approx_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # define BayesOpt\n",
        "approx_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_11 = approx_11.getResult()[0]\n",
        "params_approx_11['max_depth'] = int(params_approx_11['max_depth'])\n",
        "params_approx_11['min_child_weight'] = int(params_approx_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_approx_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_approx_11 = xgb.train(params_approx_11, dX_approx_train11)\n",
        "pred_approx_11 = model_approx_11.predict(dX_approx_test11)\n",
        "\n",
        "rmse_approx_11 = np.sqrt(mean_squared_error(pred_approx_11, y_test11))\n",
        "rmse_approx_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.7904007286371394\t 0.6894069737354023\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.727634308123781\t 0.6894069737354023\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.6894069737354023\t 0.6894069737354023\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7071657410132528\t 0.6894069737354023\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7012825433030343\t 0.6894069737354023\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.711031226877882\t 0.6894069737354023\t 0.7552688600895634\t 0.7552688600895634\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.7547506288111829\u001b[0m\t \u001b[1m\u001b[92m0.7547506288111829\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7648729702018928\t 0.6577294425265764\t 0.7263344336194053\t 0.7263344336194053\n",
            "4  \t [ 8.43962982  4.2216354  12.          0.61829836  3.          0.16854155]\t 0.9235319432135773\t 0.6577294425265764\t 0.7280976224606197\t 0.7280976224606086\n",
            "5  \t [2.20135958 9.62559813 6.         0.71280025 1.         0.39977427]\t 0.7883201967902798\t 0.6577294425265764\t 0.7348797798580413\t 0.7348797798580413\n",
            "6  \t [ 3.67323902  7.86608025  9.          0.6017103  12.          0.8976084 ]\t 0.6646588413956347\t 0.6577294425265764\t 0.7360885710255255\t 0.7360885710216637\n",
            "7  \t [ 8.8168337   8.37959662 14.          0.86429866 15.          0.72516241]\t 0.6892145672079726\t 0.6577294425265764\t 0.7341166622525704\t 0.7341166622525704\n",
            "8  \t [6.77981326 1.558009   7.         0.85055204 5.         0.30145072]\t 0.8743477887688297\t 0.6577294425265764\t 0.7330457269107141\t 0.7330457269107141\n",
            "9  \t [ 4.65266155  1.51144578 13.          0.9981878   8.          0.76538736]\t 0.6852941374864567\t 0.6577294425265764\t 0.7360471196174213\t 0.7360471196174213\n",
            "10 \t [ 9.96434657  9.7457538   7.          0.51716335 13.          0.80468719]\t 0.7098807101273504\t 0.6577294425265764\t 0.7349234924618989\t 0.7349234924618989\n",
            "11 \t [ 0.11403055  8.4704762   5.          0.64787128 18.          0.27113862]\t 0.8864529961319944\t 0.6577294425265764\t 0.7342485364105265\t 0.7342485364105265\n",
            "12 \t [ 8.75969772  9.81259093 13.          0.73915202  9.          0.12048735]\t 0.9231023673501877\t 0.6577294425265764\t 0.7369046178341202\t 0.7369046178341202\n",
            "13 \t [ 3.07772231  9.36080815 12.          0.63816578 18.          0.13286747]\t 0.9234149203761113\t 0.6577294425265764\t 0.7399937442480655\t 0.7399937442480655\n",
            "14 \t [9.71177996e-03 0.00000000e+00 1.50000000e+01 5.00000000e-01\n",
            " 1.18797628e+01 1.00000000e+00]\t 0.6585294119816538\t 0.6577294425265764\t 0.742643931224684\t 0.7426440091030598\n",
            "15 \t [0.61700864 1.88368662 5.         0.7080512  1.         0.20173876]\t 0.9297173774466645\t 0.6577294425265764\t 0.7410908227460128\t 0.7410908227460128\n",
            "16 \t [ 4.54549823  8.84141407 12.          0.50940273  3.          0.75742975]\t 0.7068100593711837\t 0.6577294425265764\t 0.7435644973903871\t 0.7435644973903871\n",
            "17 \t [4.68258101 8.96288202 5.         0.97630328 6.         0.39227084]\t 0.8031528445623343\t 0.6577294425265764\t 0.7426812077598542\t 0.7426812077598542\n",
            "18 \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]\t 0.698358780864823\t 0.6577294425265764\t 0.7431045546751343\t 0.7431045546751343\n",
            "19 \t [ 8.85073587  0.14416571 10.          0.61345236  9.          0.36196785]\t 0.873711053485897\t 0.6577294425265764\t 0.7421874059086836\t 0.7421874040128231\n",
            "20 \t [9.22875209 9.1986098  9.         0.90439491 3.         0.27523226]\t 0.8725625909092452\t 0.6577294425265764\t 0.7434461226087027\t 0.7434461226087027\n",
            "21 \t [ 4.20382838  8.11840794 14.          0.97060995 11.          0.52636944]\t 0.7250537141107671\t 0.6577294425265764\t 0.7446219961741662\t 0.7446219961741662\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7286740032592812\t 0.6577294425265764\t 0.7440491954831145\t 0.7440491954831145\n",
            "23 \t [ 9.97716226  3.28825714 13.          0.55185778 13.          0.23012169]\t 0.9247048172921157\t 0.6577294425265764\t 0.7435534590980682\t 0.7435534590980682\n",
            "24 \t [0.35274751 4.60721825 8.         0.98940661 8.         0.99370153]\t 0.6613164589989345\t 0.6577294425265764\t 0.7451684193502535\t 0.7451684193502535\n",
            "25 \t [ 4.52812342  0.19443533 13.          0.65004115  2.          0.16077491]\t 0.9247656684808231\t 0.6577294425265764\t 0.744060074625012\t 0.744060074625012\n",
            "26 \t [1.38471843 0.         5.         0.5        6.63131054 1.        ]\t 0.7205170563661122\t 0.6577294425265764\t 0.7455502392735772\t 0.7455503567860168\n",
            "27 \t [10.          0.         14.44841913  0.5         4.26342053  0.1       ]\t 0.9270066462776981\t 0.6577294425265764\t 0.7450018899449092\t 0.7450021099591203\n",
            "28 \t [ 8.98053348  8.76757495  9.82063768  0.86418592 19.25348742  0.97679707]\t 0.6579813782320892\t 0.6577294425265764\t 0.7463919928957516\t 0.7463909229942275\n",
            "29 \t [9.27654384 0.11345815 9.         0.76045104 1.         0.92226676]\t 0.6600116767225708\t 0.6577294425265764\t 0.7453848500473299\t 0.7453846379993676\n",
            "30 \t [4.8041921  4.06620309 5.         0.94317975 9.         0.20395595]\t 0.93061105311828\t 0.6577294425265764\t 0.7444492276781706\t 0.7444492276781706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52451.32960260449"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_nP9lQjUztV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f8af5b-52ae-4fe6-e848-8294e759018b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_approx_12 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_12 = GPGO_multi(surrogate_approx_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # define BayesOpt\n",
        "approx_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_12 = approx_12.getResult()[0]\n",
        "params_approx_12['max_depth'] = int(params_approx_12['max_depth'])\n",
        "params_approx_12['min_child_weight'] = int(params_approx_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_approx_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_approx_12 = xgb.train(params_approx_12, dX_approx_train12)\n",
        "pred_approx_12 = model_approx_12.predict(dX_approx_test12)\n",
        "\n",
        "rmse_approx_12 = np.sqrt(mean_squared_error(pred_approx_12, y_test12))\n",
        "rmse_approx_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.9314271055202143\t 0.7056203424268611\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.7910532936167305\t 0.7056203424268611\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.7196830962696428\t 0.7056203424268611\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7056203424268611\t 0.7056203424268611\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.8082458628311272\t 0.7056203424268611\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.74699493326549\t 0.7056203424268611\t 0.7873758687496245\t 0.7873758687496245\n",
            "2  \t [ 7.57473716  9.63637997 12.          0.83444517 10.          0.18761713]\t 0.9247498596892157\t 0.7056203424268611\t 0.785273174596175\t 0.785273174596175\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 9.04517621  0.80881017 13.          0.96890904  5.          0.75400021]\u001b[0m\t \u001b[1m\u001b[92m0.6897808103544698\u001b[0m\t \u001b[1m\u001b[92m0.6897808103544698\u001b[0m\t \u001b[1m\u001b[92m0.7903317170850199\u001b[0m\t \u001b[1m\u001b[92m0.7903317170850199\u001b[0m\n",
            "4  \t [ 2.73241117  0.55778587 14.          0.70282167 15.          0.8966204 ]\t 0.6967406870158588\t 0.6897808103544698\t 0.7738117087893788\t 0.7738117087893788\n",
            "5  \t [ 6.66970674  0.03985694  6.          0.76922453 11.          0.18327615]\t 0.9302409127927834\t 0.6897808103544698\t 0.7710739857348229\t 0.7710739857348229\n",
            "6  \t [ 1.23389285  0.85357459 13.          0.93854198  3.          0.52598214]\t 0.7221002132069921\t 0.6897808103544698\t 0.7754367581482423\t 0.7754367581482381\n",
            "7  \t [ 0.57203639  5.0857779   9.          0.68290949 10.          0.94408458]\t 0.7012842559435354\t 0.6897808103544698\t 0.7736173815777858\t 0.7736173815777858\n",
            "8  \t [ 9.11635581  9.60013795  5.          0.57034236 14.          0.41758327]\t 0.8017323350323444\t 0.6897808103544698\t 0.7716721177702356\t 0.7716721177560801\n",
            "9  \t [9.77568711 0.70796585 6.         0.73327465 3.         0.82051057]\t 0.7213506404912987\t 0.6897808103544698\t 0.7720303720205338\t 0.7720303720205338\n",
            "10 \t [ 0.14475494  9.8292754  12.          0.60331385  2.          0.9622215 ]\t 0.7073584311311387\t 0.6897808103544698\t 0.7708266720125189\t 0.77082667199224\n",
            "11 \t [ 3.24107348  8.27034509 14.          0.92485614 16.          0.53812048]\t 0.7151360298031719\t 0.6897808103544698\t 0.7695515149064602\t 0.7695515149064602\n",
            "12 \t [ 7.55307662  2.76896497 12.          0.93049335 17.          0.33736097]\t 0.7889723938717788\t 0.6897808103544698\t 0.7685542070437584\t 0.7685542070437584\n",
            "13 \t [ 0.04787228  7.48596331  8.          0.52068382 16.          0.7086396 ]\t 0.7110240148871393\t 0.6897808103544698\t 0.7688058948146393\t 0.7688058926233906\n",
            "14 \t [4.27099049 1.84437193 8.         0.60505752 3.         0.28835442]\t 0.7946180236578642\t 0.6897808103544698\t 0.7679037991469225\t 0.7679037953681115\n",
            "15 \t [ 5.00288594  8.63257736  7.          0.63451109 10.          0.4931163 ]\t 0.779054992813269\t 0.6897808103544698\t 0.768244924568441\t 0.7682448563725566\n",
            "16 \t [ 0.77892218  8.99624404 13.          0.66723238  9.          0.47803353]\t 0.7775062665234967\t 0.6897808103544698\t 0.7683396017775667\t 0.7683395529108155\n",
            "17 \t [ 8.92040797  9.99421763 13.          0.88657464 18.          0.32294618]\t 0.7893524262985254\t 0.6897808103544698\t 0.7684053844157236\t 0.7684053844157236\n",
            "18 \t [0.27586551 0.         5.         1.         1.         1.        ]\t 0.720657829823389\t 0.6897808103544698\t 0.7686113306806611\t 0.7686113060584508\n",
            "19 \t [1.43004395 0.         5.         0.5831274  6.88387308 0.1       ]\t 0.9340571709847965\t 0.6897808103544698\t 0.7680175027839395\t 0.7680177220032941\n",
            "20 \t [ 9.98175567  0.8705802   6.          0.55210219 18.          0.50471737]\t 0.7496479603542527\t 0.6897808103544698\t 0.770022444451143\t 0.770022444451143\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[ 2.35147591  0.28799347 10.28144925  0.58008711  7.46280442  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6684580755246188\u001b[0m\t \u001b[1m\u001b[92m0.6684580755246188\u001b[0m\t \u001b[1m\u001b[92m0.7697150308075553\u001b[0m\t \u001b[1m\u001b[92m0.7697152164018936\u001b[0m\n",
            "22 \t [ 6.30127505 10.          5.          1.          1.          1.        ]\t 0.7206579754575964\t 0.6684580755246188\t 0.7513943524743187\t 0.7513940555588718\n",
            "23 \t [ 7.77589547  0.99217091 15.          0.5        10.19250441  0.1       ]\t 0.9305944415458172\t 0.6684580755246188\t 0.7508736732750978\t 0.750874342868842\n",
            "24 \t [8.76763879 4.36040002 9.         0.6751541  8.         0.94911869]\t 0.7027322856127343\t 0.6684580755246188\t 0.7525886243546577\t 0.7525886243546577\n",
            "25 \t [ 9.49532945 10.         12.71748656  1.          1.          0.1       ]\t 0.9455499571698038\t 0.6684580755246188\t 0.7519076880845651\t 0.7519076857539481\n",
            "26 \t [8.97886962 5.1990592  8.         0.6115526  3.         0.92989751]\t 0.7062171777812216\t 0.6684580755246188\t 0.7537889639738723\t 0.7537889639738723\n",
            "27 \t [ 0.35496199  2.82245133 11.          0.77608605 18.          0.90361157]\t 0.6964152543036155\t 0.6684580755246188\t 0.7529949919618594\t 0.7529949919618594\n",
            "28 \t [ 3.65170008  9.58166785  7.          0.85934391 18.          0.44807251]\t 0.7757669589651004\t 0.6684580755246188\t 0.7524593789336846\t 0.7524593789336846\n",
            "29 \t [ 3.8544074   5.22723842 10.          0.76354194  1.          0.13710805]\t 0.927143786270312\t 0.6684580755246188\t 0.7524455604127821\t 0.7524455604127821\n",
            "30 \t [10.          4.82544574 13.01440539  0.5         1.          0.1       ]\t 0.9332168804927067\t 0.6684580755246188\t 0.7536398475427629\t 0.7536399150261311\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53244.71550253987"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDI2Bi9vU05U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15fa2a4-67b0-4115-d6dc-7c7093ffccdb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_approx_13 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_13 = GPGO_multi(surrogate_approx_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # define BayesOpt\n",
        "approx_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_13 = approx_13.getResult()[0]\n",
        "params_approx_13['max_depth'] = int(params_approx_13['max_depth'])\n",
        "params_approx_13['min_child_weight'] = int(params_approx_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_approx_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_approx_13 = xgb.train(params_approx_13, dX_approx_train13)\n",
        "pred_approx_13 = model_approx_13.predict(dX_approx_test13)\n",
        "\n",
        "rmse_approx_13 = np.sqrt(mean_squared_error(pred_approx_13, y_test13))\n",
        "rmse_approx_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.6628876451121497\t 0.6628876451121497\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1013657958154304\t 0.6628876451121497\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.92150734169971\t 0.6628876451121497\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.71924819784624\t 0.6628876451121497\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1014421616742969\t 0.6628876451121497\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7207240599672383\t 0.6628876451121497\t 0.7898291479807739\t 0.7898291479807739\n",
            "2  \t [6.93463528 1.25795731 8.         0.92695971 3.         0.9534311 ]\t 0.6734860180774931\t 0.6628876451121497\t 0.7806389879034862\t 0.7806389878797565\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7679544515659981\t 0.6628876451121497\t 0.7723711439477456\t 0.7723711439477456\n",
            "4  \t [ 9.69332517  0.05133704 14.          0.6050422   3.          0.79031428]\t 0.6797825903178236\t 0.6628876451121497\t 0.7690611682058053\t 0.7690611682058053\n",
            "5  \t [5.34651487 5.45650069 6.         0.93529094 7.         0.24078895]\t 1.0980632271289044\t 0.6628876451121497\t 0.7639987072322838\t 0.7639987072322838\n",
            "6  \t [ 7.68636788  7.27927184 12.          0.97932089  3.          0.87363673]\t 0.6657443951678294\t 0.6628876451121497\t 0.7728359064298369\t 0.772835906425828\n",
            "7  \t [ 6.50677714  2.64641451 14.          0.50110879 19.          0.46175841]\t 0.8250792636501453\t 0.6628876451121497\t 0.7680849136774722\t 0.7680849136774722\n",
            "8  \t [ 0.53852623  1.13078322 12.          0.85062386  1.          0.22708294]\t 1.1062273028353988\t 0.6628876451121497\t 0.7675361934445022\t 0.7675361934445022\n",
            "9  \t [ 6.80309585  9.43423094  7.          0.8851539  14.          0.77731456]\t 0.6905350263714448\t 0.6628876451121497\t 0.7742807815588181\t 0.7742807815588181\n",
            "10 \t [ 0.95213595  8.68324297 14.          0.57163216  8.          0.28130834]\t 0.9272758866528952\t 0.6628876451121497\t 0.7708662344417495\t 0.7708662344417495\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7370906275446215\t 0.6628876451121497\t 0.772302949287116\t 0.772302949287116\n",
            "12 \t [ 9.46545841  2.71414127  5.          0.83512297 13.          0.70984642]\t 0.7596192306405462\t 0.6628876451121497\t 0.7701486031027562\t 0.7701486031027562\n",
            "13 \t [ 0.65991354  4.66843968 10.          0.71271776  9.          0.9826504 ]\t 0.6689179423925529\t 0.6628876451121497\t 0.7685856909484007\t 0.7685856803216848\n",
            "14 \t [0.59196411 2.70489003 6.         0.53471064 2.         0.87047587]\t 0.71441968725325\t 0.6628876451121497\t 0.7659426446580699\t 0.7659426446580699\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.6686440552339279\t 0.6628876451121497\t 0.7641464983318925\t 0.7641464983314278\n",
            "16 \t [ 2.06284179  6.9068961   5.          0.9448545  18.          0.13792391]\t 1.0970836858783257\t 0.6628876451121497\t 0.7619721843459126\t 0.7619721843457955\n",
            "17 \t [7.55403251 6.23917493 5.         0.63649547 1.         0.75229567]\t 0.73633358340512\t 0.6628876451121497\t 0.7662897321030996\t 0.7662897321030996\n",
            "18 \t [ 2.91019341  6.38178397 14.          0.79652507  1.          0.10091662]\t 1.108112277749133\t 0.6628876451121497\t 0.7649738207001001\t 0.7649738207001001\n",
            "19 \t [ 8.70212257  9.22072414 13.          0.93050035 17.          0.7479803 ]\t 0.7016619838210264\t 0.6628876451121497\t 0.7689542548496019\t 0.7689542548491005\n",
            "20 \t [7.78054327e-03 3.05674801e+00 1.40000000e+01 9.86996551e-01\n",
            " 1.60000000e+01 3.30836599e-01]\t 0.9201059801130411\t 0.6628876451121497\t 0.7672832278374556\t 0.7672832278374556\n",
            "21 \t [9.95671825 0.88335607 5.         0.76593799 7.         0.60049246]\t 0.7676754691372668\t 0.6628876451121497\t 0.7682022847183929\t 0.7682022847183929\n",
            "22 \t [9.44502002 6.70596744 7.         0.72628773 8.         0.52383256]\t 0.7377024161191106\t 0.6628876451121497\t 0.7673348060469385\t 0.7673348060469385\n",
            "23 \t [ 2.05622909  9.08047387  8.          0.8397078  17.          0.73365999]\t 0.7124011319640049\t 0.6628876451121497\t 0.7662400652558551\t 0.7662400652558551\n",
            "24 \t [5.71666567 9.57807292 6.         0.69715499 4.         0.1016024 ]\t 1.0994513505900894\t 0.6628876451121497\t 0.7649938213497893\t 0.7649938213436858\n",
            "25 \t [ 4.58851998  9.96722725 10.          0.86802391  9.          0.49712674]\t 0.8197897150933404\t 0.6628876451121497\t 0.7680363108576707\t 0.7680363108576707\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.672888499874982\t 0.6628876451121497\t 0.7677682947655156\t 0.7677682947655156\n",
            "27 \t [ 8.09528142  1.39150052 12.          0.83538636  7.          0.34189645]\t 0.9243154896909775\t 0.6628876451121497\t 0.7662893480215494\t 0.7662893480215494\n",
            "28 \t [ 9.39601656  1.36711013  5.          0.81069129 19.          0.31051992]\t 0.9154604767665478\t 0.6628876451121497\t 0.7670810572824435\t 0.7670810572824435\n",
            "29 \t [ 1.1665804   8.5178555  13.          0.63744653 19.          0.35989497]\t 0.9216009805623578\t 0.6628876451121497\t 0.7677394239526355\t 0.7677394238432247\n",
            "30 \t [0.43091775 0.3532639  5.         0.76123896 7.         0.49074528]\t 0.8387970949832267\t 0.6628876451121497\t 0.7684155132522584\t 0.7684155132522584\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49640.64566227302"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2F_Q194U3uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "382165d4-cf7b-4df6-b8f1-3d1682930b10"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_approx_14 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_14 = GPGO_multi(surrogate_approx_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # define BayesOpt\n",
        "approx_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_14 = approx_14.getResult()[0]\n",
        "params_approx_14['max_depth'] = int(params_approx_14['max_depth'])\n",
        "params_approx_14['min_child_weight'] = int(params_approx_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_approx_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_approx_14 = xgb.train(params_approx_14, dX_approx_train14)\n",
        "pred_approx_14 = model_approx_14.predict(dX_approx_test14)\n",
        "\n",
        "rmse_approx_14 = np.sqrt(mean_squared_error(pred_approx_14, y_test14))\n",
        "rmse_approx_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.8139066743222003\t 0.6747866005380063\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.6747866005380063\t 0.6747866005380063\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.977412427074478\t 0.6747866005380063\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.6774024187451972\t 0.6747866005380063\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 1.0197967308919336\t 0.6747866005380063\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 1.0126649561802825\t 0.6747866005380063\t 0.7766813921590745\t 0.7766813921590745\n",
            "2  \t [ 5.83528891  2.63149599 12.          0.61005677 19.          0.2879488 ]\t 0.9571856949825378\t 0.6747866005380063\t 0.7855204235958163\t 0.7855204235958163\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7245455903141328\t 0.6747866005380063\t 0.7891370394223463\t 0.7891370394223463\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 1.0111604668907606\t 0.6747866005380063\t 0.7835849902939745\t 0.7835849902939745\n",
            "5  \t [9.99867084 7.44671039 9.         0.55715966 3.         0.32152891]\t 0.9600990595782894\t 0.6747866005380063\t 0.7886127643218421\t 0.7886127643218421\n",
            "6  \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]\t 1.0131910395518218\t 0.6747866005380063\t 0.7909222267645656\t 0.7909222267645656\n",
            "7  \t [ 6.6877751   9.48200682  5.          0.90861826 11.          0.9411861 ]\t 0.7242608483603965\t 0.6747866005380063\t 0.794395722487859\t 0.7943957224878562\n",
            "8  \t [ 0.63353879  9.61017877  8.          0.96421247 18.          0.39200727]\t 0.8087127953472528\t 0.6747866005380063\t 0.7902859188418508\t 0.7902859188418508\n",
            "9  \t [ 6.82711248  9.86843937 13.          0.52138031 17.          0.20003272]\t 1.0114628267773051\t 0.6747866005380063\t 0.7884675251112268\t 0.7884675251112181\n",
            "10 \t [ 8.90983817  2.82321414  7.          0.66164117 11.          0.64519606]\t 0.697395180788185\t 0.6747866005380063\t 0.7913421302218842\t 0.7913421302218842\n",
            "11 \t [3.83744645 7.95259616 7.5285931  0.65265118 6.52639813 1.        ]\t 0.6833085477835039\t 0.6747866005380063\t 0.7878155832214732\t 0.7878156506592677\n",
            "12 \t [ 1.50285169  4.17593259 14.          0.69234646  6.          0.74044842]\t 0.677587403128438\t 0.6747866005380063\t 0.7845082002049234\t 0.7845082002049234\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.25039867  4.81148287 14.          0.83239345 15.          0.88911818]\u001b[0m\t \u001b[1m\u001b[92m0.6657241930879318\u001b[0m\t \u001b[1m\u001b[92m0.6657241930879318\u001b[0m\t \u001b[1m\u001b[92m0.7814974127673558\u001b[0m\t \u001b[1m\u001b[92m0.7814974127673558\u001b[0m\n",
            "14 \t [4.48522578 6.54261798 5.         0.79314226 1.         0.29945677]\t 0.9752292115331169\t 0.6657241930879318\t 0.771550634218495\t 0.771550634218495\n",
            "15 \t [ 6.70987455  7.63355927  7.          0.88524152 18.          0.87272936]\t 0.695654285242036\t 0.6657241930879318\t 0.7735918919438618\t 0.7735918919438618\n",
            "16 \t [ 5.21920054  9.35580917 14.          0.81835368  4.          0.54800317]\t 0.7211586025861135\t 0.6657241930879318\t 0.7714027867918296\t 0.7714027867918296\n",
            "17 \t [ 4.83871117  1.89317253 13.          0.87688851 13.          0.10679344]\t 1.0126577425360461\t 0.6657241930879318\t 0.7697185324712841\t 0.7697185324712841\n",
            "18 \t [ 9.40706915  0.91600736 13.          0.648599    7.          0.62885715]\t 0.6782712913254569\t 0.6657241930879318\t 0.7721531468362122\t 0.7721531468362122\n",
            "19 \t [ 6.11645628  0.17500507  7.          0.96263937 18.          0.49631453]\t 0.8136505814470297\t 0.6657241930879318\t 0.7701312757868759\t 0.7701312757868759\n",
            "20 \t [2.03544962 0.82234782 9.         0.75192666 8.         0.57674562]\t 0.7214652120719057\t 0.6657241930879318\t 0.7697299987629567\t 0.7697299969466258\n",
            "21 \t [ 1.52900897  2.49551652 10.          0.74070159  3.          0.79386687]\t 0.6772839651254358\t 0.6657241930879318\t 0.7683799633540194\t 0.7683799629500443\n",
            "22 \t [ 7.44570943  5.21469107  9.93362029  0.5        13.87178343  0.1       ]\t 1.0099690431466606\t 0.6657241930879318\t 0.7667177803929939\t 0.7667175645370192\n",
            "23 \t [ 1.131865    9.46449787 13.          0.95242563  6.          0.3253213 ]\t 0.9637176563997644\t 0.6657241930879318\t 0.7687880149263181\t 0.7687879288614363\n",
            "24 \t [8.68356706 3.39368135 5.         0.96902719 1.         0.52647669]\t 0.7606090853553124\t 0.6657241930879318\t 0.770140598841039\t 0.7701405811834999\n",
            "25 \t [ 1.77912346  5.94690212  7.          0.6391349  10.          0.13998471]\t 1.0147931903343312\t 0.6657241930879318\t 0.7693099304523799\t 0.7693099304523799\n",
            "26 \t [ 0.  10.  15.   0.5  1.   0.1]\t 1.0144971549480983\t 0.6657241930879318\t 0.771135411453442\t 0.7711357068814223\n",
            "27 \t [8.53226404 6.98639988 5.         1.         6.3718012  1.        ]\t 0.7219271861831216\t 0.6657241930879318\t 0.7728347742086124\t 0.7728351859942328\n",
            "28 \t [ 9.70174036  9.71799099 14.          0.84593857  8.          0.66512595]\t 0.672972068481645\t 0.6657241930879318\t 0.7716931392671164\t 0.7716931392584802\n",
            "\u001b[1m\u001b[92m29\u001b[0m\t \u001b[1m\u001b[92m[ 4.76741659 10.          9.9999616   1.          1.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6559554354635349\u001b[0m\t \u001b[1m\u001b[92m0.6559554354635349\u001b[0m\t \u001b[1m\u001b[92m0.7702600168195276\u001b[0m\t \u001b[1m\u001b[92m0.7702599945307871\u001b[0m\n",
            "30 \t [ 1.26617981  4.03386415  8.          0.85223134 19.          0.86958504]\t 0.6828604856051443\t 0.6559554354635349\t 0.761138771406765\t 0.761138771406765\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52229.892868970695"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po5wImJaU6VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35cbf6d6-5894-4f7b-ba15-ba9d7c400e18"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_approx_15 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_15 = GPGO_multi(surrogate_approx_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # define BayesOpt\n",
        "approx_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_15 = approx_15.getResult()[0]\n",
        "params_approx_15['max_depth'] = int(params_approx_15['max_depth'])\n",
        "params_approx_15['min_child_weight'] = int(params_approx_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_approx_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_approx_15 = xgb.train(params_approx_15, dX_approx_train15)\n",
        "pred_approx_15 = model_approx_15.predict(dX_approx_test15)\n",
        "\n",
        "rmse_approx_15 = np.sqrt(mean_squared_error(pred_approx_15, y_test15))\n",
        "rmse_approx_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.6568473525973234\t 0.6568473525973234\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 0.9115777462403312\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 0.9091447847268881\t 0.6568473525973234\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.702826724376194\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 0.9107852583947551\t 0.6568473525973234\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.663179402460053\t 0.6568473525973234\t 0.7570167459024465\t 0.7570167459024465\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.8585273074032198\t 0.6568473525973234\t 0.7498589155313063\t 0.7498589155313063\n",
            "3  \t [ 9.6900225   0.69761314 13.          0.54877119 16.          0.55532692]\t 0.676755395441882\t 0.6568473525973234\t 0.7522698091129767\t 0.7522698091129767\n",
            "4  \t [ 3.00890132  3.25033589  6.          0.76721153 13.          0.286699  ]\t 0.8615658015198442\t 0.6568473525973234\t 0.7478764735916281\t 0.7478764735916281\n",
            "5  \t [ 7.00755347  9.83963845  5.          0.51866345 10.          0.95031515]\t 0.730615339433918\t 0.6568473525973234\t 0.7500808088437022\t 0.7500808088437022\n",
            "6  \t [ 8.69662558  6.80112051 14.          0.50188459  3.          0.90006664]\t 0.6638687110610159\t 0.6568473525973234\t 0.7481308234237891\t 0.7481308234237891\n",
            "7  \t [ 9.09795503  1.07150197  7.          0.98191679 19.          0.62951892]\t 0.6952220627574484\t 0.6568473525973234\t 0.745017407431795\t 0.7450174074297929\n",
            "8  \t [ 9.21941721  9.79827821 11.          0.81783228 11.          0.53477407]\t 0.6659586056207597\t 0.6568473525973234\t 0.7430508235663044\t 0.7430508235663044\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.7097411329660293\t 0.6568473525973234\t 0.7408311235492826\t 0.7408311235492826\n",
            "10 \t [ 8.47779105  8.43696768  5.          0.73890705 16.          0.66738091]\t 0.7564851327663848\t 0.6568473525973234\t 0.7396998158458503\t 0.7396998158458503\n",
            "11 \t [9.8850401  9.05036452 8.         0.98423572 3.         0.82693955]\t 0.6638601166418586\t 0.6568473525973234\t 0.7395425991086534\t 0.7395425991086534\n",
            "12 \t [1.37672687 0.04946237 5.         0.79719419 1.         0.81843222]\t 0.7350998875793917\t 0.6568473525973234\t 0.7379202996671788\t 0.7379202996671788\n",
            "13 \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\t 0.6855937848974291\t 0.6568473525973234\t 0.7375417360881551\t 0.7375417360881551\n",
            "14 \t [ 7.24320809  1.00477988 10.          0.73543626  1.          0.62081075]\t 0.6775831216463617\t 0.6568473525973234\t 0.736504257604104\t 0.7365042565586492\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 5.53179684  5.42623971 11.          0.96540614 10.          0.78461433]\u001b[0m\t \u001b[1m\u001b[92m0.6463871000955349\u001b[0m\t \u001b[1m\u001b[92m0.6463871000955349\u001b[0m\t \u001b[1m\u001b[92m0.7354727712078222\u001b[0m\t \u001b[1m\u001b[92m0.7354727712078222\u001b[0m\n",
            "16 \t [1.58135563 6.14676537 7.         0.58599454 7.         0.37032959]\t 0.8586845884175147\t 0.6463871000955349\t 0.7256960787366779\t 0.7256960787366779\n",
            "17 \t [ 1.99733414  0.13877735 14.          0.5792705  10.          0.44528521]\t 0.7943377363668869\t 0.6463871000955349\t 0.7272975157457706\t 0.7272975157457706\n",
            "18 \t [ 4.29171811  0.04074186 13.          0.58769183 18.          0.36351335]\t 0.8568574802990294\t 0.6463871000955349\t 0.7278602699384866\t 0.7278602699384866\n",
            "19 \t [ 1.82906731  5.15105244 12.          0.56966528 15.          0.63831204]\t 0.6762407016215379\t 0.6463871000955349\t 0.7291954294979014\t 0.7291954294979014\n",
            "20 \t [6.71458767 6.21192942 5.         0.70021974 1.         0.14733325]\t 0.9149321430036975\t 0.6463871000955349\t 0.7283130556546601\t 0.7283130037442234\n",
            "21 \t [ 7.33879012  1.13757523 10.          0.53907849 12.          0.7867979 ]\t 0.6676591765759825\t 0.6463871000955349\t 0.7302680314737936\t 0.7302668182948926\n",
            "22 \t [ 0.40222116  9.39966428 10.97544296  0.57292036  5.33430567  0.35088256]\t 0.8584859836279781\t 0.6463871000955349\t 0.7293245725212706\t 0.7293230706483272\n",
            "23 \t [ 5.3880688   2.65297896 14.          0.90613057  4.          0.23404421]\t 0.9109113159973135\t 0.6463871000955349\t 0.7304273908171771\t 0.7304273908171771\n",
            "24 \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]\t 0.756031776613528\t 0.6463871000955349\t 0.7320475056998331\t 0.7320474531797704\n",
            "25 \t [ 0.23718299  5.15069191  5.          0.53030067 17.          0.55502993]\t 0.7588357317663977\t 0.6463871000955349\t 0.7319402978953294\t 0.7319402773561391\n",
            "26 \t [ 5.12774674  9.38269657 12.          0.66930635  1.          0.1906148 ]\t 0.9139113523209742\t 0.6463871000955349\t 0.7318581888627171\t 0.7318581862813605\n",
            "27 \t [ 7.1013764   6.4581532  14.          0.85029911 15.          0.21834005]\t 0.9090028118130578\t 0.6463871000955349\t 0.7333104897277068\t 0.7333104494552147\n",
            "28 \t [ 1.066715    7.89942329  5.          1.         12.95217167  1.        ]\t 0.7191137017237054\t 0.6463871000955349\t 0.7346150924006757\t 0.7346134851651153\n",
            "29 \t [0.3364975  0.38853278 9.         0.71890632 9.         0.71653496]\t 0.6761109349749724\t 0.6463871000955349\t 0.7341409869026828\t 0.7341409864666574\n",
            "30 \t [ 6.18561281  9.20132045 12.          0.91758231  6.          0.24268371]\t 0.9100686128500474\t 0.6463871000955349\t 0.7333719357596434\t 0.7333719357596434\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50265.507092316264"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HrAQN-pU9Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b22a67e-67a6-4b64-87f0-40f3c12ac47d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_approx_16 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_16 = GPGO_multi(surrogate_approx_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # define BayesOpt\n",
        "approx_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_16 = approx_16.getResult()[0]\n",
        "params_approx_16['max_depth'] = int(params_approx_16['max_depth'])\n",
        "params_approx_16['min_child_weight'] = int(params_approx_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_approx_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_approx_16 = xgb.train(params_approx_16, dX_approx_train16)\n",
        "pred_approx_16 = model_approx_16.predict(dX_approx_test16)\n",
        "\n",
        "rmse_approx_16 = np.sqrt(mean_squared_error(pred_approx_16, y_test16))\n",
        "rmse_approx_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 0.9529819347295859\t 0.8883829281923242\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 0.9481041389252269\t 0.8883829281923242\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.8883829281923242\t 0.8883829281923242\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 0.9564077542414676\t 0.8883829281923242\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 0.9552184743546004\t 0.8883829281923242\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.9753718017522196\u001b[0m\t \u001b[1m\u001b[92m0.9753718017522196\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 0.8747438848890932\t 0.6878693399983744\t 0.8040275427718057\t 0.8040275427718057\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.8608053593354814\t 0.6878693399983744\t 0.8028355919408534\t 0.8028355919408534\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 0.9494553422981233\t 0.6878693399983744\t 0.8014251409281299\t 0.8014251409281299\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.8646755374886521\t 0.6878693399983744\t 0.803284300777709\t 0.803284300777709\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.7307340308882677\t 0.6878693399983744\t 0.802231610408923\t 0.802231610408923\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 0.9623426051674955\t 0.6878693399983744\t 0.7981359019638348\t 0.7981359019638348\n",
            "8  \t [ 5.53392197  2.00879238  6.          0.89871466 12.          0.67694144]\t 0.7620148611738933\t 0.6878693399983744\t 0.8001486769870478\t 0.8001486767224776\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.7974390418434936\u001b[0m\t \u001b[1m\u001b[92m0.7974390418434936\u001b[0m\n",
            "10 \t [ 8.77492053  6.74985642  5.          0.72525183 13.          0.93231357]\t 0.7199718018091047\t 0.6730441336589406\t 0.7819530006558432\t 0.7819530006558432\n",
            "11 \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]\t 0.9735436243628346\t 0.6730441336589406\t 0.7792863928669095\t 0.7792863928669095\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.7141008345477899\t 0.6730441336589406\t 0.7815244020544373\t 0.7815244020544373\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.7791081983700021\u001b[0m\t \u001b[1m\u001b[92m0.7791081983700021\u001b[0m\n",
            "14 \t [0.50474552 1.15372476 8.         0.52058641 1.         0.43046119]\t 0.8762709839016471\t 0.6551680070961308\t 0.762187257390749\t 0.7621872573903696\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 0.8854668121365705\t 0.6551680070961308\t 0.7626312402399327\t 0.7626312402399327\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.7778153254020743\t 0.6551680070961308\t 0.7631716723079293\t 0.7631716723079293\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 0.9718611347031094\t 0.6551680070961308\t 0.7621739835181931\t 0.7621739835181931\n",
            "18 \t [ 9.56839048  0.13416862 13.          0.80729993  3.          0.41100156]\t 0.8703303423168164\t 0.6551680070961308\t 0.763949932076101\t 0.763949932076101\n",
            "19 \t [ 9.86485549  9.03746465 10.          0.52506306 19.          0.37580875]\t 0.8664298555004347\t 0.6551680070961308\t 0.7641664588500606\t 0.7641664588500606\n",
            "20 \t [8.75370971 6.63075821 5.         0.51315816 7.         0.52603065]\t 0.8073058384557079\t 0.6551680070961308\t 0.7643106986676146\t 0.7643106986676146\n",
            "21 \t [ 3.28864291  8.88700951  7.          0.70665299 16.          0.26783249]\t 0.9496880408110411\t 0.6551680070961308\t 0.7637547060139565\t 0.7637547060139565\n",
            "22 \t [ 6.72271828  8.33075498 14.          0.78841734 10.          0.48431777]\t 0.863099611959315\t 0.6551680070961308\t 0.7649094391304653\t 0.7649083451834684\n",
            "23 \t [0.58596137 5.71336149 9.         0.70354751 9.         0.28160967]\t 0.9498200925027509\t 0.6551680070961308\t 0.764977268350964\t 0.7649772624348479\n",
            "24 \t [9.80508544 0.83042511 7.         0.54124599 9.         0.7836072 ]\t 0.7113005276137964\t 0.6551680070961308\t 0.7660089128781649\t 0.7660089128781649\n",
            "25 \t [ 9.01141716  1.23452325  9.          0.70620993 16.          0.46074297]\t 0.8622295969277951\t 0.6551680070961308\t 0.7646004247816905\t 0.7646004247816905\n",
            "26 \t [ 5.38505352  0.27838384  8.          0.64624975 19.          0.94943729]\t 0.6741571003845405\t 0.6551680070961308\t 0.7646588928412514\t 0.7646588903010758\n",
            "27 \t [ 0.2375092   5.20448002  7.          0.887766   16.          0.16167958]\t 0.971082975245141\t 0.6551680070961308\t 0.7630914529626571\t 0.7630914529626571\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 3.60668261  3.61026877 14.          0.9898327  13.          0.9620422 ]\u001b[0m\t \u001b[1m\u001b[92m0.652084379738873\u001b[0m\t \u001b[1m\u001b[92m0.652084379738873\u001b[0m\t \u001b[1m\u001b[92m0.7642783553517405\u001b[0m\t \u001b[1m\u001b[92m0.7642783553517405\u001b[0m\n",
            "29 \t [ 4.68761822 10.          5.52968999  0.5         5.85010925  1.        ]\t 0.7261261273075382\t 0.652084379738873\t 0.7602579904887521\t 0.7602572668695085\n",
            "30 \t [ 4.51433593  9.58196514 12.43272667  1.          1.          1.        ]\t 0.6570428555151187\t 0.652084379738873\t 0.759253619592086\t 0.7592524320618868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49556.08949355573"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXelbcAVVCqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b49bf7-f6c8-4971-fb6b-dbb2b020404f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_approx_17 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_17 = GPGO_multi(surrogate_approx_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # define BayesOpt\n",
        "approx_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_17 = approx_17.getResult()[0]\n",
        "params_approx_17['max_depth'] = int(params_approx_17['max_depth'])\n",
        "params_approx_17['min_child_weight'] = int(params_approx_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_approx_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_approx_17 = xgb.train(params_approx_17, dX_approx_train17)\n",
        "pred_approx_17 = model_approx_17.predict(dX_approx_test17)\n",
        "\n",
        "rmse_approx_17 = np.sqrt(mean_squared_error(pred_approx_17, y_test17))\n",
        "rmse_approx_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.7141038418197827\t 0.7141038418197827\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.8024876355160464\t 0.7141038418197827\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.7659849712152795\t 0.7141038418197827\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9684453836634761\t 0.7141038418197827\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.8556892362199922\t 0.7141038418197827\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.86898292288902\t 0.7141038418197827\t 0.8008601163353377\t 0.8008601163353377\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.778300364354035\t 0.7141038418197827\t 0.8031678891892342\t 0.8031678891892342\n",
            "3  \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\t 0.726434848802118\t 0.7141038418197827\t 0.8012680149811908\t 0.8012680149811908\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9672674042711217\t 0.7141038418197827\t 0.7982130526803441\t 0.7982130526803441\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.826366430225874\t 0.7141038418197827\t 0.803386289788417\t 0.803386289788417\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.8659399691320455\t 0.7141038418197827\t 0.8041704263763533\t 0.8041704263763533\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.7563633439329396\t 0.7141038418197827\t 0.804270529537069\t 0.804270529537069\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.861798864893942\t 0.7141038418197827\t 0.8026060695114751\t 0.8026060695114751\n",
            "9  \t [ 1.2716555   3.78378689  5.          0.57556817 17.          0.18163876]\t 0.9716163961274858\t 0.7141038418197827\t 0.8033770470955414\t 0.8033770470955414\n",
            "10 \t [1.38490793 6.87002541 5.         0.73931504 9.         0.41767138]\t 0.829976302946727\t 0.7141038418197827\t 0.8064202124025374\t 0.8064202124025374\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.8069651446453449\t 0.7141038418197827\t 0.8062381668271084\t 0.8062381668271084\n",
            "12 \t [ 9.99251025  3.68443024 14.          0.88286102  6.          0.35061034]\t 0.8574563680670202\t 0.7141038418197827\t 0.8056890538434928\t 0.8056890527458487\n",
            "13 \t [ 5.50988068  4.52551329 10.          0.62342816  9.          0.60901352]\t 0.7623016588267515\t 0.7141038418197827\t 0.8060229770740541\t 0.8060228267858964\n",
            "14 \t [5.79855217 7.64610678 9.         0.54644758 3.         0.68341681]\t 0.7349404110255493\t 0.7141038418197827\t 0.804901604246327\t 0.8049015693952833\n",
            "15 \t [ 9.19532326  8.42928342 11.          0.5289521  11.          0.74996998]\t 0.7306673350944987\t 0.7141038418197827\t 0.8035390936819792\t 0.8035390936819792\n",
            "16 \t [6.14842106 3.92031042 5.         0.80436272 5.         0.42842685]\t 0.8298337600349435\t 0.7141038418197827\t 0.8026865158552394\t 0.8026865158552394\n",
            "17 \t [ 1.93531857  1.03643759  8.          0.58366211 11.          0.77260063]\t 0.7377317601285239\t 0.7141038418197827\t 0.8023246510970021\t 0.8023244354266359\n",
            "18 \t [ 1.83368891  8.1756677   8.          0.96471075 17.          0.14868642]\t 0.9653693800994253\t 0.7141038418197827\t 0.8012934194851876\t 0.8012924909630492\n",
            "19 \t [ 1.32113565  9.62738611 14.          0.55066636 15.          0.36069244]\t 0.8636922015613553\t 0.7141038418197827\t 0.8031545227713518\t 0.8031544665260351\n",
            "20 \t [ 6.88175573  0.68997438  9.          0.55006192 19.          0.74555899]\t 0.7341056462061506\t 0.7141038418197827\t 0.8035717459701068\t 0.8035717459701068\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[ 7.32262595  0.987487   14.          0.78324612 14.          0.76403633]\u001b[0m\t \u001b[1m\u001b[92m0.7129217809179572\u001b[0m\t \u001b[1m\u001b[92m0.7129217809179572\u001b[0m\t \u001b[1m\u001b[92m0.8025800042865127\u001b[0m\t \u001b[1m\u001b[92m0.8025798186059461\u001b[0m\n",
            "\u001b[1m\u001b[92m22\u001b[0m\t \u001b[1m\u001b[92m[ 6.72796419  6.10053296 14.          0.56325639  2.          0.91580991]\u001b[0m\t \u001b[1m\u001b[92m0.672911524877989\u001b[0m\t \u001b[1m\u001b[92m0.672911524877989\u001b[0m\t \u001b[1m\u001b[92m0.8005131539235019\u001b[0m\t \u001b[1m\u001b[92m0.8005126967778937\u001b[0m\n",
            "23 \t [ 7.07271536  8.13007518  5.          0.98530219 19.          0.92839144]\t 0.7288961616067631\t 0.672911524877989\t 0.7673880335590394\t 0.7673880335590394\n",
            "\u001b[1m\u001b[92m24\u001b[0m\t \u001b[1m\u001b[92m[0.85666329 5.92364698 9.         0.69191689 5.         0.98975497]\u001b[0m\t \u001b[1m\u001b[92m0.6651465396376819\u001b[0m\t \u001b[1m\u001b[92m0.6651465396376819\u001b[0m\t \u001b[1m\u001b[92m0.76621130664546\u001b[0m\t \u001b[1m\u001b[92m0.7662111030653155\u001b[0m\n",
            "25 \t [9.66959108 0.03423869 5.         0.63791788 7.         0.65549808]\t 0.7797393754763862\t 0.6651465396376819\t 0.7587096925334973\t 0.7587096058113705\n",
            "26 \t [ 3.61406382  9.87735751 10.          0.70199599  8.          0.85082246]\t 0.721371984674188\t 0.6651465396376819\t 0.7584351582431829\t 0.7584349498796232\n",
            "27 \t [ 5.62137526  0.50742571 12.          0.60891749  1.          0.89299215]\t 0.6736748141470514\t 0.6651465396376819\t 0.7579728022459438\t 0.7579728022459438\n",
            "28 \t [ 1.82399135  0.         13.89554648  1.         12.59770987  0.1       ]\t 0.9635759955711777\t 0.6651465396376819\t 0.7566061264563113\t 0.7566060300231267\n",
            "29 \t [ 0.30609514  2.49894713 14.          0.69397027 18.          0.71750058]\t 0.7193266691045255\t 0.6651465396376819\t 0.7581305213121532\t 0.7581305213121532\n",
            "30 \t [ 7.36696598  9.94436631  5.          0.65024597 12.35877211  0.79356122]\t 0.7771306291129149\t 0.6651465396376819\t 0.7574363320962937\t 0.7574349228570361\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49991.214920392384"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJG2fAtAVFDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb61a621-ef55-4b71-f6db-9bf33cba9e12"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_approx_18 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_18 = GPGO_multi(surrogate_approx_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # define BayesOpt\n",
        "approx_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_18 = approx_18.getResult()[0]\n",
        "params_approx_18['max_depth'] = int(params_approx_18['max_depth'])\n",
        "params_approx_18['min_child_weight'] = int(params_approx_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_approx_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_approx_18 = xgb.train(params_approx_18, dX_approx_train18)\n",
        "pred_approx_18 = model_approx_18.predict(dX_approx_test18)\n",
        "\n",
        "rmse_approx_18 = np.sqrt(mean_squared_error(pred_approx_18, y_test18))\n",
        "rmse_approx_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.8853778201562241\t 0.6968179065224296\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.6968179065224296\t 0.6968179065224296\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.8778125354456613\t 0.6968179065224296\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.7421252990295766\t 0.6968179065224296\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.7041732589144625\t 0.6968179065224296\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.7694285284315747\t 0.6968179065224296\t 0.7771064693201806\t 0.7771064693201806\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.65697799905797\u001b[0m\t \u001b[1m\u001b[92m0.65697799905797\u001b[0m\t \u001b[1m\u001b[92m0.7764727345203654\u001b[0m\t \u001b[1m\u001b[92m0.7764727345203654\u001b[0m\n",
            "3  \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]\t 0.740342057576812\t 0.65697799905797\t 0.7397342408258117\t 0.7397342408258117\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.893321248053374\t 0.65697799905797\t 0.7389033826325974\t 0.7389033826325974\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.697182883066114\t 0.65697799905797\t 0.7435696700894455\t 0.7435696700894455\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 0.934413982456124\t 0.65697799905797\t 0.741128125476474\t 0.741128125476474\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 0.9339136409907385\t 0.65697799905797\t 0.745958351294845\t 0.745958351294845\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.7385292363411576\t 0.65697799905797\t 0.7494821119662312\t 0.7494821119662312\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.7318688282028918\t 0.65697799905797\t 0.7481949792679833\t 0.7481949792679833\n",
            "10 \t [ 2.63732683  4.87962717 14.          0.99986359 19.          0.86504659]\t 0.6917610853596872\t 0.65697799905797\t 0.746964909641931\t 0.7469649021767727\n",
            "11 \t [ 0.2637722   4.11659493  5.          0.61604637 11.          0.22374653]\t 0.934862140121076\t 0.65697799905797\t 0.7452158677188335\t 0.7452158677188335\n",
            "12 \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]\t 0.7530157713797134\t 0.65697799905797\t 0.7477701147432034\t 0.7477701147432034\n",
            "13 \t [ 1.3916722   9.15131624  5.          0.92812295 18.          0.82773453]\t 0.7365431886620325\t 0.65697799905797\t 0.7474255235029827\t 0.7474255235029827\n",
            "14 \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]\t 0.7718546540038929\t 0.65697799905797\t 0.7465789092736319\t 0.7465788678000492\n",
            "15 \t [3.36125149 0.38066674 7.         0.83604387 7.         0.55591318]\t 0.7419578447057461\t 0.65697799905797\t 0.7463217268451418\t 0.7463217268451418\n",
            "16 \t [ 9.04557073  7.9579056  13.          0.79457459 11.          0.37545445]\t 0.7687992481703463\t 0.65697799905797\t 0.7456858943561633\t 0.7456858943535379\n",
            "17 \t [ 2.34351425  1.27586471  9.          0.74485285 16.          0.89346344]\t 0.6655993851049598\t 0.65697799905797\t 0.7454555641536954\t 0.7454555641536954\n",
            "18 \t [10.         10.         14.          0.75379427  3.06370112  0.1       ]\t 0.9280504165220231\t 0.65697799905797\t 0.7440402692225808\t 0.7440404145049062\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 0.932289957585124\t 0.65697799905797\t 0.7461274321845837\t 0.7461274321845837\n",
            "20 \t [ 0.  10.   5.   0.5  1.   0.1]\t 0.9362285777120221\t 0.65697799905797\t 0.7478560332331666\t 0.7478569924129363\n",
            "21 \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]\t 0.7726367108722194\t 0.65697799905797\t 0.749612457913038\t 0.749612457913038\n",
            "22 \t [ 2.15969651  1.61319227 12.41871649  0.94546904  2.36772112  0.1580843 ]\t 0.9247968393206525\t 0.65697799905797\t 0.7493171919876331\t 0.7493159095950855\n",
            "23 \t [ 9.60573175  5.82788742 10.9943721   0.53089835  1.          0.82835279]\t 0.7129799229450521\t 0.65697799905797\t 0.7507452055549038\t 0.7507443231737113\n",
            "24 \t [ 4.74991262  6.10890882  7.          0.89072689 18.          0.37196885]\t 0.877748764283187\t 0.65697799905797\t 0.7499682422659947\t 0.7499682422659947\n",
            "25 \t [ 7.7160498   0.         14.54719584  0.74897098  9.67091771  0.1       ]\t 0.9280846314118076\t 0.65697799905797\t 0.7506585395861041\t 0.7506590889684628\n",
            "26 \t [ 0.          0.82278309 13.0015607   0.5        12.67152355  0.1       ]\t 0.9269344839845217\t 0.65697799905797\t 0.7519331432564862\t 0.7519319619271506\n",
            "27 \t [ 0.24526093  9.9241919  13.          0.52652258 12.          0.43108972]\t 0.7744431314593644\t 0.65697799905797\t 0.7531110862174679\t 0.7531102893564742\n",
            "28 \t [0.68687496 7.61952967 6.         0.69420959 8.         0.10232955]\t 0.9323929856925224\t 0.65697799905797\t 0.7528694165700264\t 0.7528694165700264\n",
            "29 \t [9.89337178 3.81875947 5.         0.59649267 7.         0.86884145]\t 0.739125810481835\t 0.65697799905797\t 0.754000636151151\t 0.754000636151151\n",
            "30 \t [ 8.50412994  4.6442541   7.223544    0.70343088 14.04435864  1.        ]\t 0.679863465970249\t 0.65697799905797\t 0.7532984865339665\t 0.7532974789081748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47814.5922880461"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHidSEGcVHvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b694467-2ae9-4d02-8921-08a33bfc6b4a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_approx_19 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_19 = GPGO_multi(surrogate_approx_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # define BayesOpt\n",
        "approx_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_19 = approx_19.getResult()[0]\n",
        "params_approx_19['max_depth'] = int(params_approx_19['max_depth'])\n",
        "params_approx_19['min_child_weight'] = int(params_approx_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_approx_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_approx_19 = xgb.train(params_approx_19, dX_approx_train19)\n",
        "pred_approx_19 = model_approx_19.predict(dX_approx_test19)\n",
        "\n",
        "rmse_approx_19 = np.sqrt(mean_squared_error(pred_approx_19, y_test19))\n",
        "rmse_approx_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.7381578397530673\t 0.7295721630591281\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.7470234185181706\t 0.7295721630591281\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.018052265694813\t 0.7295721630591281\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.7455570460653044\t 0.7295721630591281\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.7295721630591281\t 0.7295721630591281\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.8082051265289488\u001b[0m\t \u001b[1m\u001b[92m0.8082051265289488\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.7019341665321482\t 0.6773838424850286\t 0.7606330392636097\t 0.7606330392636097\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.0199606306890758\t 0.6773838424850286\t 0.7576906678490443\t 0.7576906678490443\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.7327508164518542\t 0.6773838424850286\t 0.7674662531409786\t 0.7674662531409786\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.8626234515673594\t 0.6773838424850286\t 0.7652958001931282\t 0.7652958001931282\n",
            "6  \t [ 8.42570155  4.07975309 12.          0.91619537  8.          0.61684591]\t 0.7059767781587389\t 0.6773838424850286\t 0.7671673061229787\t 0.7671673060235292\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.7065170119936448\t 0.6773838424850286\t 0.7648077983670685\t 0.7648077983670685\n",
            "8  \t [ 3.63408057  9.2502169   7.          0.59622027 10.          0.62731569]\t 0.7317581740148223\t 0.6773838424850286\t 0.7628473282865348\t 0.7628473282865348\n",
            "9  \t [ 1.79783097  1.91934618  5.          0.77893204 13.          0.47835366]\t 0.7857306346205829\t 0.6773838424850286\t 0.7616740231889512\t 0.7616740231889512\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[ 4.45643696  6.43761151 10.          0.59521711 15.          0.91320177]\u001b[0m\t \u001b[1m\u001b[92m0.6773536163008785\u001b[0m\t \u001b[1m\u001b[92m0.6773536163008785\u001b[0m\t \u001b[1m\u001b[92m0.7616921344392374\u001b[0m\t \u001b[1m\u001b[92m0.76169212089172\u001b[0m\n",
            "11 \t [9.94019054 7.43271319 5.         0.78342194 4.         0.90198883]\t 0.7333445147195274\t 0.6773536163008785\t 0.759830248451067\t 0.759830248451067\n",
            "12 \t [ 9.41792853  9.11293681  6.          0.87420995 11.          0.8007601 ]\t 0.7086968319816249\t 0.6773536163008785\t 0.7590867869270901\t 0.7590867778260292\n",
            "13 \t [0.04130113 6.56643894 8.         0.8316257  6.         0.23623124]\t 1.0149681655113947\t 0.6773536163008785\t 0.758062674007446\t 0.7580626651834708\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.7335321473751593\t 0.6773536163008785\t 0.7622989923373739\t 0.7622989923373739\n",
            "15 \t [ 3.29312611  0.9704927   6.          0.68391426 19.          0.43020049]\t 0.767048132195449\t 0.6773536163008785\t 0.7615474298781947\t 0.7615474298781947\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.7391934581482711\t 0.6773536163008785\t 0.76131113613378\t 0.76131113613378\n",
            "17 \t [9.42305669 0.3423134  7.         0.77066127 8.         0.63693457]\t 0.7280806792663158\t 0.6773536163008785\t 0.7607470946932241\t 0.7607470946932241\n",
            "18 \t [ 8.22438004  9.86720872 12.          0.98809303  7.          0.25782248]\t 0.8614867876969733\t 0.6773536163008785\t 0.7601039771712855\t 0.7601039771712855\n",
            "19 \t [ 1.10650842  9.77537077 14.          0.83431584  1.          0.5884296 ]\t 0.7222348544284499\t 0.6773536163008785\t 0.7611335751279223\t 0.7611335751279223\n",
            "20 \t [ 9.47745808  9.50911305 13.          0.70555451  1.          0.87222907]\t 0.6776716071409558\t 0.6773536163008785\t 0.7604662769115055\t 0.7604662769115055\n",
            "21 \t [0.63927877 0.36518569 5.         0.86590497 1.         0.99444527]\t 0.729970665502028\t 0.6773536163008785\t 0.7594138133578733\t 0.7594137344590953\n",
            "22 \t [ 7.24710389  4.18219359  9.96986951  0.9266459  19.24884275  0.65974043]\t 0.709849987661854\t 0.6773536163008785\t 0.7589388808138923\t 0.758938687738587\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[ 4.81184079  0.03027405 11.          0.96437956 10.          0.97759806]\u001b[0m\t \u001b[1m\u001b[92m0.6662783138908545\u001b[0m\t \u001b[1m\u001b[92m0.6662783138908545\u001b[0m\t \u001b[1m\u001b[92m0.758310217308891\u001b[0m\t \u001b[1m\u001b[92m0.758310217308891\u001b[0m\n",
            "24 \t [9.54373892 0.         5.         1.         1.         0.1       ]\t 1.0122267825742954\t 0.6662783138908545\t 0.748391061495386\t 0.7483913427912496\n",
            "25 \t [ 0.          3.66607317  9.58419431  0.5        16.55863848  1.        ]\t 0.6696062832683504\t 0.6662783138908545\t 0.7510487326113364\t 0.7510486037742119\n",
            "26 \t [ 9.2876216   9.23467155  9.          0.78119986 18.          0.66822771]\t 0.7093766156846689\t 0.6662783138908545\t 0.7501129697892968\t 0.7501126299215012\n",
            "27 \t [ 6.97335991  0.         13.37391204  0.5        14.60328071  0.1       ]\t 1.0167178451415917\t 0.6662783138908545\t 0.7495509799356807\t 0.7495504973000461\n",
            "28 \t [ 1.75932639  1.35419645 13.          0.50094122  6.          0.77830601]\t 0.6752776634122892\t 0.6662783138908545\t 0.7519710019665383\t 0.7519710019665383\n",
            "\u001b[1m\u001b[92m29\u001b[0m\t \u001b[1m\u001b[92m[10.          8.32657361 12.00096033  0.5        11.49329725  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6641262875116065\u001b[0m\t \u001b[1m\u001b[92m0.6641262875116065\u001b[0m\t \u001b[1m\u001b[92m0.7511337199809228\u001b[0m\t \u001b[1m\u001b[92m0.7511330298563322\u001b[0m\n",
            "30 \t [ 9.80949062  0.42526047 11.          0.61085682  4.          0.94165398]\t 0.6776829311951872\t 0.6641262875116065\t 0.7485362514132591\t 0.7485362514132591\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50488.45409603373"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGPYRJhVKsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be76fef0-19e2-4155-a038-09626463c03b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'approx' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_approx_20 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "approx_20 = GPGO_multi(surrogate_approx_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # define BayesOpt\n",
        "approx_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_approx_20 = approx_20.getResult()[0]\n",
        "params_approx_20['max_depth'] = int(params_approx_20['max_depth'])\n",
        "params_approx_20['min_child_weight'] = int(params_approx_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_approx_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_approx_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_approx_20 = xgb.train(params_approx_20, dX_approx_train20)\n",
        "pred_approx_20 = model_approx_20.predict(dX_approx_test20)\n",
        "\n",
        "rmse_approx_20 = np.sqrt(mean_squared_error(pred_approx_20, y_test20))\n",
        "rmse_approx_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.6597299542050263\t 0.6597299542050263\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.6983733363249625\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0633118913318171\t 0.6597299542050263\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.8790653027854468\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.8778581695963045\t 0.6597299542050263\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.8825953654337161\t 0.6597299542050263\t 0.76573211512963\t 0.76573211512963\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0635732061044851\t 0.6597299542050263\t 0.7672300477807688\t 0.7672300477807688\n",
            "3  \t [ 1.96661701  1.73294312 11.          0.93201699  1.          0.60463107]\t 0.7502219040814293\t 0.6597299542050263\t 0.7771356027246019\t 0.7771356027246015\n",
            "4  \t [1.41824857 5.09758018 5.         0.56802833 5.         0.75704697]\t 0.7367139517682284\t 0.6597299542050263\t 0.7723659389560228\t 0.7723659389560228\n",
            "5  \t [ 0.41794531  1.88324969 13.          0.88408406 13.          0.43578884]\t 0.8006234291185196\t 0.6597299542050263\t 0.768244281556162\t 0.768244281556162\n",
            "6  \t [ 9.80686472  1.37296982 14.          0.9100959  10.          0.1681724 ]\t 1.058727127460609\t 0.6597299542050263\t 0.7666342893425379\t 0.7666342893425379\n",
            "7  \t [ 9.82409087  4.45469949 11.          0.53160513  4.          0.66763423]\t 0.703165388931625\t 0.6597299542050263\t 0.7729767286953101\t 0.7729767286953101\n",
            "8  \t [ 1.38961005  8.07802396  5.33485594  0.90745689 14.86002239  1.        ]\t 0.7137653686029104\t 0.6597299542050263\t 0.7690326067960926\t 0.7690326014281404\n",
            "9  \t [ 9.18502444  7.06345806 13.          0.62385346 16.          0.94993271]\t 0.6703678866341707\t 0.6597299542050263\t 0.765980172966536\t 0.765980172966536\n",
            "10 \t [8.51004072 7.2917763  5.         0.96135496 1.         0.57493956]\t 0.8036859734991779\t 0.6597299542050263\t 0.7627003952117537\t 0.7627003952117537\n",
            "11 \t [ 2.39246017  9.03448663 12.          0.90271931 13.          0.8329575 ]\t 0.6843389602423093\t 0.6597299542050263\t 0.7619563306274945\t 0.7619563259059837\n",
            "12 \t [ 6.87684298  0.81341201 12.          0.63438989 19.          0.35708107]\t 0.8844718896334441\t 0.6597299542050263\t 0.7594449043317393\t 0.7594449043317393\n",
            "13 \t [ 3.51322154  8.79998304 14.          0.91142182  1.          0.35103611]\t 0.8922088424958478\t 0.6597299542050263\t 0.7605451429407076\t 0.7605451429407076\n",
            "14 \t [ 2.08109501  0.31399789  8.          0.78263012 11.          0.87673239]\t 0.6735019021239127\t 0.6597299542050263\t 0.7615039409658182\t 0.7615039409658182\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 3.5266353   3.62825369 14.          0.9501826  16.          0.91321928]\u001b[0m\t \u001b[1m\u001b[92m0.6526439057061743\u001b[0m\t \u001b[1m\u001b[92m0.6526439057061743\u001b[0m\t \u001b[1m\u001b[92m0.7593482591203923\u001b[0m\t \u001b[1m\u001b[92m0.7593482591203923\u001b[0m\n",
            "16 \t [ 7.31252146  8.98299937  5.          0.81221269 16.          0.68394735]\t 0.7337730558747049\t 0.6526439057061743\t 0.751432463201094\t 0.7514322502101414\n",
            "17 \t [ 8.3723055   9.68266939 11.          0.50145124  1.          0.82596229]\t 0.7117644991570005\t 0.6526439057061743\t 0.7503235813399134\t 0.7503235463018856\n",
            "18 \t [9.75772838 6.7101588  5.         0.62878535 6.         0.70628106]\t 0.7359001366214661\t 0.6526439057061743\t 0.7490565216120231\t 0.7490556193262178\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[ 9.37662646  9.01778668  9.63009438  1.         19.64735054  0.88792542]\u001b[0m\t \u001b[1m\u001b[92m0.6473295219381677\u001b[0m\t \u001b[1m\u001b[92m0.6473295219381677\u001b[0m\t \u001b[1m\u001b[92m0.7481677119924002\u001b[0m\t \u001b[1m\u001b[92m0.7481680442354439\u001b[0m\n",
            "20 \t [ 5.3866253   1.98558863 14.          0.93996594  6.          0.18524928]\t 1.0595101751758718\t 0.6473295219381677\t 0.7422934629860308\t 0.7422934629860308\n",
            "21 \t [ 2.16891361  0.40236972  6.          0.57865056 19.          0.33900997]\t 0.8933558323113931\t 0.6473295219381677\t 0.7457387077301756\t 0.7457387077301756\n",
            "22 \t [7.09521948 1.98932663 6.         0.65989265 2.         0.73023722]\t 0.7154584586376316\t 0.6473295219381677\t 0.7466257026377242\t 0.7466255647959328\n",
            "23 \t [ 9.71937523  0.84081751  8.          0.83815718 13.          0.15657647]\t 1.0605231713179224\t 0.6473295219381677\t 0.7456056105298948\t 0.7456056105298948\n",
            "24 \t [ 1.96869013  7.00264368 10.          0.79233192  3.          0.8133863 ]\t 0.6902699854328027\t 0.6473295219381677\t 0.7486123159792949\t 0.7486123159792949\n",
            "25 \t [ 9.4251418   2.62898513  5.          0.90450266 19.          0.92733176]\t 0.7242573372960255\t 0.6473295219381677\t 0.7473314946679405\t 0.7473314901548916\n",
            "26 \t [ 4.87229684 10.          5.          1.          8.10483957  1.        ]\t 0.7107922540164859\t 0.6473295219381677\t 0.7464663720813013\t 0.7464657977837874\n",
            "27 \t [ 9.53962563 10.         11.20732896  0.58783271 12.39849273  0.1       ]\t 1.062937570264393\t 0.6473295219381677\t 0.7455443459685792\t 0.7455430195157421\n",
            "28 \t [ 4.20070036 10.          5.87483699  1.          1.          0.1       ]\t 1.0181319769409545\t 0.6473295219381677\t 0.7481633981573849\t 0.7481624778539406\n",
            "29 \t [ 0.          9.02281337  5.          0.54896511 19.57031729  0.41410605]\t 0.8322375481139381\t 0.6473295219381677\t 0.7501124515939009\t 0.7501109050852373\n",
            "30 \t [ 0.89195001  6.01604215 14.          0.84121292  7.          0.44798682]\t 0.8038070345544759\t 0.6473295219381677\t 0.7501485569858722\t 0.7501485569858722\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50289.6721734975"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1d_1LyydIfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8343f4-734d-43ed-dbed-676c82faf240"
      },
      "source": [
        "end_approx = time.time()\n",
        "end_approx\n",
        "\n",
        "time_approx = end_approx - start_approx\n",
        "time_approx\n",
        "\n",
        "start_exact = time.time()\n",
        "start_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1663854702.4545271"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAyOw7XYVwAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a369ce35-1b03-49ef-a2e2-88a34d7ecc2a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_exact_1 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=test_perc, random_state=run_num_1)\n",
        "\n",
        "def f_syn_polarity1(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_1, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train1, y=y_train1).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_1 = dGPGO(surrogate_exact_1, Acquisition_grad(util), f_syn_polarity1, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_1.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_1 = exact_1.getResult()[0]\n",
        "params_exact_1['max_depth'] = int(params_exact_1['max_depth'])\n",
        "params_exact_1['min_child_weight'] = int(params_exact_1['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train1 = xgb.DMatrix(X_train1, y_train1)\n",
        "dX_exact_test1 = xgb.DMatrix(X_test1, y_test1)\n",
        "model_exact_1 = xgb.train(params_exact_1, dX_exact_train1)\n",
        "pred_exact_1 = model_exact_1.predict(dX_exact_test1)\n",
        "\n",
        "rmse_exact_1 = np.sqrt(mean_squared_error(pred_exact_1, y_test1))\n",
        "rmse_exact_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.17022005  7.20324493 14.          0.65116629 16.          0.31248008]\t 1.0028690365100252\t 0.6536753952667645\t    \t    \n",
            "init\t [ 3.96580727  3.87910741 11.          0.96776954  6.          0.71669755]\t 0.7391862019705779\t 0.6536753952667645\t    \t    \n",
            "init\t [ 2.0445225   8.78117436  7.          0.95698101 10.          0.48762871]\t 0.8806962872539386\t 0.6536753952667645\t    \t    \n",
            "init\t [ 9.39127789  7.78389236 14.          0.98413079  2.          0.87851823]\t 0.6536753952667645\t 0.6536753952667645\t    \t    \n",
            "init\t [8.29146907 8.29603359 8.         0.58491521 9.         0.18851215]\t 1.062518544792604\t 0.6536753952667645\t    \t    \n",
            "1  \t [ 7.86951474  0.6406733  11.          0.78919481 19.          0.44182296]\t 0.8659738506300403\t 0.6536753952667645\t 0.7709551930853659\t 0.7709551930853659\n",
            "2  \t [ 0.74723898  0.36469704 11.          0.84902862 15.          0.10419698]\t 1.0589776023267656\t 0.6536753952667645\t 0.7701844514649209\t 0.7701844514649209\n",
            "3  \t [ 3.61274713  8.16007507 11.          0.84840025 19.          0.76215891]\t 0.6771887207267527\t 0.6536753952667645\t 0.7787070305878608\t 0.7787070305878608\n",
            "4  \t [ 9.28266952  0.44927819  7.          0.97265422 12.          0.93288355]\t 0.6820774846874944\t 0.6536753952667645\t 0.7709451767560833\t 0.7709451767560833\n",
            "5  \t [0.         0.         5.         0.5        3.65739054 0.1       ]\t 1.0640504359985177\t 0.6536753952667645\t 0.7649651639686715\t 0.7649651639679055\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6504936383293095\u001b[0m\t \u001b[1m\u001b[92m0.6504936383293095\u001b[0m\t \u001b[1m\u001b[92m0.7716990261410619\u001b[0m\t \u001b[1m\u001b[92m0.7716990261325786\u001b[0m\n",
            "7  \t [ 2.05722318  9.92568059 11.          0.85938245  2.          0.31039182]\t 1.0042308077866626\t 0.6504936383293095\t 0.7636236123347916\t 0.7636236123347916\n",
            "8  \t [8.51945771 8.4424986  8.         0.90741371 1.         0.49942468]\t 0.8757522803338091\t 0.6504936383293095\t 0.7673741111668627\t 0.7673741111668627\n",
            "9  \t [ 8.9493952   3.29146002  5.          0.79714543 18.          0.48413921]\t 0.8991339428185847\t 0.6504936383293095\t 0.7673295582456\t 0.7673295582456\n",
            "10 \t [ 9.11336104  7.53362458  9.          0.74107696 16.          0.6810286 ]\t 0.7469510576000753\t 0.6504936383293095\t 0.76780412505703\t 0.76780412505703\n",
            "11 \t [ 9.4605503   2.00186066 12.          0.69186722  8.          0.11311186]\t 1.061946992849472\t 0.6504936383293095\t 0.7653277524390256\t 0.7653277524390256\n",
            "12 \t [6.76356635 2.31703141 5.         0.84148498 5.         0.43949556]\t 0.8998699639297213\t 0.6504936383293095\t 0.7693142955076059\t 0.7693142955076059\n",
            "13 \t [ 0.31984184  8.77960419  5.          0.79374224 16.          0.99761184]\t 0.7310969316491746\t 0.6504936383293095\t 0.769600353403209\t 0.769600353403209\n",
            "14 \t [ 0.99440257  2.23238431 10.          0.58984965 12.          0.68792603]\t 0.7499303794197336\t 0.6504936383293095\t 0.7672188350623935\t 0.7672188350623935\n",
            "15 \t [ 2.32915468  1.90336795  5.          0.54716167 18.          0.78236256]\t 0.7419028406254192\t 0.6504936383293095\t 0.7653201069972189\t 0.7653201069972189\n",
            "16 \t [ 0.21685405  7.71152333 13.          0.94772928  9.          0.78016857]\t 0.6760611870438261\t 0.6504936383293095\t 0.7635323384343659\t 0.7635323384343659\n",
            "17 \t [ 8.08876599  0.64586721 10.          0.91410013  1.          0.41017354]\t 0.8706463597576839\t 0.6504936383293095\t 0.7611155017567466\t 0.7611155017567466\n",
            "18 \t [4.01068305 5.82215042 6.         0.51115042 3.         0.68931927]\t 0.7871419831134446\t 0.6504936383293095\t 0.7613046463813535\t 0.7613046463813535\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.          9.50808262  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6470594877203972\u001b[0m\t \u001b[1m\u001b[92m0.6470594877203972\u001b[0m\t \u001b[1m\u001b[92m0.7604212291491176\u001b[0m\t \u001b[1m\u001b[92m0.760421072761009\u001b[0m\n",
            "20 \t [ 4.36435759  2.79479498 14.          0.68678246  1.          0.99022627]\t 0.6690805643320504\t 0.6470594877203972\t 0.7554730923236446\t 0.7554730923236446\n",
            "21 \t [ 6.93320156  6.33066268 13.          0.93499381 10.          0.7729426 ]\t 0.6748924552701796\t 0.6470594877203972\t 0.7535818686326858\t 0.7535818686326858\n",
            "22 \t [ 4.65410509  7.57869444  5.          0.7635136  15.          0.8131422 ]\t 0.7396988098813949\t 0.6470594877203972\t 0.7518759424013293\t 0.7518759424013293\n",
            "23 \t [ 0.376211    1.37074912 10.          0.60705086  3.          0.79924964]\t 0.6879216919311674\t 0.6470594877203972\t 0.7508896989612278\t 0.7508896989612278\n",
            "24 \t [9.91212104 3.52811735 6.         0.93018572 1.         0.49999318]\t 0.8890012000810771\t 0.6470594877203972\t 0.7495119296619542\t 0.7495119296619542\n",
            "25 \t [ 5.51374986  1.28974321 14.          0.63277445 13.          0.91834745]\t 0.6609468085776722\t 0.6470594877203972\t 0.7501664696618958\t 0.7501664696618958\n",
            "26 \t [ 0.50749748  8.96045258 11.          0.56036852 13.          0.50747166]\t 0.8199733593059948\t 0.6470594877203972\t 0.7486840990185816\t 0.7486840990185816\n",
            "27 \t [ 9.80506138  4.80078528 13.          0.71095318 17.          0.3227225 ]\t 1.0006677560529766\t 0.6470594877203972\t 0.7486468451645742\t 0.7486468451645742\n",
            "28 \t [ 0.          0.          5.          0.5        13.77592619  0.1       ]\t 1.0646372078494821\t 0.6470594877203972\t 0.7504283677265828\t 0.7504289607957686\n",
            "29 \t [0.05092638 2.85775637 5.         0.53783562 8.01270437 0.1576807 ]\t 1.065529042043676\t 0.6470594877203972\t 0.7528165704797797\t 0.7528162569303094\n",
            "30 \t [ 3.57982931  9.40933622 11.          0.73034117  7.          0.92682434]\t 0.6617439770794065\t 0.6470594877203972\t 0.755070397567421\t 0.755070397567421\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47099.16270975631"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrDQbChpZ48F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ebd523-649f-4414-bc47-a0ea9b346af8"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_exact_2 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=test_perc, random_state=run_num_2)\n",
        "\n",
        "def f_syn_polarity2(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_2, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train2, y=y_train2).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_2 = dGPGO(surrogate_exact_2, Acquisition_grad(util), f_syn_polarity2, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_2.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_2 = exact_2.getResult()[0]\n",
        "params_exact_2['max_depth'] = int(params_exact_2['max_depth'])\n",
        "params_exact_2['min_child_weight'] = int(params_exact_2['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train2 = xgb.DMatrix(X_train2, y_train2)\n",
        "dX_exact_test2 = xgb.DMatrix(X_test2, y_test2)\n",
        "model_exact_2 = xgb.train(params_exact_2, dX_exact_train2)\n",
        "pred_exact_2 = model_exact_2.predict(dX_exact_test2)\n",
        "\n",
        "rmse_exact_2 = np.sqrt(mean_squared_error(pred_exact_2, y_test2))\n",
        "rmse_exact_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 4.35994902  0.25926232 11.          0.97386531 12.          0.47833102]\t 0.778909206070606\t 0.681387807728051\t    \t    \n",
            "init\t [ 3.30334821  2.04648634 10.          0.55997527  6.          0.71472339]\t 0.681387807728051\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.9856117   5.86796978  8.          0.89266757 11.          0.59158659]\t 0.7040746477543849\t 0.681387807728051\t    \t    \n",
            "init\t [ 4.07307832  1.76984624 13.          0.75262305  7.          0.35908193]\t 0.7953147984784036\t 0.681387807728051\t    \t    \n",
            "init\t [ 1.16193318  1.81727038  9.          0.79837265 19.          0.29965165]\t 0.7954413972964868\t 0.681387807728051\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[9.68290573 5.74953535 8.         0.93445831 2.         0.81872709]\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.6807577751383148\u001b[0m\t \u001b[1m\u001b[92m0.7560589160240606\u001b[0m\t \u001b[1m\u001b[92m0.7560589160240606\u001b[0m\n",
            "2  \t [ 2.17907321  8.34965852  5.          0.91660625 18.          0.97349298]\t 0.7341430302765248\t 0.6807577751383148\t 0.7525465118812166\t 0.7525465118812166\n",
            "3  \t [ 3.86971225  8.36249195 14.          0.65193715  2.          0.53564822]\t 0.7073935536898857\t 0.6807577751383148\t 0.7523077377011698\t 0.7523077377011698\n",
            "4  \t [ 8.78180153  6.61060882 12.          0.91523653 18.          0.29687212]\t 0.7899041327973497\t 0.6807577751383148\t 0.7512771597589967\t 0.7512771597589967\n",
            "5  \t [ 1.04358891  9.72033478 14.          0.5859025  14.          0.459264  ]\t 0.7887181971022355\t 0.6807577751383148\t 0.752899933264899\t 0.752899933264899\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[ 9.90020282  3.3367177  10.          0.62203407  7.          0.71235234]\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.67907472219801\u001b[0m\t \u001b[1m\u001b[92m0.754248125090027\u001b[0m\t \u001b[1m\u001b[92m0.754248125090027\u001b[0m\n",
            "7  \t [ 9.14946201  2.43697872  6.          0.997805   19.          0.45949208]\t 0.8064071783057642\t 0.67907472219801\t 0.751235522947184\t 0.751235522947184\n",
            "8  \t [3.03571116 4.83939078 5.         0.66625528 1.         0.23130028]\t 0.872344629033322\t 0.67907472219801\t 0.7527302293019899\t 0.7527302293019899\n",
            "9  \t [ 4.57706999  8.33565192 11.          0.6188546   7.          0.54017925]\t 0.7035850285613279\t 0.67907472219801\t 0.7555599922415924\t 0.7555599922415924\n",
            "10 \t [0.  0.  5.  0.5 1.  0.1]\t 0.8726019020039407\t 0.67907472219801\t 0.7545733083006153\t 0.7545733083006153\n",
            "11 \t [4.59560507 9.66694693 5.         0.8652774  6.         0.90565092]\t 0.7323276592879555\t 0.67907472219801\t 0.7567929504866381\t 0.7567929504866381\n",
            "\u001b[1m\u001b[92m12\u001b[0m\t \u001b[1m\u001b[92m[ 3.17254321  4.53260476 14.27821641  1.         19.27821641  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6548129477393342\u001b[0m\t \u001b[1m\u001b[92m0.6548129477393342\u001b[0m\t \u001b[1m\u001b[92m0.7563086212933685\u001b[0m\t \u001b[1m\u001b[92m0.7563086134594142\u001b[0m\n",
            "13 \t [ 6.62295179  6.77584978 14.          0.65936287 12.          0.50955919]\t 0.7009189105357144\t 0.6548129477393342\t 0.7350724979959629\t 0.7350724979959629\n",
            "14 \t [ 1.44915477  0.14257847  6.          0.52441016 14.          0.6286643 ]\t 0.7143733066956096\t 0.6548129477393342\t 0.7342906236297694\t 0.7342906236297694\n",
            "15 \t [ 9.80429676  9.59801315  7.          0.61168386 14.          0.66107461]\t 0.6949698710548621\t 0.6548129477393342\t 0.7337725966039825\t 0.7337725966039825\n",
            "16 \t [ 0.57492216  8.73281603  8.          0.69247391 11.          0.62472664]\t 0.7089638014463941\t 0.6548129477393342\t 0.7331010609101627\t 0.7331010609101627\n",
            "17 \t [ 9.61885664  9.78589131 14.          0.8903706   1.          0.14094172]\t 0.86262646699532\t 0.6548129477393342\t 0.732580193455693\t 0.732580193455693\n",
            "18 \t [ 3.01450225  9.70375381  6.          0.82619754 13.          0.3960041 ]\t 0.8079567027245342\t 0.6548129477393342\t 0.7341816984577221\t 0.7341816984577221\n",
            "\u001b[1m\u001b[92m19\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.          8.38478567  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6545280158217619\u001b[0m\t \u001b[1m\u001b[92m0.6545280158217619\u001b[0m\t \u001b[1m\u001b[92m0.734840290313352\u001b[0m\t \u001b[1m\u001b[92m0.7348402408636654\u001b[0m\n",
            "20 \t [0.62273619 1.29124124 6.         0.81123451 8.         0.42451055]\t 0.8085428854730617\t 0.6545280158217619\t 0.7335983666685417\t 0.7335983666685417\n",
            "21 \t [ 9.43489051  1.92776052  5.          0.94651025 13.          0.65362327]\t 0.7353610247014348\t 0.6545280158217619\t 0.73426225438646\t 0.73426225438646\n",
            "22 \t [10. 10. 15.  1. 20.  1.]\t 0.6547874419782912\t 0.6545280158217619\t 0.7340913958152867\t 0.7340913957544368\n",
            "23 \t [ 9.52098346  0.33052792 12.          0.76433264 19.          0.79735818]\t 0.6730101149750612\t 0.6545280158217619\t 0.733176171997248\t 0.733176171997248\n",
            "24 \t [ 5.48814708  1.96120195 13.          0.89659682  1.          0.34125713]\t 0.7953122343367733\t 0.6545280158217619\t 0.7324816791289626\t 0.7324816791289626\n",
            "25 \t [ 0.16062273  8.48138353 13.          0.56952276 19.          0.688064  ]\t 0.6782595088703027\t 0.6545280158217619\t 0.7329641582003859\t 0.7329641582003859\n",
            "26 \t [ 9.33066006  2.69311478 11.          0.84131379 14.          0.25006316]\t 0.7914069073674315\t 0.6545280158217619\t 0.7323653088074342\t 0.7323653088074342\n",
            "27 \t [ 8.92720117  4.31465286 13.          0.70553933  1.          0.75946259]\t 0.6817048020092698\t 0.6545280158217619\t 0.7327845631046086\t 0.7327845631046086\n",
            "28 \t [ 7.32261517  3.77223908 13.          0.66532455  8.          0.34613674]\t 0.7978087661541414\t 0.6545280158217619\t 0.7322569627772613\t 0.7322569627772613\n",
            "29 \t [5.81010949 0.56240018 5.99976172 0.5        8.99976172 0.1       ]\t 0.8723704426355099\t 0.6545280158217619\t 0.7326730605535008\t 0.732672018548013\n",
            "30 \t [5.50325767 0.         8.14624067 0.5        1.         0.1       ]\t 0.864332108007188\t 0.6545280158217619\t 0.7337646622888412\t 0.7337643115625824\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48667.13187685448"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpUPyXRfZ95Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c89de6c-058e-4e0e-b5ff-617ef2c92239"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_exact_3 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=test_perc, random_state=run_num_3)\n",
        "\n",
        "def f_syn_polarity3(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_3, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train3, y=y_train3).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_3 = dGPGO(surrogate_exact_3, Acquisition_grad(util), f_syn_polarity3, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_3.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_3 = exact_3.getResult()[0]\n",
        "params_exact_3['max_depth'] = int(params_exact_3['max_depth'])\n",
        "params_exact_3['min_child_weight'] = int(params_exact_3['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train3 = xgb.DMatrix(X_train3, y_train3)\n",
        "dX_exact_test3 = xgb.DMatrix(X_test3, y_test3)\n",
        "model_exact_3 = xgb.train(params_exact_3, dX_exact_train3)\n",
        "pred_exact_3 = model_exact_3.predict(dX_exact_test3)\n",
        "\n",
        "rmse_exact_3 = np.sqrt(mean_squared_error(pred_exact_3, y_test3))\n",
        "rmse_exact_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.50797903  7.08147823 13.          0.56066429 11.          0.11687321]\t 1.0213644638508028\t 0.7688389438662246\t    \t    \n",
            "init\t [ 0.40630737  2.47888297 11.          0.72040492 13.          0.23083313]\t 1.022822678309975\t 0.7688389438662246\t    \t    \n",
            "init\t [ 4.53172301  2.15577008 11.          0.74631796  2.          0.60296868]\t 0.7688389438662246\t 0.7688389438662246\t    \t    \n",
            "init\t [ 2.59252447  4.15101197 13.          0.79330998  8.          0.24118096]\t 1.0239688135226253\t 0.7688389438662246\t    \t    \n",
            "init\t [ 5.44649018  7.80314765 10.          0.62879264 18.          0.44917413]\t 0.8703298117399682\t 0.7688389438662246\t    \t    \n",
            "1  \t [1.56262424 9.7795241  5.         0.91450054 5.         0.53102391]\t 0.8050626816251143\t 0.7688389438662246\t 0.8803862854675509\t 0.8803862854675509\n",
            "2  \t [ 7.69133691  0.25025283 10.          0.52101543 12.          0.10383979]\t 1.0212658686211613\t 0.7688389438662246\t 0.8740711069939675\t 0.8740711069939675\n",
            "3  \t [ 7.38032831  9.94067232 11.          0.77461843  2.          0.2199184 ]\t 1.0239673069901083\t 0.7688389438662246\t 0.8781440483203176\t 0.8781440483203176\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[ 4.06522402  9.52384028  5.          0.68629723 13.          0.87617671]\u001b[0m\t \u001b[1m\u001b[92m0.7354945860729\u001b[0m\t \u001b[1m\u001b[92m0.7354945860729\u001b[0m\t \u001b[1m\u001b[92m0.8812899306874933\u001b[0m\t \u001b[1m\u001b[92m0.8812899306874933\u001b[0m\n",
            "5  \t [3.68953475 2.95525094 5.         0.6894371  8.         0.99869195]\t 0.7371180474782232\t 0.7354945860729\t 0.8488027752716415\t 0.8488027752716415\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[ 9.6148103   3.70501061 15.          1.          5.1870017   1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6525688047390801\u001b[0m\t \u001b[1m\u001b[92m0.6525688047390801\u001b[0m\t \u001b[1m\u001b[92m0.8437685072735122\u001b[0m\t \u001b[1m\u001b[92m0.8437685072735122\u001b[0m\n",
            "7  \t [10.         10.         15.          1.         19.27344908  1.        ]\t 0.6548396524742095\t 0.6525688047390801\t 0.7730888127288206\t 0.7730888125822962\n",
            "8  \t [ 9.53161135  3.58753306 10.32905356  1.         16.32905356  1.        ]\t 0.6600136580153023\t 0.6525688047390801\t 0.7678530907584441\t 0.7678530909771569\n",
            "9  \t [9.68641233 7.7212035  5.         0.60078619 2.         0.57796031]\t 0.8027093215752258\t 0.6525688047390801\t 0.7634776412542466\t 0.7634776412542466\n",
            "10 \t [ 4.43398983  0.1775468  13.          0.67757521 18.          0.85307217]\t 0.7055608319391503\t 0.6525688047390801\t 0.7623063397673181\t 0.7623063397673181\n",
            "11 \t [ 1.21954001  0.36323278  6.          0.64916715 17.          0.72126664]\t 0.7591259448829037\t 0.6525688047390801\t 0.7595813671576002\t 0.7595813671576002\n",
            "12 \t [ 7.36281279  7.66763777  8.          0.59948159 13.          0.98370581]\t 0.6998375974069359\t 0.6525688047390801\t 0.7580484086739221\t 0.7580484086739221\n",
            "13 \t [0.         0.         5.         0.5        2.36885519 0.1       ]\t 1.0276632741585485\t 0.6525688047390801\t 0.7557969829273093\t 0.7557969828167741\n",
            "14 \t [0.86375274 7.69964496 8.         0.67182269 1.         0.12474838]\t 1.0238038898846435\t 0.6525688047390801\t 0.759324288655923\t 0.759324288655923\n",
            "15 \t [ 9.826652    4.08520653 10.          0.79056425  8.          0.64363996]\t 0.7286853621038535\t 0.6525688047390801\t 0.7623907802636798\t 0.7623907802636798\n",
            "16 \t [5.16820535 1.73655339 5.         0.50842306 1.         0.74078179]\t 0.7707586189513046\t 0.6525688047390801\t 0.7606341270387952\t 0.7606341270387952\n",
            "17 \t [ 9.40129426  8.85637698 13.          0.72340176  7.          0.76030308]\t 0.7059876882234674\t 0.6525688047390801\t 0.7595666977617914\t 0.7595666977617914\n",
            "18 \t [ 8.50267404  2.17033522  6.          0.50604942 19.          0.82390736]\t 0.7325461349588777\t 0.6525688047390801\t 0.7578317078623942\t 0.7578317078623942\n",
            "19 \t [ 0.59117942  7.04764364 14.          0.92579676 15.          0.40983297]\t 0.8649856112240915\t 0.6525688047390801\t 0.7565358825050271\t 0.7565358825050271\n",
            "20 \t [6.03739837 7.88708686 5.         0.82648265 8.         0.58420151]\t 0.8065292315417267\t 0.6525688047390801\t 0.7568976785778957\t 0.7568976785778957\n",
            "21 \t [ 3.40633968  0.23269315 10.          0.64291679  9.          0.50934585]\t 0.7623669782968152\t 0.6525688047390801\t 0.7565430735408613\t 0.7565430735408613\n",
            "22 \t [ 0.78461818  3.701541    6.          0.6408993  13.          0.37507717]\t 0.8886646016393479\t 0.6525688047390801\t 0.755746365993128\t 0.755746365993128\n",
            "23 \t [ 9.71610686  2.88363039 10.          0.71373353  2.          0.42833271]\t 0.8752416347792465\t 0.6525688047390801\t 0.7563682354272477\t 0.7563682354272477\n",
            "24 \t [ 8.79332091  9.88707083  7.          0.70656561 19.          0.98686954]\t 0.7009296182379514\t 0.6525688047390801\t 0.7567963186695607\t 0.7567963186695607\n",
            "25 \t [ 1.19479331  9.65045285 13.          0.86256417  8.          0.11307769]\t 1.0222244229776496\t 0.6525688047390801\t 0.7555277159709543\t 0.7555277159709543\n",
            "26 \t [ 6.05702602  0.88990025  5.          0.89549846 14.          0.28308539]\t 0.9893676443143098\t 0.6525688047390801\t 0.7575910267817995\t 0.7575910267817995\n",
            "27 \t [ 8.57708758  3.2701384   5.          0.77055576 10.          0.49757192]\t 0.9026358311898663\t 0.6525688047390801\t 0.7591416837827927\t 0.7591416837827927\n",
            "28 \t [10.         10.         15.          1.         13.13753072  1.        ]\t 0.6529788389734763\t 0.6525688047390801\t 0.7596947916257684\t 0.7596935199352605\n",
            "29 \t [ 5.84314941  4.68170974 14.          0.65810876 16.          0.11547757]\t 1.0220787308806796\t 0.6525688047390801\t 0.7581521543593066\t 0.7581521543593066\n",
            "30 \t [ 0.50646974  6.72570721  7.          0.51798099 18.          0.75487674]\t 0.7188022076639518\t 0.6525688047390801\t 0.7598871141020161\t 0.7598871141020161\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47903.28519988491"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_exact_4 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=test_perc, random_state=run_num_4)\n",
        "\n",
        "def f_syn_polarity4(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_4, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train4, y=y_train4).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_4 = dGPGO(surrogate_exact_4, Acquisition_grad(util), f_syn_polarity4, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_4.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_4 = exact_4.getResult()[0]\n",
        "params_exact_4['max_depth'] = int(params_exact_4['max_depth'])\n",
        "params_exact_4['min_child_weight'] = int(params_exact_4['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train4 = xgb.DMatrix(X_train4, y_train4)\n",
        "dX_exact_test4 = xgb.DMatrix(X_test4, y_test4)\n",
        "model_exact_4 = xgb.train(params_exact_4, dX_exact_train4)\n",
        "pred_exact_4 = model_exact_4.predict(dX_exact_test4)\n",
        "\n",
        "rmse_exact_4 = np.sqrt(mean_squared_error(pred_exact_4, y_test4))\n",
        "rmse_exact_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdDTsSEtNuf-",
        "outputId": "55064ed4-2797-4deb-daf7-6ea2f093ea5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [9.67029839 5.47232249 6.         0.92781047 9.         0.72795594]\t 0.7356156069458683\t 0.6641721421409617\t    \t    \n",
            "init\t [ 2.16089496  9.76274455 12.          0.62649118  9.          0.66966679]\t 0.7070759857649549\t 0.6641721421409617\t    \t    \n",
            "init\t [ 0.05159149  5.72356491  9.          0.99170034 10.          0.10808749]\t 0.9423811784101735\t 0.6641721421409617\t    \t    \n",
            "init\t [ 3.86571283  0.44160058 10.          0.90553105 18.          0.95407958]\t 0.6641721421409617\t 0.6641721421409617\t    \t    \n",
            "init\t [ 7.86305986  8.66289299  6.          0.53285477 14.          0.25117497]\t 0.8244425146132294\t 0.6641721421409617\t    \t    \n",
            "1  \t [ 8.45443649  8.61014312 11.          0.83475494  1.          0.14018305]\t 0.9441431878307984\t 0.6641721421409617\t 0.7500033112311408\t 0.7500033112311408\n",
            "2  \t [ 0.90674561  6.32290535 11.          0.94435129  1.          0.40346185]\t 0.7807426885653221\t 0.6641721421409617\t 0.7583013466771482\t 0.7583013466771482\n",
            "3  \t [ 7.37481669  1.69273565 11.          0.93066167  4.          0.26673965]\t 0.8222887232504895\t 0.6641721421409617\t 0.7571106204475303\t 0.7571106204475303\n",
            "4  \t [ 5.92074392  7.05411368 14.          0.56897417 18.          0.54051446]\t 0.7168223003470561\t 0.6641721421409617\t 0.7576834442271202\t 0.7576834442271202\n",
            "5  \t [0.         0.         5.         0.5        6.88412711 0.1       ]\t 0.9404794500681988\t 0.6641721421409617\t 0.7549480093604417\t 0.7549480089434363\n",
            "6  \t [ 9.52993971  0.33702013  5.          0.64331783 18.          0.12071935]\t 0.9390440646887555\t 0.6641721421409617\t 0.7592936309087559\t 0.7592936309087559\n",
            "7  \t [ 4.78239078  2.50215387 14.          0.69422942 12.          0.74303412]\t 0.7026919855148966\t 0.6641721421409617\t 0.7627862931185334\t 0.7627862931185334\n",
            "8  \t [3.86538132 1.78391589 5.         0.96297978 2.         0.70393647]\t 0.754992983638292\t 0.6641721421409617\t 0.7600323367217588\t 0.7600323367217588\n",
            "9  \t [2.90623288 8.58681802 5.         0.88137808 4.         0.34595373]\t 0.8313950332853073\t 0.6641721421409617\t 0.7587252617624973\t 0.7587252617624973\n",
            "10 \t [ 3.07807355  8.11709345  7.          0.6375573  19.          0.82418508]\t 0.7129287838369809\t 0.6641721421409617\t 0.7591258174250441\t 0.7591258174250441\n",
            "11 \t [ 9.65147322  0.33792642 12.          0.92327424 17.          0.84355403]\t 0.681769217592037\t 0.6641721421409617\t 0.7573274849588544\t 0.7573274849588544\n",
            "12 \t [ 8.53851234  9.68927616 10.          0.7634358   8.          0.30193276]\t 0.8224752672657477\t 0.6641721421409617\t 0.7552704948062057\t 0.7552704948062057\n",
            "13 \t [ 0.10754788  4.0859453  12.          0.99073826 19.          0.8694598 ]\t 0.6811049216882321\t 0.6641721421409617\t 0.7556523696367874\t 0.7556523696367874\n",
            "14 \t [ 3.22282465  1.05364145  6.          0.75774626 12.          0.92739587]\t 0.7076032952079638\t 0.6641721421409617\t 0.7539045036234514\t 0.7539045036234514\n",
            "15 \t [9.41541409 7.69245319 5.         0.52626745 1.         0.60186246]\t 0.7682434061303821\t 0.6641721421409617\t 0.7526804851917116\t 0.7526804851917116\n",
            "16 \t [ 1.59376327  9.3637724   5.          0.56698742 13.          0.29635446]\t 0.8312840491127815\t 0.6641721421409617\t 0.7523713162907743\t 0.7523713162907743\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[10.          3.01601323 13.24130573  1.          8.24130573  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.642839666819077\u001b[0m\t \u001b[1m\u001b[92m0.642839666819077\u001b[0m\t \u001b[1m\u001b[92m0.7529428785313182\u001b[0m\t \u001b[1m\u001b[92m0.7529421740091994\u001b[0m\n",
            "18 \t [ 3.8330061   0.35722521 10.          0.9669447   8.          0.85083452]\t 0.6866407929155406\t 0.642839666819077\t 0.7342140578482953\t 0.7342140578482953\n",
            "19 \t [10. 10. 15.  1. 20.  1.]\t 0.6437292534451688\t 0.642839666819077\t 0.7330646725290185\t 0.7330646725235421\n",
            "20 \t [ 7.85117777  8.88777162 12.          0.91846109 14.          0.15331143]\t 0.9427358983432921\t 0.642839666819077\t 0.7315756813003548\t 0.7315756813003548\n",
            "21 \t [ 2.53595099  3.58249861 14.          0.85804634  5.          0.53784435]\t 0.7147790736420511\t 0.642839666819077\t 0.7336617944961293\t 0.7336617944961293\n",
            "22 \t [ 0.47074559  8.10477098 13.          0.56791553 14.          0.20602216]\t 0.9419371446444249\t 0.642839666819077\t 0.7329417113468858\t 0.7329417113468858\n",
            "23 \t [4.54498845 4.73987501 6.         0.7658368  6.         0.15012886]\t 0.9412996363676764\t 0.642839666819077\t 0.7348091574077783\t 0.7348091574077783\n",
            "24 \t [9.26767626 0.09691703 5.         0.59554562 3.         0.95249041]\t 0.7275000597513097\t 0.642839666819077\t 0.7365308470529642\t 0.7365308470529642\n",
            "25 \t [4.21410488 1.53847897 8.         0.72947689 4.         0.95835056]\t 0.6751026509280861\t 0.642839666819077\t 0.7359038590350621\t 0.7359038590350621\n",
            "26 \t [ 9.495708    4.85934023 11.58899474  1.         19.95789409  1.        ]\t 0.6466111289033497\t 0.642839666819077\t 0.7348647908360322\t 0.7348645395598575\n",
            "27 \t [ 6.25552615  8.72883389 15.          1.         10.09332851  1.        ]\t 0.6432518554714678\t 0.642839666819077\t 0.7336818094179949\t 0.7336812396584759\n",
            "28 \t [ 3.47874821  4.86744807  8.          0.53112697 15.          0.6459008 ]\t 0.7163474474482164\t 0.642839666819077\t 0.7325490894008174\t 0.7325490894008174\n",
            "29 \t [ 8.50796214  3.11637479 10.          0.93318944 12.          0.724404  ]\t 0.700372085094922\t 0.642839666819077\t 0.7320267024577164\t 0.7320267024577164\n",
            "30 \t [ 1.72078221  1.85338202  5.          0.88677213 19.          0.37340399]\t 0.830888552375632\t 0.642839666819077\t 0.7314058781778385\t 0.7314058781778385\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50129.172794870865"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJmI9saAaEG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94e09e5-f4db-4e9d-c7e0-10f2014e6452"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_exact_5 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=test_perc, random_state=run_num_5)\n",
        "\n",
        "def f_syn_polarity5(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_5, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train5, y=y_train5).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_5 = dGPGO(surrogate_exact_5, Acquisition_grad(util), f_syn_polarity5, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_5.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_5 = exact_5.getResult()[0]\n",
        "params_exact_5['max_depth'] = int(params_exact_5['max_depth'])\n",
        "params_exact_5['min_child_weight'] = int(params_exact_5['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train5 = xgb.DMatrix(X_train5, y_train5)\n",
        "dX_exact_test5 = xgb.DMatrix(X_test5, y_test5)\n",
        "model_exact_5 = xgb.train(params_exact_5, dX_exact_train5)\n",
        "pred_exact_5 = model_exact_5.predict(dX_exact_test5)\n",
        "\n",
        "rmse_exact_5 = np.sqrt(mean_squared_error(pred_exact_5, y_test5))\n",
        "rmse_exact_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.21993171  8.70732306 11.          0.68186845 10.          0.53957007]\t 0.7403320965261992\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.11743863  7.65907856  5.          0.64840025 16.          0.82745351]\t 0.7493104333264211\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.49458883  8.19472793  6.          0.93996852 19.          0.36647194]\t 0.9342492295788805\t 0.7403320965261992\t    \t    \n",
            "init\t [ 6.28787909  5.7983781   6.          0.63290956 17.          0.18402673]\t 0.939514214921639\t 0.7403320965261992\t    \t    \n",
            "init\t [8.26554249 8.33492742 9.         0.97900675 3.         0.26957319]\t 0.921290745787579\t 0.7403320965261992\t    \t    \n",
            "1  \t [1.95474956 1.21548467 5.         0.65548996 6.         0.3261206 ]\t 0.9436861715841889\t 0.7403320965261992\t 0.8307757424254011\t 0.8307757424254011\n",
            "2  \t [ 3.90043826  0.30059527 11.          0.95660877 13.          0.16396145]\t 0.9276450520884063\t 0.7403320965261992\t 0.8351876237820846\t 0.8351876237820846\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 1.89102498  3.81201457 14.          0.79693323  4.          0.52365093]\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.7398148307506893\u001b[0m\t \u001b[1m\u001b[92m0.8376427386399233\u001b[0m\t \u001b[1m\u001b[92m0.8376427386399233\u001b[0m\n",
            "4  \t [ 8.98063632  2.97885127  9.          0.64249728 18.          0.16342995]\t 0.9276698902289097\t 0.7398148307506893\t 0.8345699130171362\t 0.8345699130171362\n",
            "\u001b[1m\u001b[92m5\u001b[0m\t \u001b[1m\u001b[92m[ 7.2080363   0.14020863 14.          0.70262402  1.          0.81354205]\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.6989575443158274\u001b[0m\t \u001b[1m\u001b[92m0.8349503125715962\u001b[0m\t \u001b[1m\u001b[92m0.8349503125715962\u001b[0m\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10.          9.20714694 14.82482637  1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6465555412981011\u001b[0m\t \u001b[1m\u001b[92m0.6465555412981011\u001b[0m\t \u001b[1m\u001b[92m0.7979933663675036\u001b[0m\t \u001b[1m\u001b[92m0.7979933663674998\u001b[0m\n",
            "7  \t [4.37003348 9.87890289 5.         0.65374913 7.         0.62009063]\t 0.8160533272968584\t 0.6465555412981011\t 0.7519105852152673\t 0.7519105852152673\n",
            "8  \t [ 2.68679241  7.25440098 14.          0.65390023 17.          0.99358304]\t 0.6747588495441635\t 0.6465555412981011\t 0.7514193512961175\t 0.7514193512961175\n",
            "9  \t [ 9.58792626  8.48977785 13.          0.60628176  9.          0.18518956]\t 0.9277423136052668\t 0.6465555412981011\t 0.7481260160027395\t 0.7481260160027395\n",
            "10 \t [ 6.97752806  2.98678749 10.          0.57146948  7.          0.9882264 ]\t 0.6796390241442563\t 0.6465555412981011\t 0.7504454995716423\t 0.7504454995716423\n",
            "11 \t [ 9.88162042  4.98501997  7.          0.71514689 11.          0.88825005]\t 0.6938260252917123\t 0.6465555412981011\t 0.7477315683443103\t 0.7477315683443103\n",
            "12 \t [ 1.24947698  9.04398434 11.          0.51619206  1.          0.25149054]\t 0.938747258179798\t 0.6465555412981011\t 0.7455649429366492\t 0.7455649429366492\n",
            "13 \t [4.29434972 2.01082809 8.         0.64047641 1.         0.68777935]\t 0.7130088179210804\t 0.6465555412981011\t 0.7478491556416376\t 0.7478491556416376\n",
            "14 \t [8.65416386 1.0753157  5.         0.51446617 5.         0.26433033]\t 0.9436404003700456\t 0.6465555412981011\t 0.7461851520591176\t 0.7461851520591176\n",
            "15 \t [ 0.69381482  7.09764326  5.          0.79260103 13.          0.36148114]\t 0.9417860014577227\t 0.6465555412981011\t 0.7482810696855621\t 0.7482810696855621\n",
            "16 \t [ 5.90866369  1.23912394  5.          0.73203526 13.          0.44895514]\t 0.8392510578678525\t 0.6465555412981011\t 0.7501304180423882\t 0.7501304180423882\n",
            "17 \t [ 9.82957504  3.67845167 14.          0.66259018 12.          0.65947706]\t 0.6974835790346434\t 0.6465555412981011\t 0.7502582765316814\t 0.7502582765316814\n",
            "18 \t [10.          3.18766873 14.10156321  1.         18.10156321  1.        ]\t 0.6465714231532321\t 0.6465555412981011\t 0.7486152301869081\t 0.7486151712219632\n",
            "19 \t [ 9.67824264  9.83755809  7.94909693  1.         14.94909693  1.        ]\t 0.6736078720266473\t 0.6465555412981011\t 0.7465811650760902\t 0.7465818320191632\n",
            "20 \t [ 2.93448298  5.80717368  5.          0.89608154 19.          0.6387738 ]\t 0.7616619440927369\t 0.6465555412981011\t 0.7456303750959281\t 0.7456303750959281\n",
            "21 \t [ 1.45932766  1.48724096 14.          0.8053907  17.          0.73407168]\t 0.696669546047991\t 0.6465555412981011\t 0.7444006521562236\t 0.7444006521562236\n",
            "22 \t [ 0.12492594  0.58358283  5.          0.5        11.87676381  0.1       ]\t 0.9483510508189781\t 0.6465555412981011\t 0.743217303931038\t 0.7432172945455242\n",
            "23 \t [0.  0.  5.  0.5 1.  0.1]\t 0.9489319500726727\t 0.6465555412981011\t 0.7448684859094703\t 0.7448682962173312\n",
            "24 \t [1.41074526 4.28313712 8.38281555 0.5        9.38281555 0.15849215]\t 0.9293037345375664\t 0.6465555412981011\t 0.7464047067058347\t 0.7464045712592099\n",
            "\u001b[1m\u001b[92m25\u001b[0m\t \u001b[1m\u001b[92m[ 7.43981396 10.         15.          1.         13.22201082  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6453688917834572\u001b[0m\t \u001b[1m\u001b[92m0.6453688917834572\u001b[0m\t \u001b[1m\u001b[92m0.7476061489305442\u001b[0m\t \u001b[1m\u001b[92m0.7476052954439499\u001b[0m\n",
            "26 \t [4.58320067 5.59686818 5.         0.5        4.         0.1       ]\t 0.9486520629538309\t 0.6453688917834572\t 0.745136440882437\t 0.7451369984170504\n",
            "27 \t [ 4.84811053  9.7699338  13.65242817  1.          3.65242817  1.        ]\t 0.6471699397200679\t 0.6453688917834572\t 0.7464822485532676\t 0.7464816528412037\n",
            "28 \t [9.64880583 0.85455793 9.         0.80366346 1.         0.54097439]\t 0.7473671119907898\t 0.6453688917834572\t 0.7450588743929187\t 0.7450588743929187\n",
            "29 \t [ 3.14006356  4.19464608 14.          0.50534541 10.          0.31510518]\t 0.932875387887278\t 0.6453688917834572\t 0.7444767638673874\t 0.7444767638673874\n",
            "30 \t [ 6.81145528  4.86961392 14.9076086   1.          4.9076086   1.        ]\t 0.6476571917741235\t 0.6453688917834572\t 0.7455676544446422\t 0.7455678790991679\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50948.78345022395"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_exact_6 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train6, X_test6, y_train6, y_test6 = train_test_split(X, y, test_size=test_perc, random_state=run_num_6)\n",
        "\n",
        "def f_syn_polarity6(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=int(min_child_weight),\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_6, objective = 'reg:squarederror', eval_metric = 'rmse')\n",
        "    score = np.array(cross_val_score(reg, X=X_train6, y=y_train6).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_6 = dGPGO(surrogate_exact_6, Acquisition_grad(util), f_syn_polarity6, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_6.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_6 = exact_6.getResult()[0]\n",
        "params_exact_6['max_depth'] = int(params_exact_6['max_depth'])\n",
        "params_exact_6['min_child_weight'] = int(params_exact_6['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train6 = xgb.DMatrix(X_train6, y_train6)\n",
        "dX_exact_test6 = xgb.DMatrix(X_test6, y_test6)\n",
        "model_exact_6 = xgb.train(params_exact_6, dX_exact_train6)\n",
        "pred_exact_6 = model_exact_6.predict(dX_exact_test6)\n",
        "\n",
        "rmse_exact_6 = np.sqrt(mean_squared_error(pred_exact_6, y_test6))\n",
        "rmse_exact_6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i707LrINxei",
        "outputId": "f8b87a1c-45f6-481a-c9fe-0906def8a16e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [8.92860151 3.31979805 5.         0.99251441 2.         0.57683563]\t 0.8597082353696148\t 0.7312157182363477\t    \t    \n",
            "init\t [4.18807429 3.35407849 9.         0.87750649 3.         0.56623277]\t 0.8283267033366734\t 0.7312157182363477\t    \t    \n",
            "init\t [ 5.788586    6.45355096 14.          0.70660047 12.          0.82154882]\t 0.7312157182363477\t 0.7312157182363477\t    \t    \n",
            "init\t [4.58184578 6.73834679 5.         0.90108528 3.         0.65482895]\t 0.835804847353631\t 0.7312157182363477\t    \t    \n",
            "init\t [ 4.42510505  5.75952352 14.          0.97882365 15.          0.29525604]\t 1.0201879064028692\t 0.7312157182363477\t    \t    \n",
            "1  \t [ 2.83859384  1.8954219   7.          0.66740302 13.          0.2701964 ]\t 1.019213535386702\t 0.7312157182363477\t 0.8256502022984815\t 0.8256502022984815\n",
            "2  \t [ 8.38264396  7.97650716 14.          0.82584689  4.          0.25017455]\t 1.0290226001513474\t 0.7312157182363477\t 0.8336863137033097\t 0.8336863137033097\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6519505196682808\u001b[0m\t \u001b[1m\u001b[92m0.6519505196682808\u001b[0m\t \u001b[1m\u001b[92m0.8398324733166328\u001b[0m\t \u001b[1m\u001b[92m0.8398324733163676\u001b[0m\n",
            "4  \t [ 9.72322443  9.21177696  5.          0.87917074 11.          0.86681736]\t 0.7899771348224893\t 0.6519505196682808\t 0.7696965431247302\t 0.7696965431247302\n",
            "5  \t [ 0.84801146  1.44124026 14.          0.54887437  7.          0.93547384]\t 0.6939533330723558\t 0.6519505196682808\t 0.7667602288913095\t 0.7667602288913095\n",
            "6  \t [7.42016587 0.72798902 9.         0.97721739 9.         0.86131056]\t 0.7293057049573171\t 0.6519505196682808\t 0.7619210582667122\t 0.7619210582667122\n",
            "7  \t [ 9.63031278  5.84246315  5.          0.67198611 19.          0.39028114]\t 0.9590357487434403\t 0.6519505196682808\t 0.7587351978746582\t 0.7587351978746582\n",
            "8  \t [0.89868821 8.1396473  7.         0.63042404 9.         0.55598816]\t 0.8398728988030857\t 0.6519505196682808\t 0.7617317492993843\t 0.7617317492993843\n",
            "9  \t [ 4.92956291  9.843232    9.          0.65534372 18.          0.66177662]\t 0.7778179264363217\t 0.6519505196682808\t 0.7614422706583253\t 0.7614422706583253\n",
            "10 \t [ 7.86118021  0.9120861  13.          0.79963906  4.          0.57767943]\t 0.830497675973147\t 0.6519505196682808\t 0.7598874393330745\t 0.7598874393330745\n",
            "11 \t [ 6.40351874  0.13565515 11.          0.58564403 18.          0.80232868]\t 0.7351278242287741\t 0.6519505196682808\t 0.7594759692083365\t 0.7594759692083365\n",
            "12 \t [ 0.6198914   8.6243298  14.          0.61994866  8.          0.27181131]\t 1.0274646480117697\t 0.6519505196682808\t 0.757525991775534\t 0.757525991775534\n",
            "13 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0641944470930125\t 0.6519505196682808\t 0.7611591993386028\t 0.7611591993386028\n",
            "14 \t [ 1.35461816  3.68867636  7.          0.97358458 19.          0.99760691]\t 0.7008772370455423\t 0.6519505196682808\t 0.7650297084278916\t 0.7650297084278916\n",
            "15 \t [ 0.81201206  8.38911567 10.          0.69531918  2.          0.65392368]\t 0.7796861520086864\t 0.6519505196682808\t 0.7626604078287498\t 0.7626604078287498\n",
            "16 \t [ 9.54725085  6.22002983  9.          0.62552666 13.          0.88907022]\t 0.6931760658875753\t 0.6519505196682808\t 0.7615386320829388\t 0.7615386320829388\n",
            "17 \t [ 1.15162056  8.90964142  5.          0.51235759 16.          0.30257234]\t 1.0249769697656812\t 0.6519505196682808\t 0.759496960996068\t 0.759496960996068\n",
            "18 \t [ 1.30104057  1.35048964 13.          0.67123293 19.          0.45258153]\t 0.926403791159036\t 0.6519505196682808\t 0.7621335770778519\t 0.7621335770778519\n",
            "19 \t [ 5.98453698  2.00451687 13.          0.80337068 13.          0.24875337]\t 1.0599380721478096\t 0.6519505196682808\t 0.7630783823760974\t 0.7630783823760974\n",
            "20 \t [ 0.50983823  9.47760419 12.          0.8715015  15.          0.19366175]\t 1.0590044648636237\t 0.6519505196682808\t 0.7658286900162738\t 0.7658286900162738\n",
            "21 \t [ 9.7854777   4.64577671 13.          0.68148977  9.          0.5027445 ]\t 0.828666119399937\t 0.6519505196682808\t 0.7683642777625455\t 0.7683642777625455\n",
            "22 \t [2.10152742 0.13485741 9.         0.52015738 8.         0.10109114]\t 1.0598603820885464\t 0.6519505196682808\t 0.7678432623015755\t 0.7678432623015755\n",
            "23 \t [8.86129003 7.62670792 8.         0.64247921 6.         0.45176657]\t 0.9303098840989937\t 0.6519505196682808\t 0.7700937190277921\t 0.7700937190277921\n",
            "24 \t [ 8.26255513  8.85182409 14.          0.50272259 15.          0.8232042 ]\t 0.7407492625300989\t 0.6519505196682808\t 0.7706484028965296\t 0.7706484028965296\n",
            "25 \t [ 4.56404393  6.30930448 11.          0.76414598  7.          0.97586603]\t 0.6824423798727317\t 0.6519505196682808\t 0.7692598749910449\t 0.7692598749910449\n",
            "26 \t [ 4.48261169 10.          8.08795067  1.         12.08795067  1.        ]\t 0.6666773126915988\t 0.6519505196682808\t 0.7674570102962578\t 0.7674570604400731\n",
            "27 \t [ 0.          3.46874686 11.61261966  0.5        12.61261966  0.1       ]\t 1.0608135867611395\t 0.6519505196682808\t 0.7656728526644948\t 0.7656729515410156\n",
            "28 \t [5.49371241 0.37069041 5.         0.5        6.29145924 0.1       ]\t 1.0640443963809372\t 0.6519505196682808\t 0.7676803280648106\t 0.7676796179367404\n",
            "29 \t [ 9.93142529  1.55453711  5.          0.69644974 13.          0.89571454]\t 0.7435142600117224\t 0.6519505196682808\t 0.769596934078911\t 0.769596934078911\n",
            "30 \t [ 4.46432054  1.37976416 14.          0.91350827  1.          0.70455501]\t 0.786373065109467\t 0.6519505196682808\t 0.768484829614279\t 0.768484829614279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46832.22443034189"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_exact_7 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train7, X_test7, y_train7, y_test7 = train_test_split(X, y, test_size=test_perc, random_state=run_num_7)\n",
        "\n",
        "def f_syn_polarity7(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_7, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train7, y=y_train7).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_7 = dGPGO(surrogate_exact_7, Acquisition_grad(util), f_syn_polarity7, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_7.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_7 = exact_7.getResult()[0]\n",
        "params_exact_7['max_depth'] = int(params_exact_7['max_depth'])\n",
        "params_exact_7['min_child_weight'] = int(params_exact_7['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train7 = xgb.DMatrix(X_train7, y_train7)\n",
        "dX_exact_test7 = xgb.DMatrix(X_test7, y_test7)\n",
        "model_exact_7 = xgb.train(params_exact_7, dX_exact_train7)\n",
        "pred_exact_7 = model_exact_7.predict(dX_exact_test7)\n",
        "\n",
        "rmse_exact_7 = np.sqrt(mean_squared_error(pred_exact_7, y_test7))\n",
        "rmse_exact_7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh0IJf8zNy9E",
        "outputId": "5d59726f-c982-47a7-c3d7-55c146b95bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [0.76308289 7.79918792 8.         0.98911145 8.         0.98019056]\t 0.6599162825175136\t 0.6529031062312245\t    \t    \n",
            "init\t [ 5.3849587   5.01120464 13.          0.74994125  5.          0.88192131]\t 0.6529031062312245\t 0.6529031062312245\t    \t    \n",
            "init\t [ 3.30839249  3.9294231  12.          0.6440728  13.          0.41137564]\t 0.7849988476524127\t 0.6529031062312245\t    \t    \n",
            "init\t [9.29528191 2.6258377  5.         0.80027446 1.         0.86616513]\t 0.7434573966703171\t 0.6529031062312245\t    \t    \n",
            "init\t [ 1.74052764  7.90763512 14.          0.7244129   4.          0.77536887]\t 0.6887936732176462\t 0.6529031062312245\t    \t    \n",
            "1  \t [3.43305102 3.00339076 8.         0.71322679 4.         0.33322219]\t 0.8461730749178773\t 0.6529031062312245\t 0.7211214507322005\t 0.7211214507322005\n",
            "2  \t [ 8.27276329  5.80705371  6.          0.6575149  16.          0.66596626]\t 0.7280339284910606\t 0.6529031062312245\t 0.7277003276934555\t 0.7277003276934555\n",
            "3  \t [ 8.97988092  8.79483413 14.          0.55379557 13.          0.92924117]\t 0.6571137209723783\t 0.6529031062312245\t 0.7275217885714056\t 0.7275217885714056\n",
            "4  \t [ 6.31879092  0.69939064  5.          0.5769645  12.          0.84874959]\t 0.7458231993222018\t 0.6529031062312245\t 0.7251370704301654\t 0.7251370704301654\n",
            "5  \t [ 9.90436619  1.68371673 11.          0.68947817 16.          0.400226  ]\t 0.7838758112536788\t 0.6529031062312245\t 0.7258173449579699\t 0.7258173449579699\n",
            "6  \t [ 2.27614069  9.14855814 13.          0.84138599 18.          0.79014716]\t 0.6787899501779286\t 0.6529031062312245\t 0.7274275823919338\t 0.7274275823919338\n",
            "7  \t [ 0.63761793  0.73483023 14.          0.60715475  1.          0.28353184]\t 0.8531322761504475\t 0.6529031062312245\t 0.7261848717832742\t 0.7261848717832742\n",
            "8  \t [ 1.95327375  0.09413692  7.          0.63967551 19.          0.52105045]\t 0.718715865573951\t 0.6529031062312245\t 0.7292238595169062\t 0.7292238595169062\n",
            "9  \t [5.70513125 8.30861013 6.         0.98680016 3.         0.16134411]\t 0.9984088714580504\t 0.6529031062312245\t 0.7288212195026392\t 0.7288212195026392\n",
            "10 \t [ 0.25030147  5.86047618  7.          0.62148035 15.          0.70956246]\t 0.7144935773647406\t 0.6529031062312245\t 0.7347275061504588\t 0.7347275061504588\n",
            "11 \t [0.         0.         5.         0.5        9.59697039 0.1       ]\t 1.0011007755268673\t 0.6529031062312245\t 0.7339415707544829\t 0.7339415620296479\n",
            "12 \t [9.93412004 7.01728008 6.         0.60790736 8.         0.46475011]\t 0.8183353504315909\t 0.6529031062312245\t 0.7388234301035462\t 0.7388234301035462\n",
            "13 \t [ 9.74185418  1.9812272  14.          0.94068286 10.          0.45784207]\t 0.7792188999132433\t 0.6529031062312245\t 0.7395841965514697\t 0.7395841965514697\n",
            "14 \t [ 5.05369665  2.67147005  5.          0.51290284 10.          0.64085   ]\t 0.7504591409344632\t 0.6529031062312245\t 0.7396337673781982\t 0.7396337673781982\n",
            "15 \t [ 7.27698082  9.82692974 11.          0.6446349   1.          0.67673022]\t 0.6974468561044718\t 0.6529031062312245\t 0.7392600687942308\t 0.7392600687942308\n",
            "\u001b[1m\u001b[92m16\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6415746011828174\u001b[0m\t \u001b[1m\u001b[92m0.6415746011828174\u001b[0m\t \u001b[1m\u001b[92m0.7381455391493964\u001b[0m\t \u001b[1m\u001b[92m0.7381453854947492\u001b[0m\n",
            "17 \t [ 0.08258912  2.04682383 12.          0.59206459 18.          0.58057909]\t 0.6960149194291863\t 0.6415746011828174\t 0.727495359323763\t 0.727495359323763\n",
            "18 \t [ 7.87862448  0.37268652 11.          0.83129981  1.          0.83621209]\t 0.6910349298616485\t 0.6415746011828174\t 0.7266516937961541\t 0.7266516937961541\n",
            "19 \t [ 5.28371353  3.6868484  11.          0.82200641 19.          0.12021404]\t 0.9924220081561828\t 0.6415746011828174\t 0.7258252162272646\t 0.7258252162272646\n",
            "20 \t [0.11642891 2.32089557 5.         0.5        1.         0.1       ]\t 1.0017306771912005\t 0.6415746011828174\t 0.7289468798662946\t 0.7289465540059246\n",
            "21 \t [ 1.02977609  0.66145279  7.          0.5528148  14.          0.97405529]\t 0.6856334744458132\t 0.6415746011828174\t 0.7320107315404738\t 0.7320107315404738\n",
            "22 \t [10.         10.         10.77572849  1.          7.77572849  1.        ]\t 0.6441835090876964\t 0.6415746011828174\t 0.730961658990001\t 0.7309613851276914\n",
            "23 \t [ 4.45475741  9.04863317  5.          0.93353577 13.          0.79638216]\t 0.7447620295741274\t 0.6415746011828174\t 0.7296791674258069\t 0.7296791674258069\n",
            "24 \t [ 4.2776564   9.48283936 11.          0.71877499 12.          0.19591223]\t 0.9919884917700834\t 0.6415746011828174\t 0.7293993737531828\t 0.7293993737531828\n",
            "25 \t [ 9.74156473 10.          8.49226577  1.         19.49226577  1.        ]\t 0.6608287615418145\t 0.6415746011828174\t 0.7318431309912501\t 0.7318417657240542\n",
            "26 \t [ 7.50583035  7.42634963 14.          0.81352069  9.          0.10482848]\t 0.9927806614182308\t 0.6415746011828174\t 0.7308506838711059\t 0.7308506838711059\n",
            "27 \t [9.91546913 0.35662679 7.         0.87706909 8.         0.31009443]\t 0.8520314289074896\t 0.6415746011828174\t 0.7330390673616889\t 0.7330390673616889\n",
            "28 \t [ 9.910572    5.76876265 10.          0.62357248  4.          0.60901783]\t 0.7016274432002019\t 0.6415746011828174\t 0.7336643824101422\t 0.7336643824101422\n",
            "29 \t [ 9.92745389  2.10791379  6.          0.91867901 19.          0.37494465]\t 0.8675172360459502\t 0.6415746011828174\t 0.7330164390033144\t 0.7330164390033144\n",
            "30 \t [1.52216216 8.41306408 5.         0.57743997 1.         0.26594603]\t 0.888278592469768\t 0.6415746011828174\t 0.7337482060524185\t 0.7337482060524185\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49437.90939909842"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0IPTSTbIl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178466cc-f21e-469b-f613-0ddd8e5e01c2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_exact_8 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train8, X_test8, y_train8, y_test8 = train_test_split(X, y, test_size=test_perc, random_state=run_num_8)\n",
        "\n",
        "def f_syn_polarity8(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_8, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train8, y=y_train8).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_8 = dGPGO(surrogate_exact_8, Acquisition_grad(util), f_syn_polarity8, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_8.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_8 = exact_8.getResult()[0]\n",
        "params_exact_8['max_depth'] = int(params_exact_8['max_depth'])\n",
        "params_exact_8['min_child_weight'] = int(params_exact_8['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train8 = xgb.DMatrix(X_train8, y_train8)\n",
        "dX_exact_test8 = xgb.DMatrix(X_test8, y_test8)\n",
        "model_exact_8 = xgb.train(params_exact_8, dX_exact_train8)\n",
        "pred_exact_8 = model_exact_8.predict(dX_exact_test8)\n",
        "\n",
        "rmse_exact_8 = np.sqrt(mean_squared_error(pred_exact_8, y_test8))\n",
        "rmse_exact_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.73429403  9.68540663 10.          0.68875849  9.          0.48011572]\t 0.8097437093843076\t 0.6653168057229354\t    \t    \n",
            "init\t [ 6.12033333  7.66062926  8.          0.76133734 13.          0.93379456]\t 0.676783388491471\t 0.6653168057229354\t    \t    \n",
            "init\t [ 1.46524679  7.01527914  7.          0.90913299 10.          0.36016753]\t 0.8290150461838799\t 0.6653168057229354\t    \t    \n",
            "init\t [ 9.73855241  3.33774046 14.          0.53290419  7.          0.7088681 ]\t 0.704280612172438\t 0.6653168057229354\t    \t    \n",
            "init\t [ 3.00618018  1.82702795 11.          0.75681389 14.          0.98627449]\t 0.6653168057229354\t 0.6653168057229354\t    \t    \n",
            "1  \t [4.42022545 5.48487111 9.         0.97165909 3.         0.63617522]\t 0.6939807861210728\t 0.6653168057229354\t 0.7398208900291442\t 0.7398208900291442\n",
            "2  \t [ 4.42530022  8.86662399 12.          0.55390756 19.          0.26906902]\t 0.8292448989696929\t 0.6653168057229354\t 0.7378301892426625\t 0.7378301892426625\n",
            "3  \t [ 9.08237751  2.49680746  6.          0.65941352 17.          0.68321352]\t 0.7238654894117781\t 0.6653168057229354\t 0.7417057000977814\t 0.7417057000977814\n",
            "4  \t [9.24101391 3.71625162 7.         0.92041359 7.         0.33094108]\t 0.8298868503374536\t 0.6653168057229354\t 0.7409324331191866\t 0.7409324331191866\n",
            "5  \t [ 2.71549468  6.59835463  5.          0.95307649 18.          0.8022723 ]\t 0.7298305735353544\t 0.6653168057229354\t 0.7436166701822383\t 0.7436166701822383\n",
            "6  \t [ 8.42695368  3.16936553 13.          0.82366295 16.          0.76402556]\t 0.6713374162855336\t 0.6653168057229354\t 0.7429638266458657\t 0.7429638266458657\n",
            "7  \t [ 8.83774177  5.41674027 14.          0.73954397  1.          0.31035075]\t 0.8412489648220683\t 0.6653168057229354\t 0.7410913638790863\t 0.7410913638790863\n",
            "8  \t [ 0.45904618  0.31422469 12.          0.85221495  5.          0.31125587]\t 0.8281572228887775\t 0.6653168057229354\t 0.7433754061761333\t 0.7433754061761333\n",
            "9  \t [0.  0.  5.  0.5 1.  0.1]\t 0.9366264008615343\t 0.6653168057229354\t 0.7450028727994088\t 0.7450028721174221\n",
            "10 \t [ 3.96405062  8.0979425  14.          0.59297393  7.          0.94464131]\t 0.6700820921354065\t 0.6653168057229354\t 0.7488348386819997\t 0.7488348386819997\n",
            "11 \t [9.23421894 1.96715525 6.         0.84213684 1.         0.28111445]\t 0.8403741678101049\t 0.6653168057229354\t 0.7470603207184364\t 0.7470603207184364\n",
            "12 \t [ 6.07416022  0.73060636  9.          0.91953118 17.          0.26381452]\t 0.824083830642531\t 0.6653168057229354\t 0.7483749067504644\t 0.7483749067504644\n",
            "13 \t [ 9.08307561  9.73616604  5.          0.74596783 18.          0.23735578]\t 0.9373386140641772\t 0.6653168057229354\t 0.7492492444357752\t 0.7492492444357752\n",
            "14 \t [1.36072521 8.96337054 5.         0.74382165 2.         0.12580076]\t 0.9379435984221122\t 0.6653168057229354\t 0.7519944579429318\t 0.7519944579429318\n",
            "15 \t [ 3.32794564  9.35873285 13.          0.95404271 12.          0.46503428]\t 0.8057168013419183\t 0.6653168057229354\t 0.7544529432684128\t 0.7544529432684128\n",
            "16 \t [2.33197213 0.42967242 6.09258735 0.5        9.09258735 0.1       ]\t 0.9343506859058938\t 0.6653168057229354\t 0.7546234483411778\t 0.7546234477849438\n",
            "17 \t [ 0.09889076  5.63526532 14.          0.81316857 16.          0.71340054]\t 0.6907172665844576\t 0.6653168057229354\t 0.7566594819829929\t 0.7566594819829929\n",
            "18 \t [ 8.81884199  0.29557486 11.          0.94612367  2.          0.80082225]\t 0.6729826219675135\t 0.6653168057229354\t 0.75533318939077\t 0.75533318939077\n",
            "19 \t [ 4.10272358  0.68972827 14.          0.96902802  1.          0.19814279]\t 0.9303071311772037\t 0.6653168057229354\t 0.7539340005242312\t 0.7539340005242312\n",
            "20 \t [ 1.37842187  7.92618907 14.          0.53493538  2.          0.9994541 ]\t 0.6778496323948628\t 0.6653168057229354\t 0.7556905683541296\t 0.7556905683541296\n",
            "\u001b[1m\u001b[92m21\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6454226853941064\u001b[0m\t \u001b[1m\u001b[92m0.6454226853941064\u001b[0m\t \u001b[1m\u001b[92m0.7544342001316343\u001b[0m\t \u001b[1m\u001b[92m0.754434181821303\u001b[0m\n",
            "22 \t [ 0.76637948  1.6718521   5.          0.89180884 15.          0.76035097]\t 0.7285188069721016\t 0.6454226853941064\t 0.7371272190320154\t 0.7371272190320154\n",
            "23 \t [9.0548994  9.22699073 6.         0.81952407 4.         0.89275019]\t 0.7048213880431081\t 0.6454226853941064\t 0.7365176731592068\t 0.7365176731592068\n",
            "24 \t [10.          8.56861346 13.47475269  1.          5.47475269  1.        ]\t 0.6476990255198642\t 0.6454226853941064\t 0.7357314966282095\t 0.7357313392905401\n",
            "25 \t [ 2.00363843  0.25557305 13.          0.79852696 19.          0.41982126]\t 0.8045050796386125\t 0.6454226853941064\t 0.7345148463910924\t 0.7345148463910924\n",
            "26 \t [ 6.68035886  0.          7.75331745  0.5        11.75331745  0.1       ]\t 0.9312962436711476\t 0.6454226853941064\t 0.7347563290646847\t 0.7347558335295361\n",
            "27 \t [ 7.15040543  9.72926644 14.          0.63776297 15.          0.43073814]\t 0.8100270760776773\t 0.6454226853941064\t 0.7362712435481392\t 0.7362712435481392\n",
            "28 \t [ 1.06330602  9.84698732  5.          0.70744161 15.          0.6986094 ]\t 0.7398934603464837\t 0.6454226853941064\t 0.7364934120019908\t 0.7364934120019908\n",
            "29 \t [ 0.38981625  6.83918631 12.          0.9186103   9.          0.83633941]\t 0.6681678750308067\t 0.6454226853941064\t 0.7361053919129639\t 0.7361053919129639\n",
            "30 \t [ 8.97540851  6.2085367  10.          0.89346932  4.          0.59994665]\t 0.7097725578226902\t 0.6454226853941064\t 0.7352010343041033\t 0.7352010343041033\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51081.55924427656"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UroEj_RbLSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899abc82-9a89-4634-a5d3-9cf9b5be85a9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_exact_9 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train9, X_test9, y_train9, y_test9 = train_test_split(X, y, test_size=test_perc, random_state=run_num_9)\n",
        "\n",
        "def f_syn_polarity9(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_9, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train9, y=y_train9).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_9 = dGPGO(surrogate_exact_9, Acquisition_grad(util), f_syn_polarity9, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_9.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_9 = exact_9.getResult()[0]\n",
        "params_exact_9['max_depth'] = int(params_exact_9['max_depth'])\n",
        "params_exact_9['min_child_weight'] = int(params_exact_9['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train9 = xgb.DMatrix(X_train9, y_train9)\n",
        "dX_exact_test9 = xgb.DMatrix(X_test9, y_test9)\n",
        "model_exact_9 = xgb.train(params_exact_9, dX_exact_train9)\n",
        "pred_exact_9 = model_exact_9.predict(dX_exact_test9)\n",
        "\n",
        "rmse_exact_9 = np.sqrt(mean_squared_error(pred_exact_9, y_test9))\n",
        "rmse_exact_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.10374154  5.01874592 11.          0.50377155  2.          0.29670281]\t 0.8449026536729003\t 0.6448358819228919\t    \t    \n",
            "init\t [ 4.18508181  2.48101168 13.          0.69794293  2.          0.25009871]\t 0.8430936233516066\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.78559086  9.50964032 13.          0.98395204 11.          0.90820641]\t 0.6448358819228919\t 0.6448358819228919\t    \t    \n",
            "init\t [ 6.66898973  5.47837783  6.          0.97165345 12.          0.72499481]\t 0.7455250925664565\t 0.6448358819228919\t    \t    \n",
            "init\t [ 8.24870465  4.65668475 13.          0.68760467  9.          0.98502332]\t 0.6542440322310401\t 0.6448358819228919\t    \t    \n",
            "1  \t [6.73714319 2.39608167 5.         0.58130302 3.         0.163077  ]\t 1.0516333409565926\t 0.6448358819228919\t 0.7263090534109926\t 0.7263090534109926\n",
            "2  \t [9.23885705 0.0495141  9.         0.5847098  7.         0.79832927]\t 0.6774051522557019\t 0.6448358819228919\t 0.742686185833593\t 0.742686185833593\n",
            "3  \t [ 3.67545472  4.78145311 14.          0.63123486 17.          0.4863889 ]\t 0.7930932442681178\t 0.6448358819228919\t 0.7376383541421366\t 0.7376383541421366\n",
            "4  \t [ 0.19525707  9.62416422  9.          0.85280832 10.          0.52998476]\t 0.7396199848029671\t 0.6448358819228919\t 0.7376830480463931\t 0.7376830480463931\n",
            "5  \t [ 1.86381009  9.16177979  5.          0.9344438  17.          0.81379931]\t 0.7377720407232845\t 0.6448358819228919\t 0.7360693893552984\t 0.7360693893552984\n",
            "6  \t [ 2.35563756  1.41309797  5.          0.61127581 14.          0.85229383]\t 0.7381603779527465\t 0.6448358819228919\t 0.7347261153508796\t 0.7347261153508796\n",
            "7  \t [ 0.65024006  0.20015298 14.          0.90298726 13.          0.95798937]\t 0.6479585144859159\t 0.6448358819228919\t 0.7336346569508181\t 0.7336346569508181\n",
            "8  \t [ 9.89935012  1.80411649  9.          0.642097   16.          0.9768379 ]\t 0.6624923928604278\t 0.6448358819228919\t 0.7308238750412718\t 0.7308238750412718\n",
            "9  \t [ 0.30581668  9.33751049 12.          0.80943195 19.          0.44519139]\t 0.788150408197674\t 0.6448358819228919\t 0.7287053521988817\t 0.7287053521988817\n",
            "10 \t [0.  0.  5.  0.5 1.  0.1]\t 1.0517934452387856\t 0.6448358819228919\t 0.7292707885380583\t 0.7292707885380582\n",
            "11 \t [ 7.69830016  7.83404591 13.          0.63442501  2.          0.36725242]\t 0.842436384626135\t 0.6448358819228919\t 0.7356496766452455\t 0.7356496766452455\n",
            "12 \t [ 9.81919535 10.         15.          1.         20.          1.        ]\t 0.6505488040189036\t 0.6448358819228919\t 0.7367104335704207\t 0.7367104335704203\n",
            "13 \t [1.75561603 6.13376087 5.         0.74047005 6.         0.77032586]\t 0.7376272669813917\t 0.6448358819228919\t 0.7345910802589795\t 0.7345910802589795\n",
            "14 \t [10.          4.54646916 14.31215568  1.         20.          1.        ]\t 0.6504440529764126\t 0.6448358819228919\t 0.7339236997940266\t 0.7339236919696411\n",
            "15 \t [9.88943457 8.53804591 8.         0.65243257 7.         0.28069664]\t 0.8352977818443392\t 0.6448358819228919\t 0.7321662186790324\t 0.7321662186790324\n",
            "16 \t [ 3.66353781  7.3371628  13.          0.91928424 11.          0.42437688]\t 0.78680708804053\t 0.6448358819228919\t 0.7330845517189866\t 0.7330845517189866\n",
            "17 \t [ 7.81834149  9.72965303  8.          0.64259089 17.          0.22077726]\t 1.0465197239444557\t 0.6448358819228919\t 0.7332331863771898\t 0.7332331863771898\n",
            "18 \t [ 9.00084206  1.85673124 10.          0.98011614  2.          0.25530052]\t 0.83279328574821\t 0.6448358819228919\t 0.7372947807829737\t 0.7372947807829737\n",
            "19 \t [3.71364107 1.34189013 8.         0.86771065 9.         0.8854455 ]\t 0.6658411506285626\t 0.6448358819228919\t 0.7378327718759748\t 0.7378327718759748\n",
            "20 \t [ 4.49089064  7.04035213 10.          0.71518167  6.          0.54341653]\t 0.7431428744858811\t 0.6448358819228919\t 0.736439834358907\t 0.736439834358907\n",
            "21 \t [ 4.2953213   0.27911896 10.          0.9783586  19.          0.46300401]\t 0.7860315206098012\t 0.6448358819228919\t 0.7359459822194901\t 0.7359459822194901\n",
            "22 \t [ 6.00011977  5.16081767  6.          0.83034316 19.          0.20760473]\t 1.0484753830587141\t 0.6448358819228919\t 0.7359471942130552\t 0.7359471942130552\n",
            "23 \t [ 0.79581704  0.44548953 10.          0.5535323   5.          0.9139619 ]\t 0.6649440013666069\t 0.6448358819228919\t 0.7391729123944957\t 0.7391729123944957\n",
            "24 \t [ 3.74834789  9.93946975 10.          0.52571565  1.          0.6614516 ]\t 0.7187682581856685\t 0.6448358819228919\t 0.73792592057033\t 0.73792592057033\n",
            "25 \t [ 0.          6.85748987  5.          0.5        12.4319919   0.1       ]\t 1.0518144393328384\t 0.6448358819228919\t 0.7372276472084754\t 0.7372276470348167\n",
            "26 \t [ 0.34910818  3.39479926 12.          0.75007153 14.          0.74419655]\t 0.6950503015339501\t 0.6448358819228919\t 0.7401256225908013\t 0.7401256225908013\n",
            "27 \t [ 0.45983101  9.28402862 13.          0.52786561  6.          0.42783681]\t 0.8036069849990609\t 0.6448358819228919\t 0.7392078285134488\t 0.7392079515637153\n",
            "28 \t [ 7.48807874  5.11462429 12.          0.72630446 14.          0.28208232]\t 0.834870831846418\t 0.6448358819228919\t 0.7392653096410808\t 0.7392653096410808\n",
            "29 \t [5.63583903 8.76359675 5.         0.6782879  2.         0.67940326]\t 0.7762477426066001\t 0.6448358819228919\t 0.7395973815200046\t 0.7395973815200046\n",
            "30 \t [0.08953745 2.39034843 5.         0.83307491 9.         0.67986073]\t 0.775958523251524\t 0.6448358819228919\t 0.7394112791274119\t 0.7394112791274119\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48075.00995818073"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VgaJOoJbOIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6da80f-9279-49c4-9f7f-f02abe7d067e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_exact_10 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=test_perc, random_state=run_num_10)\n",
        "\n",
        "def f_syn_polarity10(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_10, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train10, y=y_train10).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_10 = dGPGO(surrogate_exact_10, Acquisition_grad(util), f_syn_polarity10, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_10.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_10 = exact_10.getResult()[0]\n",
        "params_exact_10['max_depth'] = int(params_exact_10['max_depth'])\n",
        "params_exact_10['min_child_weight'] = int(params_exact_10['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train10 = xgb.DMatrix(X_train10, y_train10)\n",
        "dX_exact_test10 = xgb.DMatrix(X_test10, y_test10)\n",
        "model_exact_10 = xgb.train(params_exact_10, dX_exact_train10)\n",
        "pred_exact_10 = model_exact_10.predict(dX_exact_test10)\n",
        "\n",
        "rmse_exact_10 = np.sqrt(mean_squared_error(pred_exact_10, y_test10))\n",
        "rmse_exact_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.71320643  0.20751949  5.          0.72150747 17.          0.12265456]\t 0.8785010703819621\t 0.6669292375133978\t    \t    \n",
            "init\t [ 7.0920801   2.65566127 13.          0.57518893 17.          0.83494165]\t 0.6669292375133978\t 0.6669292375133978\t    \t    \n",
            "init\t [ 3.36071584  8.90816531  6.          0.86087766 15.          0.75469196]\t 0.7012460140601039\t 0.6669292375133978\t    \t    \n",
            "init\t [ 5.40880931  1.31458152  8.          0.57108502 14.          0.62551123]\t 0.7005965853529538\t 0.6669292375133978\t    \t    \n",
            "init\t [1.82631436 8.26082248 6.         0.80888349 5.         0.15900694]\t 0.880412005930048\t 0.6669292375133978\t    \t    \n",
            "1  \t [8.31989768 3.09778055 7.         0.64798085 3.         0.98471878]\t 0.6770142260932797\t 0.6669292375133978\t 0.7495260602026695\t 0.7495260602026695\n",
            "2  \t [ 3.05837423  0.98670899 11.          0.63714741 18.          0.46809298]\t 0.7417959722875219\t 0.6669292375133978\t 0.7454679568537242\t 0.7454679568537242\n",
            "3  \t [1.0517383  0.29626986 6.         0.71496305 2.         0.21703638]\t 0.8792946548244501\t 0.6669292375133978\t 0.7449099712401652\t 0.7449099712401652\n",
            "4  \t [ 2.98946783  8.70916918 12.          0.89809007  8.          0.53350402]\t 0.7006385046040607\t 0.6669292375133978\t 0.7494639804046281\t 0.7494639804046281\n",
            "5  \t [ 2.36407072  4.99081503 14.          0.6287111   1.          0.46714602]\t 0.7578758817373941\t 0.6669292375133978\t 0.7474127169463525\t 0.7474127169463525\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6455928988859453\u001b[0m\t \u001b[1m\u001b[92m0.6455928988859453\u001b[0m\t \u001b[1m\u001b[92m0.7472590006732353\u001b[0m\t \u001b[1m\u001b[92m0.7472590006732353\u001b[0m\n",
            "7  \t [8.82521763 9.96779345 8.         0.82356907 1.         0.3598298 ]\t 0.8142907394883079\t 0.6455928988859453\t 0.7273282030820657\t 0.7273282030820657\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[10.          6.82833847 12.78031813  1.         10.78031813  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6423941455356202\u001b[0m\t \u001b[1m\u001b[92m0.6423941455356202\u001b[0m\t \u001b[1m\u001b[92m0.7287937878113857\u001b[0m\t \u001b[1m\u001b[92m0.7287937878113846\u001b[0m\n",
            "9  \t [7.7714375  7.70616843 8.         0.82339468 6.         0.96195202]\t 0.661096368919013\t 0.6423941455356202\t 0.7239288920725967\t 0.7239288920725967\n",
            "10 \t [ 5.70210615  2.89189731 13.          0.5015275   7.          0.96850007]\t 0.6575972890849957\t 0.6423941455356202\t 0.7222743954485168\t 0.7222743954485168\n",
            "11 \t [ 8.19358468  0.09406813 12.          0.66286753  2.          0.39315916]\t 0.7497583304473998\t 0.6423941455356202\t 0.7207808494113833\t 0.7207808494113833\n",
            "12 \t [ 2.40528406  7.71427622 14.          0.55203588 14.          0.3470708 ]\t 0.8154596077767258\t 0.6423941455356202\t 0.7209725769818964\t 0.7209725769818964\n",
            "13 \t [ 1.32528066  5.17118506  5.          0.79204954 19.          0.27904411]\t 0.823119322181516\t 0.6423941455356202\t 0.7222590955431266\t 0.7222590955431266\n",
            "14 \t [ 0.2734411   0.20947276 13.          0.89386904  7.          0.27558279]\t 0.8166474442456968\t 0.6423941455356202\t 0.723530578048895\t 0.723530578048895\n",
            "15 \t [ 9.72703693  6.521415    7.          0.50173837 17.          0.28475777]\t 0.815168593089996\t 0.6423941455356202\t 0.7245631323905461\t 0.7245631323905461\n",
            "16 \t [ 0.          3.01903071  5.          0.5        13.3889492   0.1       ]\t 0.8811984456086404\t 0.6423941455356202\t 0.7254690546618722\t 0.7254690454378246\n",
            "17 \t [6.92866065 2.77225974 6.         0.63542927 8.         0.57662602]\t 0.731298844964982\t 0.6423941455356202\t 0.7272670832999116\t 0.7272670832999116\n",
            "18 \t [1.01278048 1.49532978 8.         0.60722177 9.         0.41545971]\t 0.7438692283338254\t 0.6423941455356202\t 0.7268836933391823\t 0.7268836933391823\n",
            "19 \t [ 3.80090214  9.80981443 12.          0.76771143  3.          0.20106055]\t 0.8840643207380687\t 0.6423941455356202\t 0.7266815256534922\t 0.7266815256534922\n",
            "20 \t [ 7.12926775  9.03696584  8.          0.73918055 12.          0.81903935]\t 0.6743512965414473\t 0.6423941455356202\t 0.7282405666333396\t 0.7282405666333396\n",
            "21 \t [ 9.5000898   1.2315106   8.67283213  1.         19.67283213  1.        ]\t 0.6630069062130752\t 0.6423941455356202\t 0.7272767577450259\t 0.7272762663455222\n",
            "22 \t [ 9.93589724  2.50925722 10.          0.73371299 12.          0.27380248]\t 0.812578165094133\t 0.6423941455356202\t 0.7262802695684253\t 0.7262802695684253\n",
            "23 \t [4.76122383 5.37906206 8.         0.72454772 2.         0.37435491]\t 0.8130617229633597\t 0.6423941455356202\t 0.7268577637701659\t 0.7268577637701659\n",
            "24 \t [ 9.44884228  8.24267271 13.          0.85613128  4.          0.70957676]\t 0.6921719352970419\t 0.6423941455356202\t 0.7273987554990667\t 0.7273987554990667\n",
            "25 \t [ 2.93488039  1.42589705 12.          0.53662532 11.          0.95990351]\t 0.6602204402618361\t 0.6423941455356202\t 0.7267503128490936\t 0.7267503128490936\n",
            "26 \t [10.          3.27333075 10.02133042  1.          7.02133042  1.        ]\t 0.6455741517229614\t 0.6423941455356202\t 0.7258807845625651\t 0.7258804502878797\n",
            "27 \t [0.73638155 5.44724197 9.         0.90159859 3.         0.84981348]\t 0.6619468807381774\t 0.6423941455356202\t 0.7249527747812003\t 0.7249527747812003\n",
            "28 \t [ 1.55481231  8.89847306 13.          0.92315868 19.          0.23858876]\t 0.8822650514974324\t 0.6423941455356202\t 0.7242052474824682\t 0.7242052474824682\n",
            "29 \t [ 8.76678657  9.19944202 14.          0.60876221 15.          0.44634556]\t 0.7435438417331935\t 0.6423941455356202\t 0.7253999354589648\t 0.7253999354589648\n",
            "30 \t [ 4.68397379  5.85846222 11.          0.95732914 19.          0.77262296]\t 0.6559247880969465\t 0.6423941455356202\t 0.7253041964196167\t 0.7253041964196167\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50424.27457116489"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51z87uHWbRGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6350cb96-2e1e-46c8-9efe-e5ef162d0eea"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_exact_11 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=test_perc, random_state=run_num_11)\n",
        "\n",
        "def f_syn_polarity11(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_11, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train11, y=y_train11).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_11 = dGPGO(surrogate_exact_11, Acquisition_grad(util), f_syn_polarity11, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_11.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_11 = exact_11.getResult()[0]\n",
        "params_exact_11['max_depth'] = int(params_exact_11['max_depth'])\n",
        "params_exact_11['min_child_weight'] = int(params_exact_11['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train11 = xgb.DMatrix(X_train11, y_train11)\n",
        "dX_exact_test11 = xgb.DMatrix(X_test11, y_test11)\n",
        "model_exact_11 = xgb.train(params_exact_11, dX_exact_train11)\n",
        "pred_exact_11 = model_exact_11.predict(dX_exact_test11)\n",
        "\n",
        "rmse_exact_11 = np.sqrt(mean_squared_error(pred_exact_11, y_test11))\n",
        "rmse_exact_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 1.80269689  0.19475241  6.          0.59705781 13.          0.47818324]\t 0.7904007286371394\t 0.6894069737354023\t    \t    \n",
            "init\t [ 4.85427098  0.12780815  5.          0.91309068 14.          0.86571558]\t 0.727634308123781\t 0.6894069737354023\t    \t    \n",
            "init\t [ 7.2996447   1.08736072 10.          0.92857712 18.          0.66910061]\t 0.6894069737354023\t 0.6894069737354023\t    \t    \n",
            "init\t [ 0.20483613  1.16737269  7.          0.57895615 16.          0.83644782]\t 0.7071657410132528\t 0.6894069737354023\t    \t    \n",
            "init\t [ 3.44624491  3.18798797 14.          0.54197657 15.          0.63958906]\t 0.7012825433030343\t 0.6894069737354023\t    \t    \n",
            "1  \t [9.77136617 6.6548802  7.         0.51036649 9.         0.81011527]\t 0.711031226877882\t 0.6894069737354023\t 0.7552688600895634\t 0.7552688600895634\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 0.59719728  4.15307516 11.          0.66501717  3.          0.95537014]\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.6577294425265764\u001b[0m\t \u001b[1m\u001b[92m0.7547506288111829\u001b[0m\t \u001b[1m\u001b[92m0.7547506288111829\u001b[0m\n",
            "3  \t [ 8.79191945  9.92354379  5.          0.67714371 18.          0.57050675]\t 0.7648729702018928\t 0.6577294425265764\t 0.7263344336194053\t 0.7263344336194053\n",
            "\u001b[1m\u001b[92m4\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6379114105099666\u001b[0m\t \u001b[1m\u001b[92m0.6379114105099666\u001b[0m\t \u001b[1m\u001b[92m0.7280976224606197\u001b[0m\t \u001b[1m\u001b[92m0.7280976224606086\u001b[0m\n",
            "5  \t [7.03281588 0.17283378 7.         0.53134171 3.         0.14005229]\t 0.927452827681251\t 0.6379114105099666\t 0.7096230146924167\t 0.7096230146924167\n",
            "6  \t [0.  0.  5.  0.5 1.  0.1]\t 0.9342890171193261\t 0.6379114105099666\t 0.7162582463153117\t 0.7162582463138073\n",
            "7  \t [8.5599695  9.54840342 6.         0.73281277 1.         0.77796226]\t 0.7154523071123053\t 0.6379114105099666\t 0.7218615003009304\t 0.7218615003009304\n",
            "8  \t [0.50746251 9.37264814 7.         0.59739834 4.         0.27068294]\t 0.8761103353410163\t 0.6379114105099666\t 0.7210251196892467\t 0.7210251196892467\n",
            "9  \t [ 6.70158594  1.29808428 14.          0.54548631  6.          0.76418845]\t 0.7033137465922826\t 0.6379114105099666\t 0.7238163085731514\t 0.7238163085731514\n",
            "10 \t [ 1.06054513  2.23745512 13.          0.92745502  9.          0.16992758]\t 0.9226798533243917\t 0.6379114105099666\t 0.722734712025936\t 0.722734712025936\n",
            "11 \t [ 5.26148142  9.71156146 14.          0.80026853  5.          0.11247715]\t 0.9235696907711354\t 0.6379114105099666\t 0.7260621932093797\t 0.7260621932093797\n",
            "12 \t [ 2.18652234  8.71428718  7.          0.98794276 11.          0.73168038]\t 0.6996596737272911\t 0.6379114105099666\t 0.7290338913317096\t 0.7290338913317096\n",
            "13 \t [ 3.07772231  9.36080815 12.          0.63816578 18.          0.13286747]\t 0.9234149203761113\t 0.6379114105099666\t 0.7277862898503002\t 0.7277862898503002\n",
            "14 \t [ 9.70476982  6.87514727  9.28360764  1.         15.28360764  0.8679986 ]\t 0.6548106623520855\t 0.6379114105099666\t 0.7302773163366513\t 0.7302772785377242\n",
            "15 \t [9.60860975 1.04640388 6.         0.96693807 8.         0.36470327]\t 0.8776279327315801\t 0.6379114105099666\t 0.7284686243186478\t 0.7284686243186478\n",
            "16 \t [ 8.16281368  3.58969423 13.          0.69582692 11.          0.52807397]\t 0.7303655873769592\t 0.6379114105099666\t 0.7299633513725657\t 0.7299633513725657\n",
            "17 \t [0.         4.42437534 5.         0.5        4.80822651 0.1       ]\t 0.9342633132533453\t 0.6379114105099666\t 0.729253275711893\t 0.729253417355666\n",
            "18 \t [ 2.10994823  7.1805032  12.          0.63048792  8.          0.67645363]\t 0.698358780864823\t 0.6379114105099666\t 0.7314656646741138\t 0.7314656646741138\n",
            "19 \t [10.        10.        15.         1.        12.3185663  1.       ]\t 0.640266511193503\t 0.6379114105099666\t 0.7303530819951499\t 0.7303529842145441\n",
            "20 \t [ 8.92025472  3.39772915 11.          0.77558517  1.          0.25503081]\t 0.8800927943410877\t 0.6379114105099666\t 0.7287749764459072\t 0.7287749764459072\n",
            "21 \t [ 4.04003571  9.43113029  7.          0.803738   15.          0.73816205]\t 0.7065721753837764\t 0.6379114105099666\t 0.7300246792567616\t 0.7300246792567616\n",
            "22 \t [5.15068265 4.76861601 5.         0.70076898 1.         0.87159533]\t 0.7286740032592812\t 0.6379114105099666\t 0.7292086434332201\t 0.7292086434332201\n",
            "23 \t [ 5.01044511  4.72437488  8.          0.94961982 14.          0.18319652]\t 0.9219210145845608\t 0.6379114105099666\t 0.7286673194971501\t 0.7286673194971501\n",
            "24 \t [5.96609946 8.58923382 8.         0.83624418 7.         0.41971406]\t 0.7695460798342351\t 0.6379114105099666\t 0.7302479546239566\t 0.7302479546239566\n",
            "25 \t [ 4.5602956   9.57663627 15.          1.         13.00829933  1.        ]\t 0.639175672903094\t 0.6379114105099666\t 0.7300642682304969\t 0.7300643951327963\n",
            "26 \t [2.07990351 0.         8.48223448 0.5        5.48223448 0.1       ]\t 0.9262931386173333\t 0.6379114105099666\t 0.7288027109446781\t 0.7288026854142463\n",
            "27 \t [4.59044759 3.75959658 6.         0.60375475 8.         0.93125794]\t 0.6940904466889954\t 0.6379114105099666\t 0.7302770192679192\t 0.7302772910745305\n",
            "28 \t [10.          6.90687537 12.37439723  1.          4.37439723  1.        ]\t 0.6400518059608096\t 0.6379114105099666\t 0.7295025239054237\t 0.7295020611705646\n",
            "29 \t [ 0.62309677  5.3989738   9.65819017  0.5        18.65819017  0.1       ]\t 0.9254445909731853\t 0.6379114105099666\t 0.7283780184390015\t 0.7283787708387424\n",
            "\u001b[1m\u001b[92m30\u001b[0m\t \u001b[1m\u001b[92m[10.          2.87090155 13.93459101  1.         18.93459101  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6365249540099869\u001b[0m\t \u001b[1m\u001b[92m0.6365249540099869\u001b[0m\t \u001b[1m\u001b[92m0.7297231455807683\u001b[0m\t \u001b[1m\u001b[92m0.7297223723200995\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50193.270557767486"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jZUeoWbTvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fba4b6-4ec8-4e51-ef9e-c40fe7634aa0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_exact_12 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train12, X_test12, y_train12, y_test12 = train_test_split(X, y, test_size=test_perc, random_state=run_num_12)\n",
        "\n",
        "def f_syn_polarity12(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_12, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train12, y=y_train12).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_12 = dGPGO(surrogate_exact_12, Acquisition_grad(util), f_syn_polarity12, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_12.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_12 = exact_12.getResult()[0]\n",
        "params_exact_12['max_depth'] = int(params_exact_12['max_depth'])\n",
        "params_exact_12['min_child_weight'] = int(params_exact_12['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train12 = xgb.DMatrix(X_train12, y_train12)\n",
        "dX_exact_test12 = xgb.DMatrix(X_test12, y_test12)\n",
        "model_exact_12 = xgb.train(params_exact_12, dX_exact_train12)\n",
        "pred_exact_12 = model_exact_12.predict(dX_exact_test12)\n",
        "\n",
        "rmse_exact_12 = np.sqrt(mean_squared_error(pred_exact_12, y_test12))\n",
        "rmse_exact_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [1.54162842 7.40049697 6.         0.54321714 4.         0.11311747]\t 0.9314271055202143\t 0.7056203424268611\t    \t    \n",
            "init\t [ 9.18747008  9.00714854 14.          0.97847467 11.          0.35544552]\t 0.7910532936167305\t 0.7056203424268611\t    \t    \n",
            "init\t [ 6.06083184  9.44225136 14.          0.95626942  5.          0.56910342]\t 0.7196830962696428\t 0.7056203424268611\t    \t    \n",
            "init\t [ 5.52037633  4.85377414  7.          0.97886436 17.          0.78810441]\t 0.7056203424268611\t 0.7056203424268611\t    \t    \n",
            "init\t [ 0.20809798  1.35210178  5.          0.65494879 16.          0.36062811]\t 0.8082458628311272\t 0.7056203424268611\t    \t    \n",
            "1  \t [9.46555822 8.57190559 5.         0.50164398 5.         0.71992807]\t 0.74699493326549\t 0.7056203424268611\t 0.7873758687496245\t 0.7873758687496245\n",
            "2  \t [ 7.57473716  9.63637997 12.          0.83444517 10.          0.18761713]\t 0.9247498596892157\t 0.7056203424268611\t 0.785273174596175\t 0.785273174596175\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[ 9.04517621  0.80881017 13.          0.96890904  5.          0.75400021]\u001b[0m\t \u001b[1m\u001b[92m0.6897808103544698\u001b[0m\t \u001b[1m\u001b[92m0.6897808103544698\u001b[0m\t \u001b[1m\u001b[92m0.7903317170850199\u001b[0m\t \u001b[1m\u001b[92m0.7903317170850199\u001b[0m\n",
            "4  \t [ 2.73241117  0.55778587 14.          0.70282167 15.          0.8966204 ]\t 0.6967406870158588\t 0.6897808103544698\t 0.7738117087893788\t 0.7738117087893788\n",
            "5  \t [ 6.66970674  0.03985694  6.          0.76922453 11.          0.18327615]\t 0.9302409127927834\t 0.6897808103544698\t 0.7710739857348229\t 0.7710739857348229\n",
            "\u001b[1m\u001b[92m6\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.650360917790661\u001b[0m\t \u001b[1m\u001b[92m0.650360917790661\u001b[0m\t \u001b[1m\u001b[92m0.7754367581482423\u001b[0m\t \u001b[1m\u001b[92m0.7754367581482381\u001b[0m\n",
            "7  \t [6.03751892 2.08855857 8.         0.88966175 1.         0.6215545 ]\t 0.7281697139284056\t 0.650360917790661\t 0.7404212154799464\t 0.7404212154799464\n",
            "8  \t [ 0.69702541  0.81349796 11.          0.61926511  9.          0.96325174]\t 0.6991946591759919\t 0.650360917790661\t 0.7391000443848529\t 0.7391000443848529\n",
            "9  \t [ 0.26677628  7.38508333 11.          0.74442526 10.          0.50156861]\t 0.7231228799921189\t 0.650360917790661\t 0.7374047605841728\t 0.7374047605841728\n",
            "10 \t [ 9.20470536  7.96480391  5.          0.84400217 12.          0.74025549]\t 0.7417877006073502\t 0.650360917790661\t 0.7363891809439899\t 0.7363891809439899\n",
            "11 \t [ 3.24107348  8.27034509 14.          0.92485614 16.          0.53812048]\t 0.7151360298031719\t 0.650360917790661\t 0.735838488675253\t 0.735838488675253\n",
            "12 \t [ 7.55307662  2.76896497 12.          0.93049335 17.          0.33736097]\t 0.7889723938717788\t 0.650360917790661\t 0.7349157855694748\t 0.7349157855694748\n",
            "13 \t [0.  0.  5.  0.5 1.  0.1]\t 0.9380339511614821\t 0.650360917790661\t 0.7352872209305373\t 0.7352872189318657\n",
            "14 \t [ 0.609825    8.87388875 14.          0.9069446   2.          0.82580346]\t 0.6998436682886817\t 0.650360917790661\t 0.7382069007841486\t 0.7382069007841486\n",
            "15 \t [ 1.10490837  9.58829464  6.          0.57860445 19.          0.21544386]\t 0.9310123715662361\t 0.650360917790661\t 0.7371017214900645\t 0.7371017214900645\n",
            "16 \t [ 9.50979811  3.16002382 14.          0.62948949 10.          0.39138316]\t 0.775390231089039\t 0.650360917790661\t 0.7395147048736069\t 0.7395147048736069\n",
            "17 \t [ 1.47655761  4.14824232  6.          0.97264194 10.          0.22160708]\t 0.9298877500180929\t 0.650360917790661\t 0.7394127528559896\t 0.7394127528559896\n",
            "18 \t [2.77785403 0.21862029 6.74258279 0.5        5.74258279 0.1       ]\t 0.9342097665992734\t 0.650360917790661\t 0.7414779646804509\t 0.7414764638875445\n",
            "19 \t [ 1.74255675  3.47348189 11.          0.60154784  2.          0.22665444]\t 0.9289460793586116\t 0.650360917790661\t 0.7434211239040248\t 0.7434211239040248\n",
            "20 \t [ 9.98175567  0.8705802   6.          0.55210219 18.          0.50471737]\t 0.7496479603542527\t 0.650360917790661\t 0.7453130916901263\t 0.7453130916901263\n",
            "21 \t [10.         7.477239   6.3348679  1.        18.3348679  1.       ]\t 0.6992390267252068\t 0.650360917790661\t 0.7445345515228194\t 0.7445332189061034\n",
            "22 \t [ 5.01443247  3.68495371 11.          0.58485608 11.          0.61144892]\t 0.7278483386007244\t 0.650360917790661\t 0.7434858976540166\t 0.7434858976540166\n",
            "23 \t [ 6.20631594  5.92000035 15.          1.         19.6213094   1.        ]\t 0.6503610108659376\t 0.650360917790661\t 0.7427844281557943\t 0.7427841925855111\n",
            "24 \t [5.91771985 4.67090504 5.         0.91087571 6.         0.28115393]\t 0.8078599705488291\t 0.650360917790661\t 0.7414476059717315\t 0.7414476059717315\n",
            "25 \t [ 6.31549168  8.67520254 10.27389942  1.         19.15140286  1.        ]\t 0.6540297828187236\t 0.650360917790661\t 0.7416263390078538\t 0.7416260428891663\n",
            "26 \t [8.97886962 5.1990592  8.         0.6115526  3.         0.92989751]\t 0.7062171777812216\t 0.650360917790661\t 0.7405985461810871\t 0.7405985461810871\n",
            "27 \t [ 0.35496199  2.82245133 11.          0.77608605 18.          0.90361157]\t 0.6964152543036155\t 0.650360917790661\t 0.7397485758938301\t 0.7397485758938301\n",
            "28 \t [ 3.44114894  8.80200355  5.          0.62088337 10.          0.23056389]\t 0.9335373729789016\t 0.650360917790661\t 0.7391641099588219\t 0.7391641099588219\n",
            "29 \t [ 9.44529298  9.93219913 14.          0.55083831  1.          0.19022129]\t 0.9288333446073491\t 0.650360917790661\t 0.7405870200312196\t 0.7405870200312196\n",
            "30 \t [9.65010963 4.87106089 7.50917222 1.         8.50917222 1.        ]\t 0.679592595267815\t 0.650360917790661\t 0.741739420087609\t 0.7417396059543793\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49876.69652464331"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snTrqE2RbWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d577eda-88da-4206-8d69-efe09cd2a942"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_exact_13 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train13, X_test13, y_train13, y_test13 = train_test_split(X, y, test_size=test_perc, random_state=run_num_13)\n",
        "\n",
        "def f_syn_polarity13(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_13, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train13, y=y_train13).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_13 = dGPGO(surrogate_exact_13, Acquisition_grad(util), f_syn_polarity13, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_13.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_13 = exact_13.getResult()[0]\n",
        "params_exact_13['max_depth'] = int(params_exact_13['max_depth'])\n",
        "params_exact_13['min_child_weight'] = int(params_exact_13['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train13 = xgb.DMatrix(X_train13, y_train13)\n",
        "dX_exact_test13 = xgb.DMatrix(X_test13, y_test13)\n",
        "model_exact_13 = xgb.train(params_exact_13, dX_exact_train13)\n",
        "pred_exact_13 = model_exact_13.predict(dX_exact_test13)\n",
        "\n",
        "rmse_exact_13 = np.sqrt(mean_squared_error(pred_exact_13, y_test13))\n",
        "rmse_exact_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 7.77702411  2.3754122  11.          0.94649135 13.          0.7827256 ]\t 0.6628876451121497\t 0.6628876451121497\t    \t    \n",
            "init\t [ 7.51661514  6.07343344 11.          0.69402149 11.          0.13153287]\t 1.1013657958154304\t 0.6628876451121497\t    \t    \n",
            "init\t [ 2.98449471  0.58512492 10.          0.73579614 12.          0.33065195]\t 0.92150734169971\t 0.6628876451121497\t    \t    \n",
            "init\t [ 3.47581215  0.0941277  11.          0.86143432  8.          0.58454932]\t 0.71924819784624\t 0.6628876451121497\t    \t    \n",
            "init\t [ 4.70137857  6.24432527 10.          0.8149145  18.          0.10784416]\t 1.1014421616742969\t 0.6628876451121497\t    \t    \n",
            "1  \t [1.51786663 9.25994479 9.         0.99792981 2.         0.61199673]\t 0.7207240599672383\t 0.6628876451121497\t 0.7898291479807739\t 0.7898291479807739\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[10.          8.17830402 15.          1.         20.          1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.648463895263151\u001b[0m\t \u001b[1m\u001b[92m0.648463895263151\u001b[0m\t \u001b[1m\u001b[92m0.7806389879034862\u001b[0m\t \u001b[1m\u001b[92m0.7806389878797565\u001b[0m\n",
            "3  \t [ 1.27154032  7.56256657  5.          0.85984573 12.          0.61608824]\t 0.7679544515659981\t 0.648463895263151\t 0.7603468400411282\t 0.7603468400411282\n",
            "4  \t [ 4.39024044  6.42906019 12.          0.96666124  5.          0.79403332]\t 0.6655222383347275\t 0.648463895263151\t 0.7570930207990597\t 0.7570930207990597\n",
            "5  \t [5.34651487 5.45650069 6.         0.93529094 7.         0.24078895]\t 1.0980632271289044\t 0.648463895263151\t 0.7516605039291846\t 0.7516605039291846\n",
            "6  \t [1.94198692 0.         5.         0.5        1.71133088 0.1       ]\t 1.0999573645797789\t 0.648463895263151\t 0.7607308108409735\t 0.7607308104401543\n",
            "7  \t [ 6.50677714  2.64641451 14.          0.50110879 19.          0.46175841]\t 0.8250792636501453\t 0.648463895263151\t 0.7681274161691498\t 0.7681274161691498\n",
            "8  \t [ 9.44002225  4.67426365 14.          0.69806573  1.          0.72511221]\t 0.7229243973927224\t 0.648463895263151\t 0.7666478146412649\t 0.7666478146412649\n",
            "9  \t [9.52796793 0.5269077  7.         0.61130342 2.         0.41024487]\t 0.8258632893631743\t 0.648463895263151\t 0.7632830603651932\t 0.7632830603651932\n",
            "10 \t [ 5.91640152  9.89232522  5.          0.52190423 15.          0.21991228]\t 1.0998703523971674\t 0.648463895263151\t 0.7623690883381887\t 0.7623690883381887\n",
            "11 \t [ 4.33230901  0.85672678  6.          0.63795453 19.          0.64597264]\t 0.7370906275446215\t 0.648463895263151\t 0.7676730186998215\t 0.7676730186998215\n",
            "12 \t [ 8.67074354  1.64396694 14.          0.83039094  7.          0.18845957]\t 1.1043508783594271\t 0.648463895263151\t 0.765103142414047\t 0.765103142414047\n",
            "13 \t [ 8.23661056  1.74251738  5.          0.73573442 11.          0.11684268]\t 1.0989959989808682\t 0.648463895263151\t 0.7697063938786571\t 0.7697063938786571\n",
            "14 \t [ 0.56153062  1.99964994 12.          0.65527832 19.          0.67862516]\t 0.7098652015644029\t 0.648463895263151\t 0.7736543055660762\t 0.7736543055660762\n",
            "15 \t [ 3.78319896  9.10205064 14.          0.62806706 13.          0.90182995]\t 0.6686440552339279\t 0.648463895263151\t 0.7708451493154812\t 0.7708451493154812\n",
            "16 \t [6.24719062 5.53382514 8.         0.54565421 1.         0.29508181]\t 0.922009341304437\t 0.648463895263151\t 0.7678154010484907\t 0.7678154010484907\n",
            "17 \t [1.72746041 9.05911241 9.         0.76972057 8.         0.72560219]\t 0.7119151444767224\t 0.648463895263151\t 0.7683752849581273\t 0.7683752849581273\n",
            "18 \t [ 0.94229296  2.02450761 13.          0.65000924  1.          0.22250131]\t 1.104491648360375\t 0.648463895263151\t 0.7661870870061891\t 0.7661870870061891\n",
            "19 \t [ 9.18192322  8.731671   11.          0.74092474  4.          0.11184795]\t 1.103627673047465\t 0.648463895263151\t 0.7695461299197209\t 0.7695461299197209\n",
            "20 \t [ 9.35280568  2.44132886  8.          0.87489385 18.          0.92170626]\t 0.67440347483604\t 0.648463895263151\t 0.7725896470583942\t 0.7725896470583942\n",
            "21 \t [ 0.15975595  4.68316579  6.81070583  0.5        15.81070583  0.1       ]\t 1.100712626473735\t 0.648463895263151\t 0.7701576526632253\t 0.7701576526628824\n",
            "22 \t [9.44502002 6.70596744 7.         0.72628773 8.         0.52383256]\t 0.7377024161191106\t 0.648463895263151\t 0.7728991199856198\t 0.7728991199856198\n",
            "23 \t [ 2.05622909  9.08047387  8.          0.8397078  17.          0.73365999]\t 0.7124011319640049\t 0.648463895263151\t 0.7712048915101466\t 0.7712048915101466\n",
            "24 \t [0.         1.5007252  5.         0.5        8.04717027 0.1       ]\t 1.1001735825073005\t 0.648463895263151\t 0.7694020782222785\t 0.7694020782208018\n",
            "25 \t [ 9.14754846  6.13923235 12.          0.62073128 16.          0.6329332 ]\t 0.7100143786907251\t 0.648463895263151\t 0.7718826471405008\t 0.7718826471405008\n",
            "26 \t [ 0.16863022  2.67389719  9.          0.62610438 15.          0.96408501]\t 0.672888499874982\t 0.648463895263151\t 0.7701600732398155\t 0.7701600732398155\n",
            "27 \t [9.28216308 9.63690211 6.         0.74633656 2.         0.66939338]\t 0.7399317555133837\t 0.648463895263151\t 0.7682069598490864\t 0.768207315895912\n",
            "28 \t [10.         10.         15.          1.          7.98571554  1.        ]\t 0.6494969194253049\t 0.648463895263151\t 0.7669320175867336\t 0.7669314672911695\n",
            "29 \t [ 1.1665804   8.5178555  13.          0.63744653 19.          0.35989497]\t 0.9216009805623578\t 0.648463895263151\t 0.7650712429330963\t 0.7650716368920951\n",
            "30 \t [ 0.35875087  9.99816653 14.          0.55154999  5.          0.36055676]\t 0.9304147018316155\t 0.648463895263151\t 0.7654955336703542\t 0.7654955336703542\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49288.16946361499"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAuEsXYbtOnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2ff273-8ac2-49e5-f48d-7f801ba785a5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_exact_14 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=test_perc, random_state=run_num_14)\n",
        "\n",
        "def f_syn_polarity14(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_14, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train14, y=y_train14).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_14 = dGPGO(surrogate_exact_14, Acquisition_grad(util), f_syn_polarity14, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_14.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_14 = exact_14.getResult()[0]\n",
        "params_exact_14['max_depth'] = int(params_exact_14['max_depth'])\n",
        "params_exact_14['min_child_weight'] = int(params_exact_14['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train14 = xgb.DMatrix(X_train14, y_train14)\n",
        "dX_exact_test14 = xgb.DMatrix(X_test14, y_test14)\n",
        "model_exact_14 = xgb.train(params_exact_14, dX_exact_train14)\n",
        "pred_exact_14 = model_exact_14.predict(dX_exact_test14)\n",
        "\n",
        "rmse_exact_14 = np.sqrt(mean_squared_error(pred_exact_14, y_test14))\n",
        "rmse_exact_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.13943344  7.73165052 12.          0.6831412  11.          0.37876233]\t 0.8139066743222003\t 0.6747866005380063\t    \t    \n",
            "init\t [ 9.57603739  5.13116712 14.          0.76959997 12.          0.71328228]\t 0.6747866005380063\t 0.6747866005380063\t    \t    \n",
            "init\t [5.34950319 2.47493539 5.         0.50293689 6.         0.29706373]\t 0.977412427074478\t 0.6747866005380063\t    \t    \n",
            "init\t [ 2.94506579  3.45329697  8.          0.87620946 14.          0.9783044 ]\t 0.6774024187451972\t 0.6747866005380063\t    \t    \n",
            "init\t [ 1.11811929  1.73004086  5.          0.73745288 12.          0.20586008]\t 1.0197967308919336\t 0.6747866005380063\t    \t    \n",
            "1  \t [ 6.50637223  2.67617722 14.          0.53562507  1.          0.16862152]\t 1.0126649561802825\t 0.6747866005380063\t 0.7766813921590745\t 0.7766813921590745\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6502979285238808\u001b[0m\t \u001b[1m\u001b[92m0.6502979285238808\u001b[0m\t \u001b[1m\u001b[92m0.7855204235958163\u001b[0m\t \u001b[1m\u001b[92m0.7855204235958163\u001b[0m\n",
            "3  \t [0.07739536 3.94062842 5.         0.7395899  3.         0.9764837 ]\t 0.7245455903141328\t 0.6502979285238808\t 0.7579883127132188\t 0.7579883127132188\n",
            "4  \t [6.9195004  0.54496332 8.         0.81208598 3.         0.15286338]\t 1.0111604668907606\t 0.6502979285238808\t 0.7537593238867123\t 0.7537593238867123\n",
            "5  \t [ 9.22243919  0.59642165  6.          0.72537748 19.          0.46639325]\t 0.8253470890530193\t 0.6502979285238808\t 0.7601846866341524\t 0.7601846866341524\n",
            "6  \t [ 0.49138495  8.52939618 10.          0.75897738  1.          0.21612775]\t 1.0131910395518218\t 0.6502979285238808\t 0.7593378511595953\t 0.7593378511595953\n",
            "7  \t [9.50752677 9.21478059 7.         0.68709357 5.         0.7478709 ]\t 0.6980584298280876\t 0.6502979285238808\t 0.7641182390499394\t 0.7641182390499394\n",
            "8  \t [ 0.63353879  9.61017877  8.          0.96421247 18.          0.39200727]\t 0.8087127953472528\t 0.6502979285238808\t 0.7602712747879945\t 0.7602712747879945\n",
            "9  \t [ 2.48800603  5.10093097 14.          0.58870342  6.          0.75046851]\t 0.679436663814411\t 0.6502979285238808\t 0.7592459009816112\t 0.7592459009816112\n",
            "10 \t [ 1.6361515   9.65601963  6.          0.78645605 10.          0.24059194]\t 1.0163848571205125\t 0.6502979285238808\t 0.7559521877103069\t 0.7559521877103069\n",
            "11 \t [ 9.88809977  3.72297385  6.          0.68686416 11.          0.16446157]\t 1.0169921141610336\t 0.6502979285238808\t 0.759781329477186\t 0.759781329477186\n",
            "12 \t [ 7.35080411  8.42969833  8.          0.54853874 19.          0.64845929]\t 0.6929769156766643\t 0.6502979285238808\t 0.7631260867511853\t 0.7631260867511853\n",
            "13 \t [ 0.91289908  0.49155493 12.          0.69437528 19.          0.25722688]\t 0.9566828107379326\t 0.6502979285238808\t 0.7603946543800881\t 0.7603946543800881\n",
            "14 \t [ 9.50881705  0.8310658  14.          0.86317554 18.          0.16718532]\t 1.0124852561685407\t 0.6502979285238808\t 0.7621807607227876\t 0.7621807607227876\n",
            "15 \t [ 9.08335885  5.57767412 12.          0.65195184  6.          0.80607804]\t 0.6813882293464838\t 0.6502979285238808\t 0.7647784035666627\t 0.7647784035666627\n",
            "16 \t [ 0.14027374  5.40881405 13.          0.72865252 14.          0.51307231]\t 0.716284046319991\t 0.6502979285238808\t 0.7622399645431885\t 0.7622399645431885\n",
            "17 \t [ 7.83429508  8.78694401 14.          0.74976219  2.          0.13371773]\t 1.0143595783371873\t 0.6502979285238808\t 0.7603444516672683\t 0.7603444516672683\n",
            "18 \t [ 0.96607499  0.08146515 10.          0.75402335  6.          0.63275599]\t 0.6767950914466152\t 0.6502979285238808\t 0.7627086471844466\t 0.7627086471844466\n",
            "19 \t [ 2.09007555  7.86113915 13.          0.73459776 19.          0.32750702]\t 0.9574373954877385\t 0.6502979285238808\t 0.760539430592609\t 0.760539430592609\n",
            "20 \t [ 4.57870743  1.98552875 14.          0.65566453 14.          0.81792968]\t 0.6768346638837561\t 0.6502979285238808\t 0.761883676328691\t 0.761883676328691\n",
            "21 \t [6.71149198 5.94756811 9.120908   0.5        2.120908   0.1       ]\t 1.0114593919171893\t 0.6502979285238808\t 0.7599191583749606\t 0.7599191546924172\n",
            "22 \t [ 2.89145179  8.95900591 10.          0.52398991  6.          0.6540998 ]\t 0.684154512907023\t 0.6502979285238808\t 0.7618984393758018\t 0.7618984393758018\n",
            "23 \t [ 6.28385098  9.05548813 12.          0.85129754 16.          0.38663401]\t 0.8082661637463469\t 0.6502979285238808\t 0.760143601933359\t 0.760143601933359\n",
            "24 \t [ 7.81565208  8.37765764  8.          0.90455467 10.          0.42628218]\t 0.8112457235444476\t 0.6502979285238808\t 0.7596677044095257\t 0.7596677044095257\n",
            "25 \t [ 5.5386478   9.30162083  6.          0.50498383 14.          0.37570322]\t 0.8247413269393998\t 0.6502979285238808\t 0.759253453254031\t 0.759253453254031\n",
            "26 \t [ 7.99859192  1.27814403 11.          0.87670998 12.          0.48785901]\t 0.8089215294655372\t 0.6502979285238808\t 0.7589952188181628\t 0.7589952188181628\n",
            "27 \t [ 0.19921359  1.33183456 11.          0.79119941 11.          0.23591371]\t 1.0112356555986186\t 0.6502979285238808\t 0.7586034326034824\t 0.7586034326034824\n",
            "28 \t [ 0.40405522  2.81796516 11.          0.8908648   1.          0.54002187]\t 0.7224622612996938\t 0.6502979285238808\t 0.7602585633306942\t 0.7602585633306942\n",
            "\u001b[1m\u001b[92m29\u001b[0m\t \u001b[1m\u001b[92m[ 9.32240401 10.         15.          1.          9.81271991  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6479795755479903\u001b[0m\t \u001b[1m\u001b[92m0.6479795755479903\u001b[0m\t \u001b[1m\u001b[92m0.7591550287284496\u001b[0m\t \u001b[1m\u001b[92m0.7591550003221584\u001b[0m\n",
            "30 \t [ 1.26617981  4.03386415  8.          0.85223134 19.          0.86958504]\t 0.6828604856051443\t 0.6479795755479903\t 0.7557826373554826\t 0.7557826373554826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49649.120605868084"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgxvE7Irbbj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed653c3-ce36-4ebe-f642-3709ad474322"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_exact_15 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train15, X_test15, y_train15, y_test15 = train_test_split(X, y, test_size=test_perc, random_state=run_num_15)\n",
        "\n",
        "def f_syn_polarity15(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_15, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train15, y=y_train15).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_15 = dGPGO(surrogate_exact_15, Acquisition_grad(util), f_syn_polarity15, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_15.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_15 = exact_15.getResult()[0]\n",
        "params_exact_15['max_depth'] = int(params_exact_15['max_depth'])\n",
        "params_exact_15['min_child_weight'] = int(params_exact_15['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train15 = xgb.DMatrix(X_train15, y_train15)\n",
        "dX_exact_test15 = xgb.DMatrix(X_test15, y_test15)\n",
        "model_exact_15 = xgb.train(params_exact_15, dX_exact_train15)\n",
        "pred_exact_15 = model_exact_15.predict(dX_exact_test15)\n",
        "\n",
        "rmse_exact_15 = np.sqrt(mean_squared_error(pred_exact_15, y_test15))\n",
        "rmse_exact_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 8.48817697  1.78895925 12.          0.55549316  8.          0.93397854]\t 0.6568473525973234\t 0.6568473525973234\t    \t    \n",
            "init\t [ 0.24953032  8.22298097 12.          0.62494951 11.          0.12924598]\t 0.9115777462403312\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.02017228  5.50882771 11.          0.85295832 19.          0.13548008]\t 0.9091447847268881\t 0.6568473525973234\t    \t    \n",
            "init\t [2.0023081  9.98543403 7.         0.6295772  2.         0.526127  ]\t 0.702826724376194\t 0.6568473525973234\t    \t    \n",
            "init\t [ 5.09715306  9.45038417 11.          0.7388277  16.          0.22739973]\t 0.9107852583947551\t 0.6568473525973234\t    \t    \n",
            "1  \t [ 0.29158961  4.9949242  12.          0.89124583  3.          0.67554049]\t 0.663179402460053\t 0.6568473525973234\t 0.7570167459024465\t 0.7570167459024465\n",
            "2  \t [2.60517447 0.82584036 7.         0.6107555  4.         0.25427784]\t 0.8585273074032198\t 0.6568473525973234\t 0.7498589155313063\t 0.7498589155313063\n",
            "3  \t [ 9.6900225   0.69761314 13.          0.54877119 16.          0.55532692]\t 0.676755395441882\t 0.6568473525973234\t 0.7522698091129767\t 0.7522698091129767\n",
            "4  \t [ 3.00890132  3.25033589  6.          0.76721153 13.          0.286699  ]\t 0.8615658015198442\t 0.6568473525973234\t 0.7478764735916281\t 0.7478764735916281\n",
            "5  \t [ 7.00755347  9.83963845  5.          0.51866345 10.          0.95031515]\t 0.730615339433918\t 0.6568473525973234\t 0.7500808088437022\t 0.7500808088437022\n",
            "6  \t [ 8.69662558  6.80112051 14.          0.50188459  3.          0.90006664]\t 0.6638687110610159\t 0.6568473525973234\t 0.7481308234237891\t 0.7481308234237891\n",
            "\u001b[1m\u001b[92m7\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6491916518522693\u001b[0m\t \u001b[1m\u001b[92m0.6491916518522693\u001b[0m\t \u001b[1m\u001b[92m0.745017407431795\u001b[0m\t \u001b[1m\u001b[92m0.7450174074297929\u001b[0m\n",
            "8  \t [ 9.21941721  9.79827821 11.          0.81783228 11.          0.53477407]\t 0.6659586056207597\t 0.6491916518522693\t 0.7359947561093437\t 0.7359947561093437\n",
            "9  \t [8.88449541 3.44367948 6.         0.58829924 7.         0.7864797 ]\t 0.7097411329660293\t 0.6491916518522693\t 0.7338257361388124\t 0.7338257361388124\n",
            "10 \t [ 8.47779105  8.43696768  5.          0.73890705 16.          0.66738091]\t 0.7564851327663848\t 0.6491916518522693\t 0.7327453917914256\t 0.7327453917914256\n",
            "11 \t [9.8850401  9.05036452 8.         0.98423572 3.         0.82693955]\t 0.6638601166418586\t 0.6491916518522693\t 0.7326403217954902\t 0.7326403217954902\n",
            "12 \t [1.37672687 0.04946237 5.         0.79719419 1.         0.81843222]\t 0.7350998875793917\t 0.6491916518522693\t 0.731049447241008\t 0.731049447241008\n",
            "13 \t [ 0.90706815  0.79490515  7.          0.51831376 19.          0.91250419]\t 0.6855937848974291\t 0.6491916518522693\t 0.730707996966001\t 0.730707996966001\n",
            "14 \t [ 7.24320809  1.00477988 10.          0.73543626  1.          0.62081075]\t 0.6775831216463617\t 0.6491916518522693\t 0.7296982642476125\t 0.7296982642476125\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[ 5.53179684  5.42623971 11.          0.96540614 10.          0.78461433]\u001b[0m\t \u001b[1m\u001b[92m0.6463871000955349\u001b[0m\t \u001b[1m\u001b[92m0.6463871000955349\u001b[0m\t \u001b[1m\u001b[92m0.7286899244019035\u001b[0m\t \u001b[1m\u001b[92m0.7286899244019035\u001b[0m\n",
            "16 \t [ 8.3663813   2.71045401  6.          0.93358602 19.          0.54898259]\t 0.722555636740782\t 0.6463871000955349\t 0.7251272369939915\t 0.7251272369939915\n",
            "17 \t [ 1.99733414  0.13877735 14.          0.5792705  10.          0.44528521]\t 0.7943377363668869\t 0.6463871000955349\t 0.724873399916217\t 0.724873399916217\n",
            "18 \t [ 4.29171811  0.04074186 13.          0.58769183 18.          0.36351335]\t 0.8568574802990294\t 0.6463871000955349\t 0.7255481541909187\t 0.7255481541909187\n",
            "19 \t [ 1.82906731  5.15105244 12.          0.56966528 15.          0.63831204]\t 0.6762407016215379\t 0.6463871000955349\t 0.7269876239300037\t 0.7269876239300037\n",
            "20 \t [1.78502553 6.3382371  7.         0.5356847  8.         0.94131063]\t 0.6859250343998504\t 0.6463871000955349\t 0.7261853976486723\t 0.7261853976486723\n",
            "21 \t [6.39740566 2.7572448  5.         0.5        2.58753518 0.1       ]\t 0.9163356051515258\t 0.6463871000955349\t 0.7255510050030978\t 0.7255509724912499\n",
            "22 \t [0.         0.         7.24132578 0.5        9.24132578 0.1       ]\t 0.9138585085519754\t 0.6463871000955349\t 0.7275633680990466\t 0.7275625313992735\n",
            "23 \t [ 5.3880688   2.65297896 14.          0.90613057  4.          0.23404421]\t 0.9109113159973135\t 0.6463871000955349\t 0.7294003140244132\t 0.7294003140244132\n",
            "24 \t [ 9.36080884  1.0313168   5.          0.6330142  14.          0.51274968]\t 0.756031776613528\t 0.6463871000955349\t 0.731059369537426\t 0.731059369537426\n",
            "25 \t [ 0.23718299  5.15069191  5.          0.53030067 17.          0.55502993]\t 0.7588357317663977\t 0.6463871000955349\t 0.7309849594150618\t 0.7309849594150618\n",
            "26 \t [ 5.12774674  9.38269657 12.          0.66930635  1.          0.1906148 ]\t 0.9139113523209742\t 0.6463871000955349\t 0.7309356434628078\t 0.7309356434628078\n",
            "27 \t [ 7.81154233  4.07454888  9.          0.93317853 14.          0.30786282]\t 0.848881320125441\t 0.6463871000955349\t 0.732419479489748\t 0.732419479489748\n",
            "28 \t [10.         10.          7.25812521  1.         20.          1.        ]\t 0.675692027646826\t 0.6463871000955349\t 0.7331520240142186\t 0.733151052301429\n",
            "29 \t [ 8.58008338  8.15977468 15.          1.          7.92391088  1.        ]\t 0.6471111504300529\t 0.6463871000955349\t 0.7323867971227164\t 0.7323867896499373\n",
            "30 \t [5.29533806 7.19033247 7.         0.701633   5.         0.56032884]\t 0.7004774817117754\t 0.6463871000955349\t 0.7314625603894663\t 0.7314625603894663\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50265.507092316264"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TaP6RoGuiNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5d6cc1-0b8a-4734-e6c3-c8fbc7a6864a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_exact_16 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(X, y, test_size=test_perc, random_state=run_num_16)\n",
        "\n",
        "def f_syn_polarity16(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_16, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train16, y=y_train16).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_16 = dGPGO(surrogate_exact_16, Acquisition_grad(util), f_syn_polarity16, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_16.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_16 = exact_16.getResult()[0]\n",
        "params_exact_16['max_depth'] = int(params_exact_16['max_depth'])\n",
        "params_exact_16['min_child_weight'] = int(params_exact_16['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train16 = xgb.DMatrix(X_train16, y_train16)\n",
        "dX_exact_test16 = xgb.DMatrix(X_test16, y_test16)\n",
        "model_exact_16 = xgb.train(params_exact_16, dX_exact_train16)\n",
        "pred_exact_16 = model_exact_16.predict(dX_exact_test16)\n",
        "\n",
        "rmse_exact_16 = np.sqrt(mean_squared_error(pred_exact_16, y_test16))\n",
        "rmse_exact_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [2.23291079 5.23163341 6.         0.65430839 5.         0.30077285]\t 0.9529819347295859\t 0.8883829281923242\t    \t    \n",
            "init\t [6.88726162 1.63731425 7.         0.97050543 2.         0.25392012]\t 0.9481041389252269\t 0.8883829281923242\t    \t    \n",
            "init\t [ 5.94328983  5.6393473   5.          0.67602695 19.          0.42538144]\t 0.8883829281923242\t 0.8883829281923242\t    \t    \n",
            "init\t [ 0.88741148  3.08148142 14.          0.56043938  9.          0.27515386]\t 0.9564077542414676\t 0.8883829281923242\t    \t    \n",
            "init\t [ 2.74631586  1.30996118 11.          0.52160786  8.          0.27956463]\t 0.9552184743546004\t 0.8883829281923242\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 7.8937256   1.5972923  14.          0.61610774 17.          0.78739284]\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.6878693399983744\u001b[0m\t \u001b[1m\u001b[92m0.9753718017522196\u001b[0m\t \u001b[1m\u001b[92m0.9753718017522196\u001b[0m\n",
            "2  \t [ 9.65014948  7.07834667 14.          0.88748515  2.          0.43513691]\t 0.8747438848890932\t 0.6878693399983744\t 0.8040275427718057\t 0.8040275427718057\n",
            "3  \t [ 9.80741348  8.90144788 14.          0.82131992 14.          0.46769684]\t 0.8608053593354814\t 0.6878693399983744\t 0.8028355919408534\t 0.8028355919408534\n",
            "4  \t [ 0.78730688  7.98438553 14.          0.91743896 18.          0.25645593]\t 0.9494553422981233\t 0.6878693399983744\t 0.8014251409281299\t 0.8014251409281299\n",
            "5  \t [ 1.64983341  0.37890577  9.          0.65437216 16.          0.49641159]\t 0.8646755374886521\t 0.6878693399983744\t 0.803284300777709\t 0.803284300777709\n",
            "6  \t [ 5.58043809  8.91463745  8.          0.85851576 10.          0.64398202]\t 0.7307340308882677\t 0.6878693399983744\t 0.802231610408923\t 0.802231610408923\n",
            "7  \t [ 2.65571666  4.32529089 14.          0.66921971  2.          0.36607383]\t 0.9623426051674955\t 0.6878693399983744\t 0.7981359019638348\t 0.7981359019638348\n",
            "8  \t [0.  0.  5.  0.5 1.  0.1]\t 0.9761208022264058\t 0.6878693399983744\t 0.8001486769870478\t 0.8001486767224776\n",
            "\u001b[1m\u001b[92m9\u001b[0m\t \u001b[1m\u001b[92m[6.95801625 9.13555009 8.         0.87520198 2.         0.98461662]\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.6730441336589406\u001b[0m\t \u001b[1m\u001b[92m0.8022000811098519\u001b[0m\t \u001b[1m\u001b[92m0.8022000811098519\u001b[0m\n",
            "10 \t [ 9.49073008  1.95543967  6.          0.82312132 10.          0.92175057]\t 0.7048401121150428\t 0.6730441336589406\t 0.7864643895758132\t 0.7864643895758132\n",
            "11 \t [ 1.18539745  9.79684488 10.          0.69107903  4.          0.12860486]\t 0.9735436243628346\t 0.6730441336589406\t 0.7832680035899731\t 0.7832680035899731\n",
            "12 \t [ 8.8197294   2.64777319 14.          0.98646567 10.          0.63786085]\t 0.7141008345477899\t 0.6730441336589406\t 0.7852442960250308\t 0.7852442960250308\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[ 0.26172129  9.94921995 14.          0.88029118  9.          0.93655616]\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.6551680070961308\u001b[0m\t \u001b[1m\u001b[92m0.7826228994795568\u001b[0m\t \u001b[1m\u001b[92m0.7826228994795568\u001b[0m\n",
            "14 \t [ 9.63904847  1.13624975 14.          0.67706869  2.          0.95236673]\t 0.6655207401201757\t 0.6551680070961308\t 0.7655727883367727\t 0.7655727883367727\n",
            "15 \t [ 0.02157337  9.97534925  5.          0.75404051 13.          0.40760752]\t 0.8854668121365705\t 0.6551680070961308\t 0.7628666375841194\t 0.7628666375841194\n",
            "16 \t [ 5.73702737  7.50903876 13.          0.61487351 15.          0.57742278]\t 0.7778153254020743\t 0.6551680070961308\t 0.763395108167759\t 0.763395108167759\n",
            "17 \t [ 7.10469951  6.34150339 11.          0.9481748   6.          0.12277199]\t 0.9718611347031094\t 0.6551680070961308\t 0.7623871271253037\t 0.7623871271253037\n",
            "\u001b[1m\u001b[92m18\u001b[0m\t \u001b[1m\u001b[92m[10. 10. 15.  1. 20.  1.]\u001b[0m\t \u001b[1m\u001b[92m0.6493784945243817\u001b[0m\t \u001b[1m\u001b[92m0.6493784945243817\u001b[0m\t \u001b[1m\u001b[92m0.7641574304593991\u001b[0m\t \u001b[1m\u001b[92m0.764157229112003\u001b[0m\n",
            "19 \t [ 2.38304891  0.39103582  5.          0.8629475  11.          0.24144597]\t 0.9722076737300622\t 0.6493784945243817\t 0.7573048357386386\t 0.7573048357386386\n",
            "20 \t [ 8.60177792  1.89933469  8.          0.92909045 16.          0.35782775]\t 0.9467791150821778\t 0.6493784945243817\t 0.7589685342770627\t 0.7589685342770627\n",
            "21 \t [ 6.66300191  0.19049997 11.          0.78724655  5.          0.59145595]\t 0.7758336723119745\t 0.6493784945243817\t 0.7601549016938655\t 0.7601549016938655\n",
            "22 \t [ 9.99926575  9.6578075   8.          0.78804094 15.          0.34788136]\t 0.9483714616421471\t 0.6493784945243817\t 0.7592673431416131\t 0.7592673431416131\n",
            "\u001b[1m\u001b[92m23\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         13.54345422  1.          7.30310789  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.64674119912955\u001b[0m\t \u001b[1m\u001b[92m0.64674119912955\u001b[0m\t \u001b[1m\u001b[92m0.7603746719342938\u001b[0m\t \u001b[1m\u001b[92m0.7603746674513681\u001b[0m\n",
            "24 \t [ 0.6221621   5.97682344 10.          0.77872519 13.          0.10493686]\t 0.9719497005255608\t 0.64674119912955\t 0.7563476634416331\t 0.7563476634416331\n",
            "25 \t [ 3.22666016  7.92832778  8.          0.72057652 16.          0.11265096]\t 0.9712468749152879\t 0.64674119912955\t 0.757681246779579\t 0.757681246779579\n",
            "26 \t [9.53244977 7.04235321 6.         0.75218774 7.         0.15792958]\t 0.9722684401992453\t 0.64674119912955\t 0.7589229015052182\t 0.7589229015052182\n",
            "27 \t [ 9.26334332  8.65557634  6.          0.701058   19.          0.33944267]\t 0.950744124728271\t 0.64674119912955\t 0.7600895624933993\t 0.7600895624933993\n",
            "28 \t [ 1.9619463   0.16028995 10.          0.50330845  2.          0.6207421 ]\t 0.7893707891931834\t 0.64674119912955\t 0.7609557886799561\t 0.7609557886799561\n",
            "29 \t [ 2.85481198  1.91621026 14.          0.54622477 17.          0.11441312]\t 0.9744815425855189\t 0.64674119912955\t 0.7602844705831093\t 0.7602846873885718\n",
            "30 \t [ 4.09652221  8.7585222  14.86409818  1.          3.86409818  1.        ]\t 0.6494333492258981\t 0.64674119912955\t 0.7613262822038467\t 0.7613259292636899\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50283.20871582488"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOaMUmgulbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e92e3fb-c2ff-4b02-806f-614890a63dfb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_exact_17 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train17, X_test17, y_train17, y_test17 = train_test_split(X, y, test_size=test_perc, random_state=run_num_17)\n",
        "\n",
        "def f_syn_polarity17(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_17, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train17, y=y_train17).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_17 = dGPGO(surrogate_exact_17, Acquisition_grad(util), f_syn_polarity17, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_17.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_17 = exact_17.getResult()[0]\n",
        "params_exact_17['max_depth'] = int(params_exact_17['max_depth'])\n",
        "params_exact_17['min_child_weight'] = int(params_exact_17['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train17 = xgb.DMatrix(X_train17, y_train17)\n",
        "dX_exact_test17 = xgb.DMatrix(X_test17, y_test17)\n",
        "model_exact_17 = xgb.train(params_exact_17, dX_exact_train17)\n",
        "pred_exact_17 = model_exact_17.predict(dX_exact_test17)\n",
        "\n",
        "rmse_exact_17 = np.sqrt(mean_squared_error(pred_exact_17, y_test17))\n",
        "rmse_exact_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 2.94665003  5.30586756 11.          0.94443241 14.          0.80828691]\t 0.7141038418197827\t 0.7141038418197827\t    \t    \n",
            "init\t [ 6.56333522  6.37520896 12.          0.81487881 18.          0.42203224]\t 0.8024876355160464\t 0.7141038418197827\t    \t    \n",
            "init\t [ 9.45683187  0.6004468  11.          0.5171566  10.          0.53881211]\t 0.7659849712152795\t 0.7141038418197827\t    \t    \n",
            "init\t [2.72705857 1.19063434 6.         0.74176431 6.         0.10101151]\t 0.9684453836634761\t 0.7141038418197827\t    \t    \n",
            "init\t [ 4.77631812  5.24671297 13.          0.66254476 19.          0.36708086]\t 0.8556892362199922\t 0.7141038418197827\t    \t    \n",
            "1  \t [ 0.65702322  5.79284078 13.          0.75136902  1.          0.30306068]\t 0.86898292288902\t 0.7141038418197827\t 0.8008601163353377\t 0.8008601163353377\n",
            "2  \t [8.79462978 7.51560605 6.         0.76312232 8.         0.57156636]\t 0.778300364354035\t 0.7141038418197827\t 0.8031678891892342\t 0.8031678891892342\n",
            "3  \t [0.65992542 7.03112384 5.         0.85138174 1.         0.9514344 ]\t 0.726434848802118\t 0.7141038418197827\t 0.8012680149811908\t 0.8012680149811908\n",
            "4  \t [ 9.51671323  9.6124566  13.          0.71797221  5.          0.16581182]\t 0.9672674042711217\t 0.7141038418197827\t 0.7982130526803441\t 0.7982130526803441\n",
            "5  \t [ 9.17797544  5.99568118  6.          0.52445603 15.          0.40946449]\t 0.826366430225874\t 0.7141038418197827\t 0.803386289788417\t 0.803386289788417\n",
            "6  \t [ 6.81284184  2.29577018  7.          0.5239727  13.          0.33920765]\t 0.8659399691320455\t 0.7141038418197827\t 0.8041704263763533\t 0.8041704263763533\n",
            "7  \t [ 2.46339402  0.14039019 14.          0.95096219  7.          0.5441132 ]\t 0.7563633439329396\t 0.7141038418197827\t 0.804270529537069\t 0.804270529537069\n",
            "8  \t [9.72843652 3.88893279 9.         0.6901555  1.         0.31608219]\t 0.861798864893942\t 0.7141038418197827\t 0.8026060695114751\t 0.8026060695114751\n",
            "9  \t [ 1.2716555   3.78378689  5.          0.57556817 17.          0.18163876]\t 0.9716163961274858\t 0.7141038418197827\t 0.8033770470955414\t 0.8033770470955414\n",
            "10 \t [1.38490793 6.87002541 5.         0.73931504 9.         0.41767138]\t 0.829976302946727\t 0.7141038418197827\t 0.8064202124025374\t 0.8064202124025374\n",
            "11 \t [ 0.19725752  8.16335211 14.          0.80836431  8.          0.45209851]\t 0.8069651446453449\t 0.7141038418197827\t 0.8062381668271084\t 0.8062381668271084\n",
            "12 \t [0.  0.  5.  0.5 1.  0.1]\t 0.973743062796521\t 0.7141038418197827\t 0.8056890538434928\t 0.8056890527458487\n",
            "13 \t [ 7.51514915  5.57821555 12.          0.8704045   9.          0.10769764]\t 0.9654026035949915\t 0.7141038418197827\t 0.8080938277524777\t 0.8080938277524777\n",
            "14 \t [5.79855217 7.64610678 9.         0.54644758 3.         0.68341681]\t 0.7349404110255493\t 0.7141038418197827\t 0.8100777183845699\t 0.8100777183845699\n",
            "\u001b[1m\u001b[92m15\u001b[0m\t \u001b[1m\u001b[92m[10.        10.        12.2363834  1.        16.2363834  1.       ]\u001b[0m\t \u001b[1m\u001b[92m0.6459568092098263\u001b[0m\t \u001b[1m\u001b[92m0.6459568092098263\u001b[0m\t \u001b[1m\u001b[92m0.8084512194099017\u001b[0m\t \u001b[1m\u001b[92m0.8084514680780175\u001b[0m\n",
            "16 \t [6.14842106 3.92031042 5.         0.80436272 5.         0.42842685]\t 0.8298337600349435\t 0.6459568092098263\t 0.7524966753144922\t 0.7524966753144922\n",
            "17 \t [ 1.93531857  1.03643759  8.          0.58366211 11.          0.77260063]\t 0.7377317601285239\t 0.6459568092098263\t 0.7519233852361532\t 0.7519234429936846\n",
            "18 \t [ 3.53837011  9.01841925  6.39908028  1.         16.39908028  1.        ]\t 0.6994821845670678\t 0.6459568092098263\t 0.7506544932218413\t 0.7506535900479723\n",
            "19 \t [ 0.45348627  9.34732483 12.          0.95759453 19.          0.71400033]\t 0.7137199048529451\t 0.6459568092098263\t 0.7490687522827358\t 0.7490687522827358\n",
            "20 \t [ 6.88175573  0.68997438  9.          0.55006192 19.          0.74555899]\t 0.7341056462061506\t 0.6459568092098263\t 0.747760910392524\t 0.7477609115954118\n",
            "21 \t [ 7.32262595  0.987487   14.          0.78324612 14.          0.76403633]\t 0.7129217809179572\t 0.6459568092098263\t 0.7467656725761571\t 0.7467656725761571\n",
            "22 \t [ 6.72796419  6.10053296 14.          0.56325639  2.          0.91580991]\t 0.672911524877989\t 0.6459568092098263\t 0.7456349375250095\t 0.7456352394247764\n",
            "23 \t [ 5.18644121  9.97216159 13.          0.51656015 15.          0.59837352]\t 0.7660042630046296\t 0.6459568092098263\t 0.7445605020665508\t 0.7445605020665508\n",
            "24 \t [0.85666329 5.92364698 9.         0.69191689 5.         0.98975497]\t 0.6651465396376819\t 0.6459568092098263\t 0.7437589069414282\t 0.7437590804607687\n",
            "25 \t [9.66959108 0.03423869 5.         0.63791788 7.         0.65549808]\t 0.7797393754763862\t 0.6459568092098263\t 0.7424373962626829\t 0.7424373962626829\n",
            "26 \t [ 3.61406382  9.87735751 10.          0.70199599  8.          0.85082246]\t 0.721371984674188\t 0.6459568092098263\t 0.7421934196090577\t 0.742193429700716\n",
            "27 \t [ 5.62137526  0.50742571 12.          0.60891749  1.          0.89299215]\t 0.6736748141470514\t 0.6459568092098263\t 0.741755893128918\t 0.741755893128918\n",
            "\u001b[1m\u001b[92m28\u001b[0m\t \u001b[1m\u001b[92m[ 4.91762129 10.         15.          1.          9.07372253  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6442722473700804\u001b[0m\t \u001b[1m\u001b[92m0.6442722473700804\u001b[0m\t \u001b[1m\u001b[92m0.7403909645002622\u001b[0m\t \u001b[1m\u001b[92m0.7403916480979037\u001b[0m\n",
            "29 \t [ 0.30609514  2.49894713 14.          0.69397027 18.          0.71750058]\t 0.7193266691045255\t 0.6442722473700804\t 0.7378437932440652\t 0.7378437932440652\n",
            "30 \t [6.35656988 0.         5.         0.5        1.55338291 0.1       ]\t 0.9737446912602603\t 0.6442722473700804\t 0.7372412957576043\t 0.7372404906864768\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49448.62041714394"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4MWSXFcZjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c9cc52f-14ef-4827-f0cd-2f0e12ce7f1e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_exact_18 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train18, X_test18, y_train18, y_test18 = train_test_split(X, y, test_size=test_perc, random_state=run_num_18)\n",
        "\n",
        "def f_syn_polarity18(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_18, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train18, y=y_train18).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_18 = dGPGO(surrogate_exact_18, Acquisition_grad(util), f_syn_polarity18, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_18.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_18 = exact_18.getResult()[0]\n",
        "params_exact_18['max_depth'] = int(params_exact_18['max_depth'])\n",
        "params_exact_18['min_child_weight'] = int(params_exact_18['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train18 = xgb.DMatrix(X_train18, y_train18)\n",
        "dX_exact_test18 = xgb.DMatrix(X_test18, y_test18)\n",
        "model_exact_18 = xgb.train(params_exact_18, dX_exact_train18)\n",
        "pred_exact_18 = model_exact_18.predict(dX_exact_test18)\n",
        "\n",
        "rmse_exact_18 = np.sqrt(mean_squared_error(pred_exact_18, y_test18))\n",
        "rmse_exact_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [6.50374242 5.05453374 6.         0.59092011 3.         0.28357516]\t 0.9953081887469889\t 0.7220763687473127\t    \t    \n",
            "init\t [0.11506734 4.26891483 9.         0.81785956 5.         0.63489043]\t 0.7220763687473127\t 0.7220763687473127\t    \t    \n",
            "init\t [ 2.8861259   6.35547834 11.          0.64267955 14.          0.27877092]\t 0.9889075947558364\t 0.7220763687473127\t    \t    \n",
            "init\t [6.57189031 6.99655629 8.         0.63235896 4.         0.52894035]\t 0.7606594495187335\t 0.7220763687473127\t    \t    \n",
            "init\t [ 6.66600348  2.11312037 14.          0.74363461  4.          0.73174558]\t 0.7225304513182221\t 0.7220763687473127\t    \t    \n",
            "1  \t [ 8.67093232  0.11649132  5.          0.92962202 15.          0.53672863]\t 0.8181138208820815\t 0.7220763687473127\t 0.8143299429335743\t 0.8143299429335743\n",
            "\u001b[1m\u001b[92m2\u001b[0m\t \u001b[1m\u001b[92m[ 7.2764983   0.11744451 14.          0.65239666 17.          0.99049521]\u001b[0m\t \u001b[1m\u001b[92m0.6527007643358951\u001b[0m\t \u001b[1m\u001b[92m0.6527007643358951\u001b[0m\t \u001b[1m\u001b[92m0.8130945040634344\u001b[0m\t \u001b[1m\u001b[92m0.8130945040634344\u001b[0m\n",
            "3  \t [ 6.9243088   2.24175244  9.          0.535904   10.          0.52104842]\t 0.7581381331811782\t 0.6527007643358951\t 0.7509870196233731\t 0.7509870196233731\n",
            "4  \t [ 9.05522886  7.72410538  5.          0.69563915 18.          0.34113663]\t 0.995752758561317\t 0.6527007643358951\t 0.7489412296502286\t 0.7489412296502286\n",
            "5  \t [ 9.98394208  8.5932438  14.          0.75596751 19.          0.64506065]\t 0.7153197782842456\t 0.6527007643358951\t 0.7559102718417623\t 0.7559102718417623\n",
            "6  \t [ 8.22273842  9.68669454  5.          0.7147283  11.          0.16411281]\t 1.0132763479062032\t 0.6527007643358951\t 0.7523598728887179\t 0.7523598728887179\n",
            "7  \t [3.28907983 0.32007134 5.         0.82737078 1.         0.19815427]\t 1.0120318552286456\t 0.6527007643358951\t 0.7582912058189356\t 0.7582912058189356\n",
            "8  \t [ 1.24316399  9.43141312 14.          0.66900118  7.          0.55235225]\t 0.745004296865836\t 0.6527007643358951\t 0.7626330350685552\t 0.7626330350685552\n",
            "9  \t [ 1.80118477  1.19747778 13.          0.79590104  8.          0.56741067]\t 0.7386631133573338\t 0.6527007643358951\t 0.7602422804312197\t 0.7602422804312197\n",
            "\u001b[1m\u001b[92m10\u001b[0m\t \u001b[1m\u001b[92m[10.          9.9395376  10.81667229  1.          7.81667229  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6497648370812502\u001b[0m\t \u001b[1m\u001b[92m0.6497648370812502\u001b[0m\t \u001b[1m\u001b[92m0.758067717832982\u001b[0m\t \u001b[1m\u001b[92m0.7580677138176221\u001b[0m\n",
            "11 \t [ 0.2637722   4.11659493  5.          0.61604637 11.          0.22374653]\t 1.0148667858309313\t 0.6497648370812502\t 0.7524254340932363\t 0.7524254340932363\n",
            "12 \t [ 3.09522647  6.97119948 14.          0.63850148  1.          0.54769428]\t 0.7593781021734818\t 0.6497648370812502\t 0.7561959053448478\t 0.7561959053448478\n",
            "13 \t [ 1.3916722   9.15131624  5.          0.92812295 18.          0.82773453]\t 0.7760470257675838\t 0.6497648370812502\t 0.7548215444405795\t 0.7548215444405795\n",
            "14 \t [8.45918053 0.39509087 9.         0.81105792 3.         0.47358724]\t 0.8424181577085037\t 0.6497648370812502\t 0.753848311789057\t 0.753848311789057\n",
            "15 \t [ 2.48015892  1.47696138 11.          0.71803346 17.          0.49953238]\t 0.8352743547412123\t 0.6497648370812502\t 0.7539750153621549\t 0.7539750153621549\n",
            "16 \t [ 4.59534012  4.01550061  7.          0.90448443 19.          0.83175575]\t 0.7153642731933768\t 0.6497648370812502\t 0.7539832127997651\t 0.7539832127997651\n",
            "\u001b[1m\u001b[92m17\u001b[0m\t \u001b[1m\u001b[92m[ 8.6360214   7.39289423 12.22229584  1.         13.23570689  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.6419630949117721\u001b[0m\t \u001b[1m\u001b[92m0.6419630949117721\u001b[0m\t \u001b[1m\u001b[92m0.7524260462155257\u001b[0m\t \u001b[1m\u001b[92m0.7524260037982232\u001b[0m\n",
            "18 \t [ 2.33009125  0.         10.79561661  0.5         2.79561661  0.1       ]\t 1.0093178587345324\t 0.6419630949117721\t 0.744086513979242\t 0.7440866189441562\n",
            "19 \t [9.2798599  7.10759547 6.         0.7926243  1.         0.10786223]\t 1.0088210680321927\t 0.6419630949117721\t 0.7468903839127082\t 0.7468903839127082\n",
            "20 \t [ 3.98037481  6.07418665 15.          1.         20.          1.        ]\t 0.6430321528860679\t 0.6419630949117721\t 0.7491701861347768\t 0.7491688516482788\n",
            "21 \t [ 1.2588084   9.80413977  5.          0.75618546 12.          0.53020258]\t 0.8196793624782129\t 0.6419630949117721\t 0.7471051982720118\t 0.7471051982720118\n",
            "22 \t [10.          3.72270582 12.50013198  1.          7.50013198  1.        ]\t 0.6433038533833433\t 0.6419630949117721\t 0.746964428184655\t 0.7469649572938604\n",
            "23 \t [ 9.73631216  7.46194167 14.          0.919988    1.          0.18982878]\t 1.0037909714736977\t 0.6419630949117721\t 0.745130640123817\t 0.745130640123817\n",
            "24 \t [ 0.22595335  5.98536626  8.          0.51612812 19.          0.39759607]\t 0.8518884632739487\t 0.6419630949117721\t 0.7473273151472194\t 0.7473273151472194\n",
            "25 \t [1.07172211 9.91320527 6.         0.98176043 4.         0.24706724]\t 1.0106629985673714\t 0.6419630949117721\t 0.7474093448239683\t 0.7474093448239683\n",
            "26 \t [ 1.35116929  0.          8.65693521  0.5        12.65693521  0.1       ]\t 1.007950688509711\t 0.6419630949117721\t 0.7493472882863471\t 0.7493464661835177\n",
            "\u001b[1m\u001b[92m27\u001b[0m\t \u001b[1m\u001b[92m[ 2.93477275  9.74814488 14.65277808  1.         15.65277808  0.88695576]\u001b[0m\t \u001b[1m\u001b[92m0.6354593174733028\u001b[0m\t \u001b[1m\u001b[92m0.6354593174733028\u001b[0m\t \u001b[1m\u001b[92m0.7511237918196026\u001b[0m\t \u001b[1m\u001b[92m0.7511237347828895\u001b[0m\n",
            "28 \t [0.68687496 7.61952967 6.         0.69420959 8.         0.10232955]\t 1.0098398215101554\t 0.6354593174733028\t 0.7444564615559908\t 0.7444564615559908\n",
            "29 \t [9.89337178 3.81875947 5.         0.59649267 7.         0.86884145]\t 0.7753063665062683\t 0.6354593174733028\t 0.7461505763633203\t 0.7461505763633203\n",
            "30 \t [ 8.86798526  4.51282254  7.48664327  1.         14.48664327  1.        ]\t 0.6715235997222664\t 0.6354593174733028\t 0.7454518451130908\t 0.7454521623213977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48268.09990235775"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zaPbk2uuzH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6fb019d-3695-425a-952e-6dd3748e9216"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_exact_19 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=test_perc, random_state=run_num_19)\n",
        "\n",
        "def f_syn_polarity19(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_19, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train19, y=y_train19).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_19 = dGPGO(surrogate_exact_19, Acquisition_grad(util), f_syn_polarity19, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_19.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_19 = exact_19.getResult()[0]\n",
        "params_exact_19['max_depth'] = int(params_exact_19['max_depth'])\n",
        "params_exact_19['min_child_weight'] = int(params_exact_19['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train19 = xgb.DMatrix(X_train19, y_train19)\n",
        "dX_exact_test19 = xgb.DMatrix(X_test19, y_test19)\n",
        "model_exact_19 = xgb.train(params_exact_19, dX_exact_train19)\n",
        "pred_exact_19 = model_exact_19.predict(dX_exact_test19)\n",
        "\n",
        "rmse_exact_19 = np.sqrt(mean_squared_error(pred_exact_19, y_test19))\n",
        "rmse_exact_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 0.97533602  7.61249717 13.          0.85765469 11.          0.39830191]\t 0.7381578397530673\t 0.7295721630591281\t    \t    \n",
            "init\t [ 0.82999565  6.71977081  6.          0.50407413 19.          0.67209466]\t 0.7470234185181706\t 0.7295721630591281\t    \t    \n",
            "init\t [ 2.15923256  5.49027432 12.          0.52588686 10.          0.20235326]\t 1.018052265694813\t 0.7295721630591281\t    \t    \n",
            "init\t [4.99659267 1.52108422 6.         0.73481085 4.         0.71949465]\t 0.7455570460653044\t 0.7295721630591281\t    \t    \n",
            "init\t [ 3.72927156  9.46160045  5.          0.80554614 18.          0.97708466]\t 0.7295721630591281\t 0.7295721630591281\t    \t    \n",
            "\u001b[1m\u001b[92m1\u001b[0m\t \u001b[1m\u001b[92m[ 8.33060043  1.42030563  8.          0.92863724 14.          0.78606141]\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.6773838424850286\u001b[0m\t \u001b[1m\u001b[92m0.8082051265289488\u001b[0m\t \u001b[1m\u001b[92m0.8082051265289488\u001b[0m\n",
            "2  \t [ 9.87536409  7.17591217 14.          0.99713522 17.          0.55460731]\t 0.7019341665321482\t 0.6773838424850286\t 0.7606330392636097\t 0.7606330392636097\n",
            "3  \t [ 9.05225624  3.60011377 14.          0.89518364  1.          0.11342054]\t 1.0199606306890758\t 0.6773838424850286\t 0.7576906678490443\t 0.7576906678490443\n",
            "4  \t [ 0.63994078  3.71351436 14.          0.60091862  1.          0.58598556]\t 0.7327508164518542\t 0.6773838424850286\t 0.7674662531409786\t 0.7674662531409786\n",
            "5  \t [4.99125702 9.50308409 8.         0.55828329 3.         0.34673953]\t 0.8626234515673594\t 0.6773838424850286\t 0.7652958001931282\t 0.7652958001931282\n",
            "6  \t [ 1.43653664  6.25319475  5.          0.5        11.42700395  0.1       ]\t 1.0123750128903268\t 0.6773838424850286\t 0.7671673061229787\t 0.7671673060235292\n",
            "7  \t [ 3.74566023  2.13062241 14.          0.71219729 18.          0.68959412]\t 0.7065170119936448\t 0.6773838424850286\t 0.7731130419298647\t 0.7731130419298647\n",
            "\u001b[1m\u001b[92m8\u001b[0m\t \u001b[1m\u001b[92m[ 8.78531367  5.16236615 10.          0.71284072  9.          0.88546543]\u001b[0m\t \u001b[1m\u001b[92m0.6722375711719282\u001b[0m\t \u001b[1m\u001b[92m0.6722375711719282\u001b[0m\t \u001b[1m\u001b[92m0.7704833285609539\u001b[0m\t \u001b[1m\u001b[92m0.7704833285609539\u001b[0m\n",
            "9  \t [ 2.19431997  0.03640407  7.          0.62674231 12.          0.80025129]\t 0.6943584427070677\t 0.6722375711719282\t 0.7635087905767328\t 0.7635087905767328\n",
            "10 \t [0.  0.  5.  0.5 1.  0.1]\t 1.012959712728477\t 0.6722375711719282\t 0.7614103991327628\t 0.7614103859654181\n",
            "11 \t [ 8.347612    9.05501181  5.          0.50033019 10.          0.41046448]\t 0.7834119309620006\t 0.6722375711719282\t 0.7659308942451596\t 0.7659308942451596\n",
            "12 \t [ 6.11039048  8.9398787   9.          0.84431675 14.          0.73928782]\t 0.7102000973560662\t 0.6722375711719282\t 0.7653847710858185\t 0.7653847710858185\n",
            "\u001b[1m\u001b[92m13\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         15.          1.         11.54730623  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.649932789681593\u001b[0m\t \u001b[1m\u001b[92m0.649932789681593\u001b[0m\t \u001b[1m\u001b[92m0.7637796756026455\u001b[0m\t \u001b[1m\u001b[92m0.7637796707733289\u001b[0m\n",
            "14 \t [ 9.18890824  5.50760906  5.          0.92553651 18.          0.76040056]\t 0.7335321473751593\t 0.649932789681593\t 0.7437999247886474\t 0.7437999247886474\n",
            "15 \t [ 8.99876272  0.14180428 14.          0.5207566  10.          0.28841204]\t 0.8640399232649498\t 0.649932789681593\t 0.742848467816905\t 0.742848467816905\n",
            "16 \t [ 0.9019348   8.21531788 14.          0.85098746 17.          0.41254672]\t 0.7391934581482711\t 0.649932789681593\t 0.7438626954916029\t 0.7438626954916029\n",
            "17 \t [9.42305669 0.3423134  7.         0.77066127 8.         0.63693457]\t 0.7280806792663158\t 0.649932789681593\t 0.7430702338878448\t 0.7430702338878448\n",
            "18 \t [ 4.53712581  0.82823489 12.          0.77278662  7.          0.49955948]\t 0.7418182765032342\t 0.649932789681593\t 0.7422158466334741\t 0.7422158466334741\n",
            "19 \t [ 9.97958622  9.03409533 12.          0.51772082  4.          0.45869101]\t 0.7501971944554292\t 0.649932789681593\t 0.7415928163541454\t 0.7415928163541454\n",
            "20 \t [10.         10.          9.89176651  1.         20.          1.        ]\t 0.6633827771010997\t 0.649932789681593\t 0.7411149309073451\t 0.7411148494354386\n",
            "21 \t [ 3.16526468  9.88957695 14.          0.66718624  2.          0.49421519]\t 0.754638877583424\t 0.649932789681593\t 0.7397902657976386\t 0.7397902657976386\n",
            "22 \t [9.45817904 5.07482593 5.         0.8727678  6.         0.48725282]\t 0.7840445337336488\t 0.649932789681593\t 0.7394636828712665\t 0.7394636828712665\n",
            "23 \t [ 5.88466809 10.         10.3697924   1.          8.3697924   1.        ]\t 0.654237534658687\t 0.649932789681593\t 0.7394639039675818\t 0.7394629166397925\n",
            "24 \t [ 2.76287935  0.832992   10.          0.52421602  1.          0.77581255]\t 0.6811258108165148\t 0.649932789681593\t 0.7382594326319255\t 0.7382599257578686\n",
            "25 \t [0.69693578 8.073742   8.         0.85442901 7.         0.41823279]\t 0.7450774347575637\t 0.649932789681593\t 0.7373610829896762\t 0.7373610829896762\n",
            "26 \t [ 0.          3.0670386  10.14152815  0.5         6.14152815  0.1       ]\t 1.0176244215538337\t 0.649932789681593\t 0.7370712675485821\t 0.737071649743015\n",
            "27 \t [ 0.          0.64306559 11.75346562  0.5        15.75346562  0.1       ]\t 1.0151785649796032\t 0.649932789681593\t 0.7396016683416217\t 0.7396011813201229\n",
            "28 \t [ 4.53470807  2.6500816   5.          0.70480421 17.          0.65004423]\t 0.7697998132860621\t 0.649932789681593\t 0.7419386916014883\t 0.7419386916014883\n",
            "29 \t [ 8.73793669  2.43663345 11.          0.74070373 19.          0.18745114]\t 1.016658260578657\t 0.649932789681593\t 0.7417434023989492\t 0.7417434023989492\n",
            "30 \t [ 9.80949062  0.42526047 11.          0.61085682  4.          0.94165398]\t 0.6776829311951872\t 0.649932789681593\t 0.7438885188699965\t 0.7438885188699965\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48910.60814155049"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkuHKlQuxRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c071afd7-54b5-410d-c01f-423ce30d10a3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'exact' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_exact_20 = dGaussianProcess(cov_func, optimize=opt)\n",
        "\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(X, y, test_size=test_perc, random_state=run_num_20)\n",
        "\n",
        "def f_syn_polarity20(alpha, gamma, max_depth, subsample, min_child_weight, colsample):\n",
        "    reg = XGBRegressor(reg_alpha=alpha, gamma=gamma, max_depth=int(max_depth), subsample=subsample, min_child_weight=min_child_weight,\n",
        "          colsample_bytree=colsample, n_estimators = n_est, random_state=run_num_20, objective = 'reg:squarederror')\n",
        "    score = np.array(cross_val_score(reg, X=X_train20, y=y_train20).mean())\n",
        "    return operator * score\n",
        "\n",
        "exact_20 = dGPGO(surrogate_exact_20, Acquisition_grad(util), f_syn_polarity20, param, n_jobs = -1) # Define BayesOpt\n",
        "exact_20.run(max_iter = max_iter, init_evals = n_init) # run\n",
        "\n",
        "### Return optimal parameters' set:\n",
        "params_exact_20 = exact_20.getResult()[0]\n",
        "params_exact_20['max_depth'] = int(params_exact_20['max_depth'])\n",
        "params_exact_20['min_child_weight'] = int(params_exact_20['min_child_weight'])\n",
        "\n",
        "### Re-train with optimal parameters, run predictons:\n",
        "dX_exact_train20 = xgb.DMatrix(X_train20, y_train20)\n",
        "dX_exact_test20 = xgb.DMatrix(X_test20, y_test20)\n",
        "model_exact_20 = xgb.train(params_exact_20, dX_exact_train20)\n",
        "pred_exact_20 = model_exact_20.predict(dX_exact_test20)\n",
        "\n",
        "rmse_exact_20 = np.sqrt(mean_squared_error(pred_exact_20, y_test20))\n",
        "rmse_exact_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t  Best eval. \t         Max. ExactAcqFunc \t Max. ApproxAcqFunc \n",
            "init\t [ 5.88130801  8.97713728 14.          0.81074445  8.          0.95540649]\t 0.6597299542050263\t 0.6597299542050263\t    \t    \n",
            "init\t [6.72865655 0.41173329 8.         0.6361582  7.         0.76174061]\t 0.6983733363249625\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.77387703  8.66202323 10.          0.51833215  7.          0.10123387]\t 1.0633118913318171\t 0.6597299542050263\t    \t    \n",
            "init\t [ 5.75489985  4.74524381  8.          0.78084343 15.          0.26643049]\t 0.8790653027854468\t 0.6597299542050263\t    \t    \n",
            "init\t [ 4.53444     4.47342833  8.          0.91974896 18.          0.35997552]\t 0.8778581695963045\t 0.6597299542050263\t    \t    \n",
            "1  \t [ 7.96566073  7.15509535  7.          0.79906691 11.          0.34132075]\t 0.8825953654337161\t 0.6597299542050263\t 0.76573211512963\t 0.76573211512963\n",
            "2  \t [ 1.72798052  9.03285612 13.          0.50351094 19.          0.11416888]\t 1.0635732061044851\t 0.6597299542050263\t 0.7672300477807688\t 0.7672300477807688\n",
            "\u001b[1m\u001b[92m3\u001b[0m\t \u001b[1m\u001b[92m[10.         10.         14.97065983  1.         17.97065983  1.        ]\u001b[0m\t \u001b[1m\u001b[92m0.640171978551528\u001b[0m\t \u001b[1m\u001b[92m0.640171978551528\u001b[0m\t \u001b[1m\u001b[92m0.7771356027246019\u001b[0m\t \u001b[1m\u001b[92m0.7771356027246015\u001b[0m\n",
            "4  \t [0.  0.  5.  0.5 1.  0.1]\t 1.0679096170180373\t 0.640171978551528\t 0.7539062141211441\t 0.7539062141190496\n",
            "5  \t [ 7.50758902  2.31989813 13.          0.92794435  1.          0.52943075]\t 0.7559982376783114\t 0.640171978551528\t 0.7617046574420706\t 0.7617046574420706\n",
            "6  \t [ 0.55198982  4.75264073 14.          0.93528567 13.          0.58376745]\t 0.7405528896365979\t 0.640171978551528\t 0.7580186870637098\t 0.7580186870637098\n",
            "7  \t [ 1.01837104  4.41995744  6.          0.52021829 12.          0.99601116]\t 0.7078573361250974\t 0.640171978551528\t 0.7547408082374919\t 0.7547408082374919\n",
            "8  \t [5.5108266  6.15957203 5.00694992 0.5        3.00694992 0.1       ]\t 1.067536082982016\t 0.640171978551528\t 0.7510687304059095\t 0.7510687194369603\n",
            "9  \t [ 8.00974414  4.59126341 14.          0.56460775 14.          0.49726491]\t 0.8085856455509264\t 0.640171978551528\t 0.7568159315893171\t 0.7568159315893171\n",
            "10 \t [ 2.80497429  1.01980964 13.          0.88100892  4.          0.76512005]\t 0.6900530852018463\t 0.640171978551528\t 0.7555470429695573\t 0.7555470429695573\n",
            "11 \t [ 0.97109006  6.64906646 10.          0.68736304  1.          0.83364975]\t 0.6988638404037975\t 0.640171978551528\t 0.7522687525170157\t 0.7522687525170157\n",
            "12 \t [ 6.87684298  0.81341201 12.          0.63438989 19.          0.35708107]\t 0.8844718896334441\t 0.640171978551528\t 0.7496069981172067\t 0.7496069981172067\n",
            "13 \t [0.58308799 2.17001544 7.         0.96791802 6.         0.7702227 ]\t 0.6960527431631587\t 0.640171978551528\t 0.7503963894841825\t 0.7503963894841825\n",
            "14 \t [ 9.23004102  7.42355186 10.          0.69362726  2.          0.96169196]\t 0.6694801068381588\t 0.640171978551528\t 0.748012432065351\t 0.748012432065351\n",
            "15 \t [ 9.90619221  7.05528672  5.          0.91932487 18.          0.63366006]\t 0.7328927505356351\t 0.640171978551528\t 0.745677198008232\t 0.745677198008232\n",
            "16 \t [ 7.65146653  2.36586786 13.          0.71989624  7.          0.80860445]\t 0.6888973472758477\t 0.640171978551528\t 0.7442232799174435\t 0.7442232799174435\n",
            "17 \t [ 0.2041128   7.58471382 13.          0.88143644  6.          0.71454404]\t 0.6898813053383854\t 0.640171978551528\t 0.7424379315326494\t 0.7424379315326494\n",
            "18 \t [ 0.7766431   8.0732046   5.          0.88801393 19.          0.19994543]\t 1.063694650982524\t 0.640171978551528\t 0.7408214527688658\t 0.7408214527688658\n",
            "19 \t [8.67223652 9.66010575 6.         0.63457768 6.         0.86415257]\t 0.7147083784607429\t 0.640171978551528\t 0.744455262185176\t 0.744455262185176\n",
            "20 \t [ 3.65859461  0.92515984  9.37257536  0.5        12.37257536  0.18411105]\t 1.062777560600922\t 0.640171978551528\t 0.743153969051973\t 0.743154176122105\n",
            "21 \t [ 2.16891361  0.40236972  6.          0.57865056 19.          0.33900997]\t 0.8933558323113931\t 0.640171978551528\t 0.7464350448752719\t 0.7464350448752719\n",
            "22 \t [ 2.39999736  8.25935251 10.          0.76621897 14.          0.97994917]\t 0.6650911441542652\t 0.640171978551528\t 0.7470771789410968\t 0.7470771789410968\n",
            "23 \t [ 9.71937523  0.84081751  8.          0.83815718 13.          0.15657647]\t 1.0605231713179224\t 0.640171978551528\t 0.7453771356887414\t 0.7453771356887414\n",
            "24 \t [ 2.79786899  0.79670157 14.          0.51865068 18.          0.73783169]\t 0.6974525814074385\t 0.640171978551528\t 0.7481870876831689\t 0.7481870876831689\n",
            "25 \t [ 8.84027285 10.          8.17274895  1.         15.17274895  1.        ]\t 0.6583606361996189\t 0.640171978551528\t 0.746790252748786\t 0.7467912418760186\n",
            "26 \t [ 0.          2.12315891 12.70311586  0.5         8.70311586  0.1       ]\t 1.063477401206384\t 0.640171978551528\t 0.7452163665524542\t 0.7452155173397128\n",
            "27 \t [10.         10.         15.          1.         11.69326985  1.        ]\t 0.6440222429859022\t 0.640171978551528\t 0.7477524881832588\t 0.7477521655571365\n",
            "28 \t [ 5.26806888  9.79444938 14.          0.72998947 15.          0.32861977]\t 0.8831401624229749\t 0.640171978551528\t 0.7461443251371457\t 0.7461443251371457\n",
            "29 \t [10.          9.29701904 14.78143725  1.          1.78143725  1.        ]\t 0.6455226357706716\t 0.640171978551528\t 0.7466038534855858\t 0.7466045270020747\n",
            "30 \t [10.         10.          9.27929207  1.         20.          1.        ]\t 0.6476827640930217\t 0.640171978551528\t 0.7451315200645373\t 0.7451322084933124\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48992.31475314243"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKuwvS3uzrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1c864b-42a8-43b4-90fd-c1c70e285ce7"
      },
      "source": [
        "end_exact = time.time()\n",
        "end_exact\n",
        "\n",
        "time_exact = end_exact - start_exact\n",
        "time_exact"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2275.0587482452393"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU2FlhY4vHUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abd1d76-ec36-4fad-9924-e7a48783655a"
      },
      "source": [
        "rmse_approx = [rmse_approx_1,\n",
        "rmse_approx_2,\n",
        "rmse_approx_3,\n",
        "rmse_approx_4,\n",
        "rmse_approx_5,\n",
        "rmse_approx_6,\n",
        "rmse_approx_7,\n",
        "rmse_approx_8,\n",
        "rmse_approx_9,\n",
        "rmse_approx_10,\n",
        "rmse_approx_11,\n",
        "rmse_approx_12,\n",
        "rmse_approx_13,\n",
        "rmse_approx_14,\n",
        "rmse_approx_15,\n",
        "rmse_approx_16,\n",
        "rmse_approx_17,\n",
        "rmse_approx_18,\n",
        "rmse_approx_19,\n",
        "rmse_approx_20]\n",
        "\n",
        "np.mean(rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50340.85839421808"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ53FsWXu3J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a91a40c-1f11-4342-b75a-98de01b88d10"
      },
      "source": [
        "rmse_exact = [rmse_exact_1,\n",
        "rmse_exact_2,\n",
        "rmse_exact_3,\n",
        "rmse_exact_4,\n",
        "rmse_exact_5,\n",
        "rmse_exact_6,\n",
        "rmse_exact_7,\n",
        "rmse_exact_8,\n",
        "rmse_exact_9,\n",
        "rmse_exact_10,\n",
        "rmse_exact_11,\n",
        "rmse_exact_12,\n",
        "rmse_exact_13,\n",
        "rmse_exact_14,\n",
        "rmse_exact_15,\n",
        "rmse_exact_16,\n",
        "rmse_exact_17,\n",
        "rmse_exact_18,\n",
        "rmse_exact_19,\n",
        "rmse_exact_20]\n",
        "\n",
        "np.mean(rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49288.70649044413"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9FOyoH8u5Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4446b334-ae9c-4122-860b-c4aa271b4a71"
      },
      "source": [
        "min_rmse_approx = min_max_array(rmse_approx)\n",
        "min_rmse_approx, len(min_rmse_approx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([48973.66312746987,\n",
              "  48973.66312746987,\n",
              "  48973.66312746987,\n",
              "  48973.66312746987,\n",
              "  48973.66312746987,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  48068.332581319075,\n",
              "  47814.5922880461,\n",
              "  47814.5922880461,\n",
              "  47814.5922880461],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXOpKHcvO15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180cafb6-0eeb-4323-b6a2-196f30f740ff"
      },
      "source": [
        "min_rmse_exact = min_max_array(rmse_exact)\n",
        "min_rmse_exact, len(min_rmse_exact)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([47099.16270975631,\n",
              "  47099.16270975631,\n",
              "  47099.16270975631,\n",
              "  47099.16270975631,\n",
              "  47099.16270975631,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189,\n",
              "  46832.22443034189],\n",
              " 20)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxo85-HEvRPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "f7165fb4-ea86-41ac-c649-2cf317130ceb"
      },
      "source": [
        "### Visualise!\n",
        "\n",
        "title = obj_func\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(min_rmse_approx, color = 'Yellow', label='RMSE: Approx GP EI gradients')\n",
        "plt.plot(min_rmse_exact, color = 'Red', label='RMSE: Exact GP dEI gradients', ls='--')# r'($\\nu$' ' = {})'.format(df))\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('Experiment(s)', weight = 'bold', family = 'Arial') # x-axis label\n",
        "plt.ylabel('RMSE (US Dollars $)', weight = 'bold', family = 'Arial') # y-axis label\n",
        "plt.legend(loc=0) # add plot legend\n",
        "\n",
        "### Make the x-ticks integers, not floats:\n",
        "count = len(min_rmse_approx)\n",
        "plt.xticks(np.arange(count), np.arange(1, count + 1))\n",
        "plt.grid(b=None)\n",
        "plt.show() #visualize!\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwyO7_iZvT7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb5569b-c457-45e2-a937-e3b59d6e022a"
      },
      "source": [
        "time_approx, time_exact\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2308.4914548397064, 2275.0587482452393)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHLA-0DnVXxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc08ff1-3807-477e-d9e2-0ab3b8c44d01"
      },
      "source": [
        "min(min_rmse_exact), min(min_rmse_approx)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46832.22443034189, 47814.5922880461)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUNBRy3W0GY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}